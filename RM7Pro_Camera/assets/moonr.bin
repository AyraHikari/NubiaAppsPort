E:\MyDoc\AI\ImageProcess\work\ZyModel
snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_mnv3_640_360.pb --input_dim sub_2 "1,361,641,3" --out_node "ArgMax" --output_path ./mnv3.dlc --allow_unconsumed_nodes
/home/droid/smb_share/snpe_1_35_0/snpe-1.35.0.698/lib/python/snpe/converters/common/converter_ir/ir_to_dlc.py:166:
 RuntimeWarning: info_code=802; message=Layer parameter value is invalid in GPU. Layer ArgMax : 
 output width = 361, depth = 641 width * depth (packed) = 58121 exceeds maximum image width 16384 for Adreno A650; component=GPU Runtime; 
 line_no=707; thread_id=140253143332672
  node.op.keep_dims)

snpe-dlc-info -i mnv3.dlc -s mnv3.csv -m
snpe-dlc-viewer -i mnv3.dlc -s mnv3.html

手动模型转换：
pwd
/home/droid/smb_share/snpe_1_35_0/test/deeplabv3_mnv3/0219/export
snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_mnv3_640_360.pb --input_dim sub_2 "1,361,641,3" --out_node "ResizeBilinear_2" --output_path ./optimized_frozen_inference_graph_mnv3_640_360.dlc --allow_unconsumed_nodes
snpe-dlc-info -i optimized_frozen_inference_graph_mnv3_640_360.dlc -s optimsnpe-dlc-info -i mnv3.dlc -s mnv3.csv -m
snpe-dlc-viewer -i mnv3.dlc -s mnv3.htmlized_frozen_inference_graph_mnv3_640_360.csv -m
snpe-dlc-viewer -i optimized_frozen_inference_graph_mnv3_640_360.dlc -s optimized_frozen_inference_graph_mnv3_640_360.html

snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_mnv3_640_360.pb --input_dim sub_2 "1,361,641,3" --out_node "ArgMax" --output_path ./argmax/argmax_optimized_frozen_inference_graph_mnv3_640_360.dlc --allow_unconsumed_nodes
snpe-dlc-info -i optimized_frozen_inference_graph_mnv3_640_360.dlc -s optimized_frozen_inference_graph_mnv3_640_360.csv -m
snpe-dlc-info -i argmax_optimized_frozen_inference_graph_mnv3_640_360.dlc -s argmax_optimized_frozen_inference_graph_mnv3_640_360.csv -m
snpe-dlc-viewer -i argmax_optimized_frozen_inference_graph_mnv3_640_360.dlc -s argmax_optimized_frozen_inference_graph_mnv3_640_360.html

全自动模型转换、输入数据准备、量化：
python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r dsp
python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r aip

snpe-dlc-info -i optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_aip_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_aip_quantized.csv
snpe-dlc-viewer -i optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_aip_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_aip_quantized.html
snpe-dlc-info -i optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_dsp_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_dsp_quantized.csv
snpe-dlc-viewer -i optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_dsp_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_resizebilinear_2_dsp_quantized.html

snpe-dlc-info -i optimized_frozen_inference_graph_mnv3_640_360_argmax_aip_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_argmax_aip_quantized.csv
snpe-dlc-viewer -i optimized_frozen_inference_graph_mnv3_640_360_argmax_aip_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_argmax_aip_quantized.html
snpe-dlc-info -i optimized_frozen_inference_graph_mnv3_640_360_argmax_dsp_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_argmax_dsp_quantized.csv
snpe-dlc-viewer -i optimized_frozen_inference_graph_mnv3_640_360_argmax_dsp_quantized.dlc -s optimized_frozen_inference_graph_mnv3_640_360_argmax_dsp_quantized.html


手动量化：
cd /home/droid/smb_share/snpe_1_35_0/snpe-1.35.0.698/models/mn_v3/dlc_ArgMax
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_mnv3_640_360.dlc --input_list  ../data/cropped/raw_list.txt --output_dlc mv3_test_quantized.dlc

BenchMark：
python snpe_bench.py -c mn_v3_gpu.json -l detailed -json
python snpe_bench.py -c mn_v3_dsp.json -l detailed -json
python snpe_bench.py -c mn_v3_aip.json -l detailed -json

CpuFallback:False


Result:
       TF Lite       SNPE
CPU     150          260
GPU     21           60
DSP     
AIP     -

0224下载地址：
http://10.63.228.28:8888/tree/zhuyan/research_191108/deeplab/datasets/zte_seg/exp_dfanet/train_on_trainval_set_mnv3_640_480_0223/export
python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r dsp


private static String MODEL_PATH_TF_GPU = "optimized_mnv3_641_481_0223.tflite";
private static String MODEL_PATH_TF_DSP = "quantize_optimized_mnv3_641_481_0223.tflite";

641 X 481	
Result:
       TF Lite       SNPE
CPU     200          300
GPU     28           83
DSP     19           65       no quantize:
AIP     -

http://10.63.228.28:8888/tree/zhuyan/research_191108/deeplab/datasets/zte_seg/exp_dfanet/quantize_train_on_trainval_set_mnv3_640_480_0223/export

Created TensorFlow Lite delegate for Hexagon.
Hexagon delegate: X nodes delegated out of Y nodes.

snpe-dlc-info -i no_opt_quantize_mnv3_641_481_resizebilinear_1_aip_quantized.dlc -s no_opt_quantize_mnv3_641_481_resizebilinear_1_aip_quantized.csv
snpe-dlc-viewer -i no_opt_quantize_mnv3_641_481_resizebilinear_1_aip_quantized.dlc -s no_opt_quantize_mnv3_641_481_resizebilinear_1_aip_quantized.html

snpe-dlc-info -i no_opt_mnv3_641_481_resizebilinear_1_aip_quantized.dlc -s no_opt_mnv3_641_481_resizebilinear_1_aip_quantized.csv
snpe-dlc-viewer -i no_opt_mnv3_641_481_resizebilinear_1_aip_quantized.dlc -s no_opt_mnv3_641_481_resizebilinear_1_aip_quantized.html
snpe-dlc-info -i no_opt_quantize_mnv3_641_481_resizebilinear_2_dsp.dlc -s no_opt_quantize_mnv3_641_481_resizebilinear_2_dsp.csv	   
snpe-dlc-info -i no_opt_quantize_mnv3_641_481_resizebilinear_2_dsp_quantized.dlc -s no_opt_quantize_mnv3_641_481_resizebilinear_2_dsp_quantized.csv

//////////////////////////////////////////
python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r dsp

量化感知转化：
org：
tflite_convert \
  --output_file=${EXPORT_DIR}/quantize_frozen_inference_graph.tflite \
  --graph_def_file=${EXPORT_DIR}/frozen_inference_graph_8000.pb \
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=6 \
  --change_concat_input_ranges=true  #use this
  
test ok：   
tflite_convert \
  --output_file=quantize_mnv3_641_481_0225_self.tflite \
  --graph_def_file=quantize_mnv3_641_481_0225.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=6
  --change_concat_input_ranges=true  #use this

tflite_convert \
  --output_file=optimized_quan_mnv3_dsp_test_3_512.tflite \
  --graph_def_file=optimized_quan_mnv3_aip_test_3_512.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,512,512,3 \
  --output_arrays="ResizeBilinear_1" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=6  
  
tflite_convert \
  --output_file=optimized_quan_mnv3_640_480_8000_1_fold.tflite \
  --graph_def_file=optimized_quan_mnv3_640_480_8000_1_fold.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=6  
  

tflite_convert \
  --output_file=quantize_mnv3_641_481_0225_self_zy.tflite \
  --graph_def_file=quantize_mnv3_641_481_0225.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=127.5 \
  --mean_values=127.5 \
  --default_ranges_min=0 \
  --default_ranges_max=6
  
bazel模型转换：
bazel run //tensorflow/lite/python:tflite_convert \
  --output_file=/home/zhangdm/tensorflow_20200106_master/tensorflow_master/tensorflow/test/quantize_mnv3_641_481_0225.tflite \
  --graph_def_file=/home/zhangdm/tensorflow_20200106_master/tensorflow_master/tensorflow/test/quantize_mnv3_641_481_0225.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=255 \
  --change_concat_input_ranges=true
  
  
bazel-bin/tensorflow/contrib/lite/toco/toco \
--input_file=/home/lg/Desktop/mobilenet_v1/frozen_mobilenet_v1_224.pb \
--input_format=TENSORFLOW_GRAPHDEF  \
--output_format=TFLITE  \
--output_file=/home/lg/Desktop/mobilenet_v1/frozen_graph_mobilenet_v1-QUANTIZED_UINT8.tflite \
--inference_type=QUANTIZED_UINT8  \
--input_type=QUANTIZED_UINT8 \
--input_arrays=Placeholder  \
--output_arrays=MobilenetV1/Predictions/Reshape_1  \
--input_shapes=1,224,224,3 \
--default_ranges_min=0.0 \
–default_ranges_max=255.0

  
//////////////////////////量化资料
生成.tflite文件过程中遇到的问题及解决方案
https://blog.csdn.net/liugan528/article/details/79770680
模型量化原理及tflite示例,非常详细：
https://www.cnblogs.com/sdu20112013/p/11960552.html
TensorFlow 8 bit模型量化
https://www.cnblogs.com/arkenstone/p/10856466.html
tensorflow的量化教程(1)
https://blog.csdn.net/u012101561/article/details/82587806
MobileNet SSD V2 tflite模型的量化
https://www.jianshu.com/p/660c791cb909
JAVA中的无符号整形
https://www.cnblogs.com/jpit/p/9068429.html

quantization: -1 ≤ 0.0078125 * (q - 128) ≤ 0.9921875
quantization: -17.315221786499023 ≤ 0.1419280469417572 * (q - 122) ≤ 18.876428604125977
		   
////////////////////////
0227：
python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r aip
Starting assembler.
NO ERRORS;
NO WARNINGS;
snpe-dlc-quantize: /local/mnt/workspace/c_yetazh/p4_dsp/compiler/test/legacy_compiler/libs/core/src/MetadataPass.cpp:641: void MetadataPass::generateBilinearKernels(NpuLayer&, NpuIr::ScalingParams&): Assertion `factorX == factorY' failed.
INFO: Setup mn_v3 completed.
snpe-tensorflow-to-dlc --input_network quantize_mnv3_641_481_0227.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_641_481_0227.dlc --allow_unconsumed_nodes
snpe-dlc-info -i quantize_mnv3_641_481_0227.dlc -s quantize_mnv3_641_481_0227.csv
snpe-dlc-quantize --input_dlc quantize_mnv3_641_481_0227.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_641_481_0227_dsp.dlc
snpe-dlc-quantize --input_dlc quantize_mnv3_641_481_0227.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_641_481_0227_aip.dlc --enable_hta --hta_partitions 0-50 
snpe-dlc-info -i quantize_mnv3_641_481_0227_aip.dlc -s quantize_mnv3_641_481_0227_aip.csv

93节点：
snpe-dlc-quantize --input_dlc quantize_mnv3_641_481_0227.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_641_481_0227_aip.dlc --enable_hta --hta_partitions 0-75,86-92


snpe-dlc-quantize --input_dlc quantize_mnv3_641_481_0227.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_641_481_0227_aip.dlc --enable_hta --hta_partitions sm8150:0-75,77-78,80-81,83-84,86-92,95-98

0-75,77-78,80-81,83-84,86-92,95-98 
     
               name                                            算子type               是否支持                 
76：MobilenetV3/expanded_conv_13/depthwise/depthwise_Fold      convolutional           不支持
79：MobilenetV3/expanded_conv_13/add                           elementwise_op          不支持
82：MobilenetV3/expanded_conv_14/depthwise/depthwise_Fold      convolutional           不支持
85：MobilenetV3/expanded_conv_14/add                           elementwise_op          不支持
93：ResizeBilinear:0                                           scaling                 不支持
94：concat                                                     concatenation           不支持
99：ResizeBilinear_2:0                                         scaling                 不支持

              name                                            算子type               是否支持   
77：MobilenetV3/expanded_conv_13/depthwise/Relu               neuron                 可以运行，但提示建议Drop
78：MobilenetV3/expanded_conv_13/project/Conv2D_Fold          convolutional          可以运行，但提示建议Drop
80: MobilenetV3/expanded_conv_14/expand/Conv2D_Fold           convolutional          可以运行，但提示建议Drop
81: MobilenetV3/expanded_conv_14/expand/Relu                  neuron                  可以运行，但提示建议Drop
83：MobilenetV3/expanded_conv_14/depthwise/Relu               neuron                  可以运行，但提示建议Drop
84：MobilenetV3/expanded_conv_14/project/Conv2D_Fold          convolutional           可以运行，但提示建议Drop

snpe-tensorflow-to-dlc --input_network quantize_mnv3_641_481_0227.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_641_481_0227.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_641_481_0227.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_641_481_0227_aip.dlc --enable_hta --hta_partitions 0-75
snpe-dlc-viewer -i quantize_mnv3_641_481_0227.dlc -s quantize_mnv3_641_481_0227.html


2020-02-28 11:19:49*[朱燕00111288]说:
flod修改：
http://10.63.228.28:8888/tree/zhuyan/research_191108/deeplab/datasets/zte_seg/exp_dfanet/quantize_train_on_trainval_set_mnv3_640_480_0224/export

snpe-tensorflow-to-dlc --input_network optimized_quan_mnv3_640_480_8000_1_fold.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_quan_mnv3_640_480_8000_1_fold.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_quan_mnv3_640_480_8000_1_fold.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quan_mnv3_640_480_8000_1_fold_aip.dlc --enable_hta --hta_partitions 0-75,76-76
snpe-dlc-info -i optimized_quan_mnv3_640_480_8000_1_fold.dlc -s optimized_quan_mnv3_640_480_8000_1_fold.csv

optimized_quan_mnv3_640_480_8000_1_fold_aip.dlc
snpe-dlc-info -i optimized_quan_mnv3_640_480_8000_1_fold_aip.dlc -s optimized_quan_mnv3_640_480_8000_1_fold_aip.csv

0303_no resize2 test:
snpe-tensorflow-to-dlc --input_network optimized_quan_mnv3_640_480_8000_1_fold.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_1" --output_path optimized_quan_mnv3_640_480_8000_1_fold_no_scale.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_quan_mnv3_640_480_8000_1_fold_no_scale.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quan_mnv3_640_480_8000_1_fold_no_scale_aip.dlc --enable_hta --hta_partitions 0-92
snpe-dlc-info -i optimized_quan_mnv3_640_480_8000_1_fold.dlc -s optimized_quan_mnv3_640_480_8000_1_fold.csv


0422:
snpe-tensorflow-to-dlc --input_network optimized_quan_mnv3_640_480_8000_1_fold.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_quan_mnv3_640_480_8000_1_fold.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_quan_mnv3_640_480_8000_1_fold.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quan_mnv3_640_480_8000_1_fold_aip.dlc --enable_hta --hta_partitions 0-75,76-76
snpe-dlc-quantize --input_dlc optimized_quan_mnv3_640_480_8000_1_fold.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quan_mnv3_640_480_8000_1_fold_aip.dlc --enable_hta --hta_partitions 0-10

//
snpe-tensorflow-to-dlc --input_network optimized_quan_mnv3_2_resize_test.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_quan_mnv3_2_resize_test.dlc --allow_unconsumed_nodes
snpe-dlc-info -i optimized_quan_mnv3_2_resize_test.dlc -s optimized_quan_mnv3_2_resize_test.csv
snpe-dlc-quantize --input_dlc optimized_quan_mnv3_2_resize_test.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quan_mnv3_2_resize_test_aip.dlc --enable_hta --hta_partitions 0-75,76-76

snpe-tensorflow-to-dlc --input_network optimized_quan_mnv3_aip_test_3_512.pb --input_dim sub_2 "1,512,512,3" --out_node "ResizeBilinear_2" --output_path optimized_quan_mnv3_aip_test_3_512.dlc --allow_unconsumed_nodes

python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r aip
snpe-dlc-info -i optimized_quan_mnv3_aip_test_3_512.dlc -s optimized_quan_mnv3_aip_test_3_512.csv
snpe-dlc-viewer -i optimized_quan_mnv3_aip_test_3_512_resizebilinear_1_aip_quantized.dlc -s optimized_quan_mnv3_aip_test_3_512_resizebilinear_1_aip_quantized.html

snpe-dlc-quantize --input_dlc optimized_quan_mnv3_aip_test_3_512.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quan_mnv3_aip_test_3_512_aip.dlc --enable_hta --hta_partitions 0-98

//////////////////////////////////////////////////////
0229
snpe-tensorflow-to-dlc --input_network quantize_mnv3_512_512_0229.pb --input_dim sub_2 "1,512,512,3" --out_node "ResizeBilinear_1" --output_path quantize_mnv3_512_512_0229.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_512_512_0229.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_512_512_0229_aip.dlc --enable_hta --hta_partitions 0-98
snpe-dlc-info -i quantize_mnv3_512_512_0229_aip.dlc -s quantize_mnv3_512_512_0229_aip.csv
snpe-dlc-info -i quantize_mnv3_512_512_0229_aip.dlc -s quantize_mnv3_512_512_0229_aip.csv

snpe-tensorflow-to-dlc --input_network optimized_quantize_mnv3_512_512_0229.pb --input_dim sub_2 "1,512,512,3" --out_node "ResizeBilinear_1" --output_path optimized_quantize_mnv3_512_512_0229.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_quantize_mnv3_512_512_0229.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quantize_mnv3_512_512_0229_aip.dlc --enable_hta --hta_partitions 0-98
snpe-dlc-info -i optimized_quantize_mnv3_512_512_0229_aip.dlc -s optimized_quantize_mnv3_512_512_0229_aip.csv
snpe-dlc-info -i optimized_quantize_mnv3_512_512_0229.dlc -s optimized_quantize_mnv3_512_512_0229.csv
/////////////////test no scale:
logits/semantic/Conv2D
snpe-tensorflow-to-dlc --input_network optimized_quantize_mnv3_512_512_0229.pb --input_dim sub_2 "1,512,512,3" --out_node "logits/semantic/Conv2D" --output_path optimized_quantize_mnv3_512_512_0229_no_scale.dlc --allow_unconsumed_nodes
snpe-dlc-info -i optimized_quantize_mnv3_512_512_0229_no_scale.dlc -s optimized_quantize_mnv3_512_512_0229_no_scale.csv
snpe-dlc-quantize --input_dlc optimized_quantize_mnv3_512_512_0229_no_scale.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_quantize_mnv3_512_512_0229_no_scale_aip.dlc --enable_hta --hta_partitions 0-97
snpe-dlc-info -i optimized_quantize_mnv3_512_512_0229_no_scale_aip.dlc -s optimized_quantize_mnv3_512_512_0229_no_scale_aip.csv

//////////////////////////////////////////////////////////////
0302

logits/semantic/Conv2D
snpe-tensorflow-to-dlc --input_network optimized_mnv3_641_481_03_02.pb --input_dim sub_2 "1,641,481,3" --out_node "logits/semantic/Conv2D" --output_path optimized_mnv3_641_481_03_02_no_scale.dlc --allow_unconsumed_nodes
snpe-dlc-info -i optimized_mnv3_641_481_03_02_no_scale.dlc -s optimized_mnv3_641_481_03_02_no_scale.csv
snpe-dlc-quantize --input_dlc optimized_mnv3_641_481_03_02_no_scale.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc optimized_mnv3_641_481_03_02_no_scale_aip.dlc --enable_hta --hta_partitions 0-92
snpe-dlc-info -i optimized_mnv3_641_481_03_02_no_scale_aip.dlc -s optimized_mnv3_641_481_03_02_no_scale_aip.csv
///////////////////////////////////////////////////////////////
0303
android中保存Bitmap图片到指定文件夹中的方法
https://blog.csdn.net/u013144863/article/details/51542354
Android学习之保存Bitmap到指定文件夹
https://www.2cto.com/kf/201508/435102.html

我们对原始图像进行薄板样条平滑，以便仿真快速的相机移动和旋转:
https://ai.googleblog.com/2018/03/mobile-real-time-video-segmentation.html

android的file文件创建
https://blog.csdn.net/hcq__yy/article/details/81782140
///////////////////////////////
/sdcard/Android/data/com.zte.opengldemo/files
rm -R 18325
adb pull /sdcard/Android/data/com.zte.opengldemo/files/18325 .

2020-03-04 10:31:21.106 18601-19167/com.zte.opengldemo D/TFliteSegment: test debug doudong bmpToInputBuffer fileName=1583289081_0027_org.jpg,
mCurrFilePath=/storage/emulated/0/Android/data/com.zte.opengldemo/files/18325/org/,
mInOriginBitmap.getWidth()=1280,mInOriginBitmap.getHeight=720,
inBitmap.getWidth()=481,inBitmap.getHeight=641,
mPreviewWidth=1280,mPreviewHeight=720

ok
2020-03-04 11:14:40.716 28098-28136/com.zte.opengldemo D/TFliteSegment: test debug doudong bmpToInputBuffer fileName=1583291680_0051_org.jpg,mCurrFilePath=/storage/emulated/0/Android/data/com.zte.opengldemo/files/18325/org/,
mInOriginBitmap.getWidth()=1280,mInOriginBitmap.getHeight=720,
inBitmap.getWidth()=481,inBitmap.getHeight=641,
mPreviewWidth=1280,mPreviewHeight=720

2020-03-04 13:57:28.481 3364-3435/com.zte.opengldemo D/TFliteSegment: test debug doudong outSmallMaskBitmapToCanvas fileName=1583301448_0021_org.jpg,mCurrFilePath=/storage/emulated/0/Android/data/com.zte.opengldemo/files/18325/org/,
mMaskSmallBitmap.getWidth()=481,mMaskSmallBitmap.getHeight=641,
INPUT_WIDTH=481,INPUT_HEIGHT=641,
OUTPUT_WIDTH=481,OUTPUT_HEIGHT=641,
mPreviewWidth=1280,mPreviewHeight=720

//0305
cd /sdcard/Android/data/com.zte.opengldemo/files
rm -R 18328
adb pull /sdcard/Android/data/com.zte.opengldemo/files/18328 .

Android中的图像处理
https://blog.csdn.net/yao_94/article/details/79202654
//0306

Android实现Bitmap高斯模糊效果
https://blog.csdn.net/xinpengfei521/article/details/74856848
使用RenderScript实现高斯模糊(毛玻璃/磨砂)效果
https://segmentfault.com/a/1190000008101820
renderScript实现图片放大，黑白，添加光源，怀旧效果实例附源码
https://blog.csdn.net/gediseer/article/details/68488656
//0309
/sdcard/Android/data/com.zte.opengldemo/files
rm -R 18330
adb pull /sdcard/Android/data/com.zte.opengldemo/files/18330 .

//0310
pb转tf lite参考：
tflite_convert \
  --output_file=quantize_mnv3_641_481_0225_self.tflite \
  --graph_def_file=quantize_mnv3_641_481_0225.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=6
  
  bazel run --config=opt \
  //tensorflow/contrib/lite/toco:toco -- \
  --input_file=/tmp/mobilenet_v1_1.0_224_frozen.pb \   # 待转换模型路径
  --output_file=/tmp/tflite_model2.tflite \            # 目标模型路径
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --input_shape=1,224,224,3 \                           # 输入图像宽高
  --input_array=input \                                 # 输入节点名称<参考1>
  --output_array=MobilenetV1/Predictions/Reshape_1 \    # 输出节点名称<参考1>
  --inference_type=FLOAT \                              # 图像数据类型
  --input_data_type=FLOAT
  
不含ArgMax：  
tflite_convert \
  --output_file=deeplabv3_mnv2_pascal_train_aug_self.tflite \
  --graph_def_file=deeplabv3_mnv2_pascal_train_aug.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_7" \
  --input_shape=1,513,513,3 \
  --output_arrays="ResizeBilinear_3"
含ArgMax：
tflite_convert \
  --output_file=deeplabv3_mnv2_pascal_train_aug_self_ArgMax.tflite \
  --graph_def_file=deeplabv3_mnv2_pascal_train_aug.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_7" \
  --input_shape=1,513,513,3 \
  --output_arrays="ArgMax"
  
 tflite_convert \
  --output_file=deeplabv3_mnv2_pascal_train_aug_self_ArgMax_2.tflite \
  --graph_def_file=deeplabv3_mnv2_pascal_train_aug.pb\
  --input_arrays="sub_7" \
  --input_shape=1,513,513,3 \
  --output_arrays="ArgMax"    
  
snpe-tensorflow-to-dlc –graph deeplabv3_mnv2_pascal_train_aug/deeplabv3_mnv2_pascal_train_aug.pb -i sub_7 1,513,513,3 --out_node ArgMax --dlc deeplabv3.dlc --allow_unconsumed_nodes
///////////////////
0311
outBufferToMaskBitmap()
runInterpret()
public void bmpToInputBuffer(Bitmap bitmap)

//////////////////////////////////////////////
图像预处理资料：
/sdcard/Android/data/com.zte.opengldemo/files
opencv 人像检测 + Holes填充:
https://blog.csdn.net/guguant/article/details/54428817
opencv 二值图像的孔洞填充:
https://blog.csdn.net/hust_bochu_xuchao/article/details/51967846?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
opencv二值图孔洞填充算法(方法系转载):
https://blog.csdn.net/zbyzhlsp2/article/details/8134227?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
OPENCV二值化图像内孔洞填充/小区域去除:重要
https://blog.csdn.net/liuuze5/article/details/77881390?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

python_opencv实现图像分割孔洞填充后处理
https://blog.csdn.net/weixin_42181588/article/details/89467478?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
python_opencv实现图像分割（多分类彩色图像）孔洞填充后处理

opencv-python填充算法（水漫填充）
https://blog.csdn.net/E01114255/article/details/76186656?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
OpenCV入门教程之十五】水漫金山：OpenCV漫水填充算法（Floodfill）重要
https://blog.csdn.net/poem_qianmo/article/details/28261997?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

Android Studio使用Opencv实现图像的实时处理--java版 重要
https://blog.csdn.net/xuanwo11/article/details/74973259?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
实时显示 Opencv处理后的Camera图像 AndroidStudio NDK方法 --ndk版 重要
https://blog.csdn.net/u010677365/article/details/78344202?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

android使用opencv之亮度与对比度处理
https://blog.csdn.net/xuyankuanrong/article/details/78884824
android中使用OpenCV之图像边缘检测
https://blog.csdn.net/xuyankuanrong/article/details/79243997?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
opencv 彩色图像对比度增强
https://blog.csdn.net/abcjennifer/article/details/7428737?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
OpenCV——对比度增强
https://blog.csdn.net/hushaoqiqimingxing/article/details/92080833?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
Opencv 学习---8种常用图像增强算法
https://blog.csdn.net/guanzhen3657/article/details/81138868?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

Android 接入 OpenCV库的三种方式 重要！！！！！！！！
https://www.cnblogs.com/xiaoxiaoqingyi/p/6676096.html
 
Android改变图像的饱和度、亮度和对比度 重要！！！！！！！！数组用法
https://blog.csdn.net/gf771115/article/details/40778091
https://blog.csdn.net/sxwyf248/article/details/7019731  

Android图片色彩处理ColorMatrix
https://blog.csdn.net/qq_15128547/article/details/55261349
ColorMatrix 对比度 亮度 黑白 效果
https://blog.csdn.net/hnulwt/article/details/41848095?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

Android色彩特效处理之色调、饱和度、亮度、ColorMatrix精炼详解，，，，，重要，精彩！！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/weixin_41101173/article/details/80146504?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

亮度，饱和度，对比度的计算方法 重要，一句话说清楚

https://blog.csdn.net/gaowebber/article/details/79829962
颜色的RGB-计算HSV公式色度/饱和度/亮度 简化代码
https://blog.csdn.net/ChinarCSDN/article/details/81396045

图像编辑之对比度调整 亮度对比度的算法公式----PhotoShop 对比度计算方法,重要！！！！！！！！！！！！！！！！！
https://www.cnblogs.com/skiwnchiwns/p/10130833.html

nRGB = RGB + (RGB - Threshold) * Contrast / 255
(1)、nRGB = RGB + (RGB - Threshold) * Contrast / 255
    公式中，nRGB表示图像像素新的R、G、B分量，RGB表示图像像素R、G、B分量，Threshold为给定的阀值，Contrast为处理过的对比度增量。
    Photoshop对于对比度增量，是按给定值的正负分别处理的：
    当增量等于-255时，是图像对比度的下端极限，此时，图像RGB各分量都等于阀值，图像呈全灰色，灰度图上只有1条线，即阀值灰度；
    当增量大于-255且小于0时，直接用上面的公式计算图像像素各分量；
    当增量等于 255时，是图像对比度的上端极限，实际等于设置图像阀值，图像由最多八种颜色组成，灰度图上最多8条线，即红、黄、绿、青、蓝、紫及黑与白；
    当增量大于0且小于255时，则先按下面公式(2)处理增量，然后再按上面公式(1)计算对比度：
(2)、nContrast = 255 * 255 / (255 - Contrast) - 255
公式中的nContrast为处理后的对比度增量，Contrast为给定的对比度增量。

(3)图像亮度/对比度综合调整算法。这个很简单，当亮度、对比度同时调整时：
如果对比度大于0，先调整亮度，再调整对比度；
当对比度小于0时，则相反，先调整对比度，再调整亮度。

亮度对比度的联合计算算法公式
一副图像的亮度对比度调节属于图像的灰度线性变换，其公式如下: ----亮度、对比度统一变换公式：
y = [x - 127.5 * (1 - B)] * k + 127.5 * (1 + B);
x为调节前的像素值，y为调节后的像素值。
其中B取值[-1,1]，调节亮度；
k调节对比度，arctan(k)取值[1,89]，所以
k = tan( (45 + 44 * c) / 180 * pi );
其中c取值[-1,1]。通常我们用该值来设置对比度
特别的,
当B=0 时：y = (x - 127.5) * k + 127.5; 这时只调节对比度。
当c=0 时，k = 1：y = x + 255 * B; 这时只调节亮度。
当B=0 时：y = (x - 127.5) * k + 127.5; 这时只调节对比度。
当c=0 时，k = 1：y = x + 255 * B; 这时只调节亮度。

对比度：
Out = Average + (In – Average) * ( 1 + percent)
亮度 = fixed3 finalColor = texture.rgb * _Brightness
 
图像编辑之对比度调整 亮度对比度的算法公式：重要，综合调整。
https://www.cnblogs.com/skiwnchiwns/p/10130833.html

{ contrast, 0, 0, 0, 0,
  0,contrast, 0, 0, 0,// 改变对比度 
  0, 0, contrast, 0, 0,
  0, 0, 0, 1, 0 }
   
 1, 0, 0, 0, brightness, 
 0, 1, 0, 0, brightness,// 改变亮度  
 0, 0, 1, 0, brightness,
 0, 0, 0, 1, 0 }

求颜色的饱和度（纯度）的数学公式：
https://zhidao.baidu.com/question/553742131.html 
Y = 0.299 * r + 0.587 * g + 0.114 * b;
U = 0.1687* r - 0.3313* g + 0.5 * b + 128;
V = 0.5 * r - 0.4187*g - 0.0813*b + 128;
Y=亮度 U=色度 V=饱和度


【数字图像处理系列二】基本概念：亮度、对比度、饱和度、锐化、分辨率 ---重要，基础概念
https://blog.csdn.net/feilong_csdn/article/details/82755816?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

1、RGB空间图像亮度、对比度调节
对于数字图像变换，设原像素灰度为 f(i,j)，转化后的像素灰度为 g(i,j)，则常用的线性变换是 g(i,j)= af(i,j) + b， 其中系数 a 影响图像的对比度，系数 b 影响图像的亮度，具体如下：
(1) a=1时是原图；
(2) a>1时对比度增强，图像看起来更加清晰；
(3) a<1时对比度减弱，图像看起来变暗；
(4) b影响图像的亮度，随着增加b (b>0)和减小b (b>0)，图像整体的灰度值上移或者下移, 也就是图像整体变亮或者变暗, 不会改变图像的对比度
 
YUV与RGB互转各种公式 (YUV与RGB的转换公式有很多种，请注意区别！！！)--重要，YUV亮度转换
https://blog.csdn.net/xiaoyafang123/article/details/82153279
 
OpenCV 官网：
https://opencv.org/releases/
https://github.com/opencv/opencv/releases/tag/4.0.1

android 图像处理—锐化效果
https://blog.csdn.net/zb774095236/article/details/90667324
andrid图像处理系统1.3.0图像的直方图均衡
https://www.2cto.com/kf/201208/152039.html
使用颜色空间进行图像分割
http://www.360doc.com/content/18/1003/15/13328254_791618642.shtml
使用 Python 通过基于颜色的图像分割进行物体检测 
https://www.sohu.com/a/308099485_717210
RGB、YUV和HSV颜色空间模型
https://www.cnblogs.com/justkong/p/6570914.html
基于颜色信息的图像分割算法
https://blog.csdn.net/clannadxiaoxi/article/details/70169540?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

边缘检测在android上的小应用
https://blog.csdn.net/jliu200861/article/details/79486875

DIBR中对于模糊图像的基于分割的空洞填充算法
http://www.paper.edu.cn/releasepaper/content/4671295

基于直方图的图像增强算法（HE、CLAHE）之（二） 重要！！！！！！！！！！！
https://blog.csdn.net/baimafujinji/article/details/50660189
限制对比度自适应直方图均衡(CLAHE算法) 重要！！！！！！！！！！！
https://blog.csdn.net/grafx/article/details/53311915?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
[图像去雾]（一）限制对比度的自适应直方图均衡化(CLAHE)的学习体会——图像分块
https://blog.csdn.net/destinysjc93/article/details/52366597?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

/////////////
adb pull /sdcard/Android/data/com.zte.opengldemo/files/18332 .

//0313
cd /sdcard/Android/data/com.zte.opengldemo/files
rm -R 18335
adb pull /sdcard/Android/data/com.zte.opengldemo/files/18335 .

//0317
二值图像中封闭孔洞的高效填充算法（附源码）。!!!!!!!!!!!!!!!!图像博客
https://www.cnblogs.com/Imageshop/p/3308183.html
OPENCV二值化图像内孔洞填充/小区域去除！！！！！！！！！！！！！！！区域去除和填充
https://blog.csdn.net/liuuze5/article/details/77881390?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

Opencv图像识别从零到精通（24）------漫水填充，种子填充，区域生长、孔洞填充
https://blog.csdn.net/qq_20823641/article/details/52186629?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

opencv 一种不均匀光照的补偿方法
https://blog.csdn.net/hust_bochu_xuchao/article/details/54019994
针对光照不均匀图像处理
https://blog.csdn.net/qq_33183517/article/details/88982182?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
去除图像中光照不均匀
https://blog.csdn.net/FLY_CAFFE/article/details/84783012?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
【图像处理】一种低光照图像的亮度提升方法（Adaptive Local Tone Mapping Based on Retinex for High Dynamic Range Images）
https://blog.csdn.net/u013921430/article/details/84111247?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
低照度图像增强（附步骤及源码）
https://blog.csdn.net/grafx/article/details/53233508?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
Opencv图像识别从零到精通（24）------漫水填充，种子填充，区域生长、孔洞填充
https://blog.csdn.net/qq_20823641/article/details/52186629?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
OpenCv漫水填充floodFill详解-----------重要，使用方法详解！！！！！！！！！！
https://blog.csdn.net/weixin_42296411/article/details/80966724?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
//0318
opencv 删除二值化图像中面积较小的连通域
https://blog.csdn.net/lhs198541/article/details/6746715?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
二值图像连通区域标记法，两步法
https://blog.csdn.net/u010186001/article/details/54865829
matlab练习程序（二值图像连通区域标记法，一步法）
https://blog.csdn.net/greenapple_shan/article/details/44205193?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
A Fast Clustering Algorithm for Binary Image in Video Sequence%一种视频序列中二值图像的快速聚类算法
http://xueshu.baidu.com/usercenter/paper/show?paperid=8b580a5440b6def86b4b2373cd39002d
//0324
Java--填充替换数组元素、对数组进行排序、复制数组、数组查询
https://blog.csdn.net/qq_32823673/article/details/72417029?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

//0326

cd /sdcard/Android/data/com.zte.opengldemo/files
rm -R 18347
adb pull /sdcard/Android/data/com.zte.opengldemo/files/18347 .

//0330
虚化流程分析：
拍照场景,虚化基于OpenCV：
MainActivity.kt::onCreate:capture.setOnClickListener-->runnable = Runnable r -->camera.capture()
-->Camera.kt::capture()--> mSession.captureBurst(requests, captureCallback, null)--> init--> processImages()
  --> PortraitBokeh.capture(input, CAPTURE_SIZE.width, CAPTURE_SIZE.height, 90, output)
-->PortraitBokeh.java::native int capture(byte[] yuvIn, int w, int h, int r, byte[] yuvOut)
-->jni.cpp:: JNINativeMethod methods[]::{"capture", "([BIII[B)I", (void *) do_capture}-->static int do_capture(JNIEnv *env
-->PortratBokenPic.cpp::PortraitBokehPic::doPortraitBokeh(unsigned char *nv21ByteArray, int width, int height,
                                       int rotate, unsigned char *res)
-->PortraitBokehPicImpl::doPortraitBokeh(unsigned char *nv21ByteArray, int width, int height,
                                           int rotate, unsigned char *res) 
     mSplitter->doSegment(nv21ByteArray, width, height, rotate, mask);//分割
     backGroundHandle(nv21ByteArray, mask, width, height, size, size,
                     width / 2, height / 2, res, rotate);后处理
    -->backGroundHandle(const unsigned char *imgC_addr, unsigned char *imgD_addr, int widthC, int heightC,
                 int widthD, int heightD, int posx, int posy, unsigned char *imgRes_addr,
                 int rotate) {    
       bokeh.gaussBlurSelfAdaption2(maskFilted, imgCy, imgCuv);				 
-->BackgBokeh.cpp: void BackgBokeh::gaussBlurSelfAdaption2(Mat &imgM, Mat &imgCy, Mat &imgCuv) {//后处理流程。
    double startThis = now_ms()	
    GaussianBlur(uvDown, uvGauss, Size(7, 7), 0, 0);//高斯模糊
-->OpenCV-android-sdk\sdk\native\jni\include\opencv2\imgproc.hpp:imgproc.hpp
CV_EXPORTS_W void GaussianBlur( InputArray src, OutputArray dst, Size ksize,
                                double sigmaX, double sigmaY = 0,
                                int borderType = BORDER_DEFAULT ) //OPenCV高斯模糊实现
预览场景,虚化基于OpenGL：
流程0：
PortraitBokehPreviewImpl.cpp:PortraitBokehPreviewImpl 
    m_openGLThread = std::thread(std::bind(&PortraitBokehPreviewImpl::bokehViaOpenGL, this));
   -->bokehViaOpenGL()
       realTimeSingleStepDrawing(mask, inputData, width, height, m_outputData);//mask,width,height,虚化调用接口参数
-->bokehInterface.cpp:void realTimeSingleStepDrawing(void *m, unsigned char *imgC_addr, int widthC, int heightC,
                               unsigned char *imgRes_addr)
	     gpuBokeh.setPicAddr(imgC_addr, ((Mat *) m)->data, imgRes_addr);
		 -->this->imgCAddr = imgCAddr;//input data
            this->imgMAddr = imgMAddr;//mask
            this->imgResAddr = imgResAddr;//reslout image
        gpuBokeh.loadTexture();
        -->yuvTexture = loadTextureYuvFromRAM(); -->yData = imgCAddr;//input data
           mTexture = loadTextureYFromRAM();//yData = imgMAddr;        		   
-->GpuBokeh::draw2() //随后再仔细分析
    //虚化渲染
    bool horizontal = true, first_iteration = true;
    unsigned int amount = 2;
    for (unsigned int i = 0; i < amount; i++) {	
	
    shader = Shader(shaderVs, shaderFs);
    screenShader = Shader(screenShaderVs, screenShaderFs);	
		
流程1：
jni.cpp:: static int do_preview(JNIEnv *env, jclass clazz,
--> preview->doPortraitBokeh((unsigned char *) in, (unsigned char *) out, true);
-->PortraitBokehPreview::doPortraitBokeh(
-->PortraitBokehPreviewImpl::doPortraitBokeh(
    // do segment
	
	std::condition_variable m_ConVar_segment;
    std::condition_variable m_ConVar_opengl;
    std::condition_variable m_ConVar_output;
	
    m_ConVar_segment.notify_one();//分割
	// do bokeh 
    ...
    if (isOutputDataUpdated()) {
        readOutputData(output);
    }
--> memcpy(data, m_outputData, (size_t) (width * height * 3 / 2));
void PortraitBokehPreviewImpl::bokehViaOpenGL()	
   --> void *mask = readMaskData();
       realTimeSingleStepDrawing(mask, inputData, width, height, m_outputData);
	   
-->bokenInterface.cpp::realTimeSingleStepDrawing(mask, inputData, width, height, m_outputData);
	gpuBokeh.setPicAddr(imgC_addr, ((Mat *) m)->data, imgRes_addr);//将mask数据加载进去
    gpuBokeh.loadTexture();
    gpuBokeh.draw2();
    gpuBokeh.releaseTexture();
-->bool GpuBokeh::loadTexture() {
    yuvTexture = loadTextureYuvFromRAM();//原始图像加载进纹理
    mTexture = loadTextureYFromRAM();//mask加载进纹理
-->void GpuBokeh::draw2() {
核心操作：如何实现虚化效果的？？？	

流程2：	
PortraitBokehPreviewImpl::PortraitBokehPreviewImpl
m_segmentAndPorcessMaskThread = std::thread(//分割线程
            std::bind(&PortraitBokehPreviewImpl::segmentAndProcessMask, this));
-->			
void PortraitBokehPreviewImpl::segmentAndProcessMask()
//分割实际处理
mSplitter->doSegment(inputData, width, height, rotate, mask);
-->int SnpeSplitter::doSegment(unsigned char *input, int width, int height, int rotate,
                             unsigned char *mask) {
    std::unique_ptr<zdl::DlSystem::ITensor> inputTensor =
            loadYuvTensorFromByteArrayOpencv(snpe, input, width, height, rotate, imageMean,
                                             imageStd, isNv12);
    zdl::DlSystem::TensorMap outputTensorMap;

    {
        std::lock_guard<std::mutex> lockTmp(mutexExcute);
        LOGD("execute!");
        snpe->execute(inputTensor.get(), outputTensorMap);//SNPE分割处理
        LOGD("execute done!");
    }
//mask预处理？？？	
maskPretreat(inputData, mask, width, height, snpe_input_size, snpe_input_size,
                     width / 2, height / 2, rotate, maskMat);	
-->重要，mask的后处理操作，可借鉴：
Mat MaskFilter::maskPretreat(Mat &mask, Point &relaPos, int boxFilterWs)
 //阶梯化并反色
    Mat mMultiSc;
    multiLayer(m, mMultiSc, 14 - 1);
    m = mMultiSc;
	

					 
//0331
Android利用OpenGL实现高斯模糊
https://www.jianshu.com/p/5c61a11188c9

Android OpenGL ES从白痴到入门系列
https://www.jianshu.com/u/3ffae4524139
Android OpenGL ES从白痴到入门(一):概念
https://www.jianshu.com/p/5401df2ee0ae
ndroid OpenGL ES从白痴到入门(二):App诞生
https://www.jianshu.com/p/5b9556c9237f
Android OpenGL ES从白痴到入门(三):引入EGL
https://www.jianshu.com/p/9db986365cda
Android OpenGL ES从白痴到入门(四):离屏渲染(Pbuffer)
https://www.jianshu.com/p/8793f0fbd1e6
https://www.jianshu.com/p/5c61a11188c9
Android OpenGL ES从白痴到入门(五):妖艳的着色器
https://www.jianshu.com/p/ce20f98e20cf

OpenGL ES 框架详细解析（八） —— OpenGL ES 设计指南
https://www.jianshu.com/p/456c961164d9
OpenGL ES 框架详细解析（十三） —— Xcode OpenGL ES工具概述
https://www.jianshu.com/p/36f7796cc978

//0401
2020-04-01 09:44:27*[林俊萱10048596]说:
http://a22741041-2:8080/
账号:zdm 密码：12345678

[OpenGL] 屏幕后处理：景深效果
https://blog.csdn.net/ZJU_fish1996/article/details/82952866
【OpenGL编程】虚化模糊场景（类似摄像机的人像效果）
https://blog.csdn.net/modestbean/article/details/79512208
GPU图像处理的基本流程
https://blog.csdn.net/Evankaka/article/details/38177999?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task
Android GLSurfaceView模糊效果
https://blog.csdn.net/java_pengjin/article/details/95196282?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task

//0402
Qualcomm CreatePoint Tool Suite Release Update Notification for:Snapdragon_NPE_SDK.LA.1.0 Installer 00102.1
http://createpoint.qti.qualcomm.com/tools/link/suite/201/46323

在Android上使用OpenCL调用GPU加速
https://blog.csdn.net/dj0379/article/details/39484061
初试Android高性能编程OpenCL
https://blog.csdn.net/sephyioth/article/details/89360916
Android 7.0及以上使用OpenCL
https://www.cnblogs.com/willhua/p/9909063.html
Opencl与Android集成
http://www.cocoachina.com/articles/102653
OpenCL学习入门
https://www.jianshu.com/p/7a48ae330e35
从零开始学习OpenCL开发（一）架构
https://www.xuebuyuan.com/3266068.html
OpenCL快速入门教程-----重要参考：
https://www.csdn.net/article/a/2013-05-29/15815411
OpenCL 2.0 规范 – SVM共享虚拟内存
https://www.cnblogs.com/lifan3a/articles/4613858.html
OpenCL2.0特性之SVM
https://blog.csdn.net/tommy_wxie/article/details/52217993
编译并使用带有OpenCL模块的OpenCV for android SDK
https://blog.csdn.net/weixin_34185364/article/details/85745521?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.nonecase
Opencv4Android的OpenCL的测试，使用Opencv的ocl封装库
https://blog.csdn.net/wjskeepmaking/article/details/70187885?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-9

毕业5年，我问遍了身边的大佬，总结了他们的学习方法
https://blog.csdn.net/qq_35190492/article/details/103847147?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-56.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-56.nonecase


CMAKE简单入门
https://blog.csdn.net/yjj546542806/article/details/78461555
OpenCL编程入门（一）
https://blog.csdn.net/lychee_ee/article/details/40783583

OpenCL学习资料合辑包括OpenCL编程指南,OpenCL中文教程(AMD),OpenCL编程入门
https://download.csdn.net/download/zhanggangbz2/8928503

全网第一个c++版本的opencl编程详解（gpu编程）
https://blog.csdn.net/brucexiajun/article/details/100895127

OpenCL使用GPU滤波
https://blog.csdn.net/augusdi/article/details/9469953

//0403
Android jni 二维数组 传递
https://www.cnblogs.com/Free-Thinker/p/6829210.html
android - JNI - 一维数组、二维数组的访问与使用
https://www.cnblogs.com/qianheng/p/12203049.html

//0407
C++中用二维数组传参时形参该怎样写 [转]
https://www.cnblogs.com/longdouhzt/archive/2012/04/22/2465399.html 
template <typename T,int M, int N>
void func(T (&a)[M][N]);

[C语言]二维数组传参的格式(详细+总结)
https://blog.csdn.net/qq_43868654/article/details/84641383
C/C++语言 二维数组作为函数的参数总结---总结全面
https://blog.csdn.net/lizi_stdio/article/details/74502986

C++用new创建二维数组的方法
https://blog.csdn.net/yuqinjh/article/details/79095787
C++二维数组new小结(zz)--------------重要参考：
https://www.cnblogs.com/beyondstorm/archive/2008/08/26/1276278.html 工程实现参考！！！！
https://www.cnblogs.com/zyqy/p/10951716.html

/////////////////////////////////////////////////////////
//0409
C++中set用法详解-------------重要参考：
https://www.cnblogs.com/caiyishuai/p/8646345.html
深入了解STL中set与hash_set，hash表基础-------------重要参考：工程代码实现
https://www.cnblogs.com/CheeseZH/p/5176970.html

git pull --rebase origin dev
git commit -m "update fill hole native utils and test code" 
git push origin dev:refs/for/dev

//0410
OpenCL快速入门教程
https://www.csdn.net/article/a/2013-05-29/15815411

//0415
贴图层OpenGL——glUniform1i 用法
https://blog.csdn.net/linuxheik/article/details/78906568
OpenGLES入门(三)与着色器交互
https://www.jianshu.com/p/64692105ca6f
OpenGL ES之glUniform函数 
https://www.cnblogs.com/Anita9002/p/4930341.html

//0416
Opengl es2.0 学习笔记（四）shader语法 GLSL
https://www.cnblogs.com/hiwoshixiaoyu/p/10034909.html
传递数组到 Shader
https://blog.csdn.net/wenzhilu/article/details/51894501?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2&utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2
从0开始的OpenGL学习（五）-纹理
https://www.jianshu.com/p/1b327789220d

Android利用OpenGL实现高斯模糊 高斯模糊参考
https://www.jianshu.com/p/5c61a11188c9

OpenGL 之 FBO--视频美颜的基础
https://www.jianshu.com/p/c16c7e7cdf91

//0418
LearnOpenGL学习笔记（六）——纹理单元
https://www.wandouip.com/t5i217621/
OpenGLES入门(三)与着色器交互
https://www.jianshu.com/p/64692105ca6f
//0420
opengl fbo离屏渲染，处理Android截屏卡顿太久。
https://blog.csdn.net/SXH_Android/article/details/78835966?utm_source=blogxgwz9
Android OpenGLES2.0（十二）——FBO离屏渲染
https://www.jianshu.com/p/6cda1102df51
OpenGLES 之 显示图片（四）
https://www.jianshu.com/p/480ff0be7900

//
0422
snpe-dlc-info -i quantize_mnv3_641_481_0225_resizebilinear_2_dsp.dlc -s quantize_mnv3_641_481_0225_resizebilinear_2_dsp.csv -m
snpe-dlc-info -i no_opt_quantize_mnv3_641_481_resizebilinear_2_dsp_quantized.dlc -s no_opt_quantize_mnv3_641_481_resizebilinear_2_dsp_quantized.csv -m
no_opt_quantize_mnv3_641_481_resizebilinear_2_dsp_quantized

//
0423
//0326

cd /sdcard/Android/data/com.zte.opengldemo/files
rm -R 18375
adb pull /sdcard/Android/data/com.zte.opengldemo/files/18375 .

adb  pull data/local/vendor_logs .

Android利用OpenGL实现高斯模糊 高斯模糊参考
https://www.jianshu.com/p/5c61a11188c9

OpenGL 之 FBO--视频美颜的基础
https://www.jianshu.com/p/c16c7e7cdf91

Android OpenGLES2.0（十二）——FBO离屏渲染
https://www.jianshu.com/p/6cda1102df51

OpenGL 图形库的使用（二十五）—— 高级OpenGL之帧缓冲Framebuffers---仔细看！！！
https://www.jianshu.com/p/d7066d6a02cc

penGL启用双缓冲时颜色变淡或者不纯的解法方法
https://blog.csdn.net/niusiqiang/article/details/43116213

Android OpenGL ES （十）FrameBuffer离屏渲染 ---------重要！！！！！！！！！！
https://blog.csdn.net/suyimin2010/article/details/98885940

Android OpenGL ES 开发教程(23)：FrameBuffer
https://blog.csdn.net/lyunabc/article/details/84228118

//0427

git commit  app/jni/FillHole.cpp --amend 
git pull --rebase origin dev
git commit -m "update fill hole native utils and test code" 
git commit -m "update guassian blur implementation code" 
git push origin dev:refs/for/dev
http://10.95.243.146:8080/c/AI/CV/Demo/+/135027

//0428
双线性插值算法的详细总结
https://blog.csdn.net/xjz18298268521/article/details/51220576

//0429
snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0423.dlc --allow_unconsumed_nodes
snpe-dlc-info -i quantize_mnv3_mini_641_481_0423.dlc -s quantize_mnv3_mini_641_481_0423.csv
snpe-dlc-viewer -i quantize_mnv3_mini_641_481_0423.dlc -s quantize_mnv3_mini_641_481_0423.html
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0423.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0423_dsp.dlc
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0423.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0423_dsp.dlc --enable_hta --hta_partitions 0-75,76-76

tflite_convert \
  --output_file=quantize_mnv3_mini_641_481_0423_range.tflite \
  --graph_def_file=quantize_mnv3_mini_641_481_0423.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=6 \
  --change_concat_input_ranges=true
  
//0506
环境变量设置：
source bin/envsetup.sh -t $TENSORFLOW_DIR

全自动模型转换、输入数据准备、量化：
python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r dsp
python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r aip

SNPE 138环境搭建：
./connect_internet.sh -u 10087295
conda create --name snpe138_tf14 python=3.5
conda remove -n snpe_1_21 --all 
conda search --full-name tensorflow
https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow/
G:\我的文档\定制需求\2_AI\Spring2020\spring2020_0218\SNPE\tensorflow-1.14.0-cp35\tensorflow-1.14.0rc1-cp35-cp35m-manylinux1_x86_64.whl  

grpcio-1.28.1
conda search --full-name grpcio
import tensorflow as tf
tf.__version__
'1.6.0'
tf.__path__
/home/zhangdm/anaconda3/envs/snpe138_tf14/lib/python3.5/site-packages/tensorflow
conda search --full-name Pillow
pillow                    5.2.0  py35heded4f4_0  pkgs/main

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0506.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0506.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0506_138_dsp.dlc
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0506.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0506_138_aip.dlc --enable_hta --hta_partitions 0-75

//0507
snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0506.dlc --allow_unconsumed_nodes
snpe-dlc-info -i quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp.dlc -s quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp.csv 
snpe-dlc-info -i quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp_quantized.dlc -s quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp_quantized.csv 

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0507.dlc --allow_unconsumed_nodes --input_type  "sub_2" image  --input_encoding "sub_2" rgb
snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0507_opaque.dlc --allow_unconsumed_nodes --input_type  "sub_2" opaque 

tflite_convert \
  --output_file=quantize_mnv3_mini_641_481_0423_resizebilinear_2_gpu.tflite \
  --graph_def_file=quantize_mnv3_mini_641_481_0423.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2"
  
//0508
OpenCL-SVM（共享虚拟内存）实验
https://blog.csdn.net/KayChanGEEK/article/details/78914991  

//0511
PB推理计算：
2020-05-08 10:32:05 朱燕00111288 对 张冬明10087295 说：
http://10.63.228.28:8888/notebooks/zhuyan/research_191108/deeplab/deeplab_demo_zte.ipynb

MIOU计算：
http://10.63.228.28:8888
(账户:10005358)--不用填写
密码:AI+2018

http://10.63.228.28:8888/edit/zhuyan/research_191108/deeplab/eval.py
2020-05-11 09:24:46*[朱燕00111288]说:
predictions = prediction[common.OUTPUT_TYPE]
从这一行开始
2020-05-11 09:24:56*[朱燕00111288]说:
predictions 就是mask
2020-05-11 09:25:03*[朱燕00111288]说:
下面就是开始计算

图像分割的衡量指标详解 ---已读
https://blog.csdn.net/qq_37274615/article/details/78957962
论文笔记 |　基于深度学习的图像语义分割技术概述之5.1度量标准
https://blog.csdn.net/u014593748/article/details/71698246

深度学习计算机视觉图像分割领域指标mIoU（平均交并比）计算代码与逐行解析 -------重要，Python，mIOU Python github代码，已读
https://blog.csdn.net/jiongnima/article/details/84750819
github计算代码：https://github.com/wasidennis/AdaptSegNet/blob/master/compute_iou.py
参考：numpy.bincount详解
https://blog.csdn.net/xlinsist/article/details/51346523?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase

语义分割评价指标--mIOU-------重要，mIOU Python github代码，已读
https://zhuanlan.zhihu.com/p/88805121
github计算代码：https://github.com/dilligencer-zrj/code_zoo/tree/master
https://github.com/dilligencer-zrj/code_zoo/blob/master/compute_mIOU

语义分割的评价指标——IoU -------重要，python简化计算公式
https://blog.csdn.net/lingzhou33/article/details/87901365

//0512
TF,GPU,641X481:85.796585%, alpha=0x0F:85.796585%, alpha=0x7F:85.34117%, alpha=0xFF:84.91859%
TF,DSP,641X481:85.796585%, alpha=0x0F:49.094585%, alpha=0x7F:47.895973%, alpha=0xFF:46.597733%
TF,GPU,481X361:84.37939%, alpha=0x0F:85.796585%, alpha=0x7F:85.34117%, alpha=0xFF:84.91859%
SNPE,GPU,641X481:85.13832%, alpha=0x0F:86.01251%, alpha=0x7F:85.718376%, alpha=0xFF:85.13832%
SNPE,DSP,641X481:83.855574%, alpha=0x0F:85.11164%, alpha=0x7F:84.59145%, alpha=0xFF:83.85574%

//0513
一、以手动标记的200张mask图像为参考答案，计算各模型与手工标记的mIOU分值，衡量各模型与手工标记的损失：
TF PB,电脑,641X481:87.21833%
TF Lite,GPU,641X481:85.796585%
TF Lite,DSP,641X481:49.094585% 
TF Lite,GPU,481X361:84.37939%
SNPE,GPU,641X481:86.01251%
SNPE,DSP,641X481:85.14611%

二、以电脑端pb模型推理出的200张mask图像为参考答案，计算各模型相对于pb模型的mIOU分值，衡量各模型与pb的损失：
TF Lite,GPU,641X481:92.28958%
TF Lite,DSP,641X481:50.598137% 
TF Lite,GPU,481X361:87.19731%
SNPE,GPU,641X481:92.43392%
SNPE,DSP,641X481:91.47195%

//0514
git clone "ssh://10087295@10.95.243.146:29418/AI/CV/VideoSegmentation" && scp -p -P 29418 10087295@10.95.243.146:hooks/commit-msg "VideoSegmentation/.git/hooks/"

git pull --rebase origin dev
git commit -m "update fill hole native utils and test code" 
git push origin dev:refs/for/dev

//0518
颜色连通域
http://cprs.patentstar.com.cn/Search/Detail?ANE=7FAA0AAA9GDB9BIH9EGC7CFA9FCF9GBB9CDDAGCA9IBF9EAC

从 RGB 到 HSV 的转换详细介绍
https://blog.csdn.net/hanshanbuleng/article/details/80383813?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase
Grey = 0.299*R + 0.587*G + 0.114*B
//0522
1-0f-->1-0.5f;
0.5f*ratio +0.5f;

//0522
opencv人体识别技术汇总
https://blog.csdn.net/cnbloger/article/details/77954251
OPENCV人形查找
https://blog.csdn.net/cnbloger/article/details/77987181?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-1
OPENCV图像轮廓检测
https://www.cnblogs.com/dengxiaojun/p/5252294.html
Python Opencv实现图像轮廓识别功能
https://www.jb51.net/article/160484.htm

opencv主动轮廓模型
https://blog.csdn.net/qq_18454025/article/details/84037942
scikit-image库-- 主动轮廓模型（十六）
https://blog.csdn.net/weixin_38632246/article/details/99694934?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-3
Active Contour Models 主动轮廓模型概述
https://blog.csdn.net/hustrains/article/details/9160813?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-1

主动轮廓模型----重要，包括水平集！！！！！！
https://blog.csdn.net/weixin_40054912/article/details/82658934?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase

OpenCV3】图像轮廓查找与绘制——cv::findContours()与cv::drawContours()详解----重要，如何查找和绘制轮廓！！！！！
https://blog.csdn.net/guduruyu/article/details/69220296?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-9.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-9.nonecase
【OpenCV3】图像最大轮廓检测——cvFindBiggestContour()封装----重要，如何查找和绘制轮廓！！！！！
https://blog.csdn.net/guduruyu/article/details/80056322

Python-OpenCV 处理图像（五）：图像中边界和轮廓检测
https://blog.csdn.net/tony2278/article/details/85231210?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-3
Python-OpenCV 处理图像（五）：图像中边界和轮廓检测
https://blog.csdn.net/qq_26898461/article/details/50454547----重要，如何查找和绘制轮廓！！！！！

【OpenCV入门指南】第五篇 轮廓检测 上
https://blog.csdn.net/qq_26898461/article/details/50454547

主动轮廓模型-水平集方法----重要，如何理解水平集！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/a553654745/article/details/44002367
图像分割之（五）活动轮廓模型之Snake模型简介---重要，如何理解水平集！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/zouxy09/article/details/8712287
基于区域特征的水平集方法——CV模型
https://download.csdn.net/download/u010934308/5505785?utm_medium=distribute.pc_relevant.none-task-download-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-download-BlogCommendFromMachineLearnPai2-1.nonecase
水平集（CV模型）---重要，如何理解水平集！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/u011460059/article/details/59538983
水平集图像分割序列——CV模型--重要，水平集分割Pytho实现
https://blog.csdn.net/hit1524468/article/details/79682837?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase
水平集图像分割序列——LBF模型
https://blog.csdn.net/hit1524468/article/details/79705819?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase
求助] 水平集图像分割方法的CV模型推导
http://muchong.com/t-8349293-1-authorid-1858976


---重要，如下三篇如何理解水平集和计算水平集！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
水平集详解与代码分析一
https://blog.csdn.net/a553654745/article/details/45481509
水平集详解与代码分析二
https://blog.csdn.net/a553654745/article/details/45500803?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-10.nonecase
主动轮廓模型-水平集方法
https://blog.csdn.net/a553654745/article/details/44002367

图像分割之（五）活动轮廓模型之Snake模型简介---经典，透彻、详细说清楚了主动轮廓模型的含义
https://blog.csdn.net/zouxy09/article/details/8712287

h:
Python--level set （水平集）和 chan-vese模型
https://blog.csdn.net/qq_38784098/article/details/82144106
计算机视觉之图像分割——水平集方法_ACWE2001
https://blog.csdn.net/VictoriaW/article/details/60966232
其github：
https://github.com/VictoriaW1/ACWE

RGB到HSI转换
https://blog.csdn.net/shaozidianqiu/article/details/53079763

//0525
基于颜色的区域增长分割 Color-based region growing segmentation
https://blog.csdn.net/renyuanxingxing/article/details/84661564
PCL学习：点云分割-基于颜色的区域生长分割
https://blog.csdn.net/zfjBIT/article/details/95070413?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase
基于区域生长的彩色图像分割
https://download.csdn.net/download/longmentulong/4871790
色差计算(颜色之间的相似度计算)----重要！！！！！,有LAB空间基于RGB的近似计算公式！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/qq_16564093/article/details/80698479?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase
HSV和HSI区别
https://www.cnblogs.com/2018shawn/p/10616854.html
HSV与HSI颜色空间的区别以及和RGB之间的转换----重要！！！！！
https://blog.csdn.net/weixin_42150026/article/details/92398143
RGB、HSV、HSI颜色空间----重要！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/Osean_li/article/details/95028698?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase

一种新的颜色相似度定义及其计算方法（作者郑斯彬）
https://blog.csdn.net/longkey_zsb/article/details/55000468?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase
最新改进：一种新的颜色相似度算法的具体实现（作者：郑斯彬，C#2005）
https://blog.csdn.net/longkey_zsb/article/details/89211622
CIELAB色差计算----重要！！！！！！！！
https://blog.csdn.net/lanmengyiyu/article/details/80374211?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase

一种基于皮肤颜色区域分割和机器学习算法相融合的手势识别方法及其应用---专利全文，肤色检测
https://www.ixueshu.com/document/a8b9855222fc772c172d50dce697640d318947a18e7f9386.html
论文检索网站：
https://www.ixueshu.com/search/index.html?search_type=&q=%E9%A2%9C%E8%89%B2%E5%8C%BA%E5%9F%9F%E5%88%86%E5%89%B2

融合颜色和区域信息的彩色图像分割新方法
https://www.ixueshu.com/document/4da86022a3a979422cfc8a17ea7aa1ed318947a18e7f9386.html

///////////////////////////////////////////////////////////////////////////////
重要：区域分割系列文章：总览
https://www.ixueshu.com/document/4da86022a3a979422cfc8a17ea7aa1ed318947a18e7f9386.html

【待读】融合颜色和区域信息的彩色图像分割新方法：
https://www.ixueshu.com/download/4da86022a3a979422cfc8a17ea7aa1ed318947a18e7f9386.html

均值漂移（Meanshift）算法--均值漂移算法的CSDN说明
https://blog.csdn.net/qwerasdf_1_2/article/details/54577336
OpenCV之均值漂移(Mean Shift)算法
https://blog.csdn.net/qq_23968185/article/details/51804574?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-3
基于MeanShift的目标跟踪算法及实现----上篇参考文献
https://blog.csdn.net/jinshengtao/article/details/30258833
机器学习算法原理与实践（二）、meanshift算法图解以及在图像聚类、目标跟踪中的应用-----重要，说明了概要图！！！！！
https://blog.csdn.net/llp1992/article/details/44679185?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase
Meanshift，聚类算法-------重要，推导过程！！！！！！！！！！
https://www.cnblogs.com/liqizhou/archive/2012/05/12/2497220.html

mean shift 图像分割（一、二、三）重要！！！！！MS图像分割
https://blog.csdn.net/u011511601/article/details/72843247?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase

//0526

0507 dlc tranform
snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0506.dlc --allow_unconsumed_nodes
snpe-dlc-info -i quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp.dlc -s quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp.csv 
snpe-dlc-info -i quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp_quantized.dlc -s quantize_mnv3_mini_641_481_0423_resizebilinear_2_dsp_quantized.csv 

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0507.dlc --allow_unconsumed_nodes --input_type  "sub_2" image  --input_encoding "sub_2" rgb
snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0423.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0507_opaque.dlc --allow_unconsumed_nodes --input_type  "sub_2" opaque 

0526

source bin/envsetup.sh -t $TENSORFLOW_DIR

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0526.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0526.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0526.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0526_138_dsp.dlc

85.14611%%,86.749214%%
未加入训练的1000张测试图片测试结果：
上面200张测试集图片确认已加入训练集，指标不大可信，以下是未加入训练的1000张测试图片测试结果：
OpenCV颜色空间——Luv颜色空间:

//0530
高斯滤波及高斯卷积核C++实现
https://blog.csdn.net/dcrmg/article/details/52304446
radius=4,sigma=1.0,result=0.39910322,0.24200355,0.053998288,0.004393151,5.3412234E-5,total=1.0

radius=9,sigma=20.0,result=0.07608185,0.06848635,0.06823,0.067804895,0.06721419,0.059027158,0.050748706,0.04245832,0.034234527,0.0037549194,total=1.0

git pull --rebase origin dev
git commit -m "update edge blur smooth algorithm by opengl shader" 
git push origin dev:refs/for/dev


0601
source bin/envsetup.sh -t $TENSORFLOW_DIR

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0601.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0601_138_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0601_138_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0601_138_dsp.dlc

OPENCL 操作：

CPU中读取到GPU中：
/** write tensor from cpu to gpu */
err = clEnqueueWriteBuffer(aiQueue, tensor2x_bufferIn, CL_TRUE, 0,
                               TENSOR2X_BUF_IN_SIZE, pInTensor, 0, NULL, NULL);

另一种方式，直接在createBuffer时直接传入：
cl_mem src_a_d = clCreateBuffer(context,
CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, mem_size, src_a_h, &error);
							   
GPU中读到CPU:  
/** read tensor from gpu to cpu */
err = clEnqueueReadBuffer(aiQueue, x2tensor_bufferOut, CL_TRUE, 0,
                              X2TENSOR_BUF_OUT_SIZE, pOutTensor, 0, NULL, NULL);
释放操作：
if (NULL != program) clReleaseProgram(program);
if (NULL != aiQueue) clReleaseCommandQueue(aiQueue);
if (NULL != aiContext) clReleaseContext(aiContext);
	
clReleaseKernel(vector_add_k);
//clReleaseCommandQueue(queue);
//clReleaseContext(context);
clReleaseMemObject(src_b_d);
clReleaseMemObject(res_d);							  
	
//0603
quantize_mnv3_mini_641_481_0601_138_gpu_lll

source bin/envsetup.sh -t $TENSORFLOW_DIR

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0603.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0603_138_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0603_138_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0603_138_dsp.dlc

//0604
灰度化、二值化、膨胀算法、腐蚀算法以及开运算和闭运算
https://blog.csdn.net/li_wen01/article/details/72867057

/0605
quantize_mnv3_mini_641_481_0601_138_gpu_lll

source bin/envsetup.sh -t $TENSORFLOW_DIR

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0605.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0605_138_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0605_138_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0605_138_dsp.dlc

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0605_2.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0605_2_138_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0605_2_138_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0605_2_138_dsp.dlc

//0606
YUV与RGB互转各种公式 (YUV与RGB的转换公式有很多种，请注意区别！！！)
https://blog.csdn.net/xiaoyafang123/article/details/82153279

//0610
git commit -m "modify back camera blur radius" 
git push origin dev:refs/for/dev

【OpenCV】Meanshift图像分割---参考价值较高，直接用openCV分割图像
https://blog.csdn.net/iefenghao/article/details/88871301?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase
OpenCV之meanshift分割详解--API使用说明和效果演示
https://blog.csdn.net/laobai1015/article/details/76400739?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase

MeanShift用于彩色图像分割（OpenCV）
https://blog.csdn.net/guoyunfei20/article/details/78729490?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.nonecase

均值漂移迭代公式：重要！！！！！
mean shift 图像分割（二）
https://blog.csdn.net/ttransposition/article/details/38514271

均值漂移OpenCV实现过程具体来实现图像分割的过程：重要！！！！！
OpenCV之meanshift分割详解
https://blog.csdn.net/laobai1015/article/details/76400739?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase

mean--shift 图像分割的理解整理----重要！！！！！
https://blog.csdn.net/qq_34622997/article/details/77838328?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.nonecase

//0612
snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0612.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0612_138_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0612_138_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quantize_mnv3_mini_641_481_0612_138_dsp.dlc

LUV色彩空间介绍及从RGB到LUV的转换
https://blog.csdn.net/kit_147/article/details/5485470?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase

用c++实现颜色空间rgb，grey，luv和lab的互转---重要，有RGB转LUV具体实现代码
http://blog.sina.com.cn/s/blog_5309cefc0101cdeg.html
LUV色彩空间全称CIE 1976(L*,u*,v*)（也作CIELUV）色彩空间，L*表示物体亮度，u*和v*是色度。
于1976年由国际照明委员会(International Commission on Illumination)提出，由CIE XYZ空间经简单变换得到，具视觉统一性。
类似的色彩空间有CIELAB。对于一般的图像，u*和v*的取值范围为-100到+100，亮度为0到100。

double L, u, v;
  double R = ((double) rgb[0]) / (double)255.0;
  double G = ((double) rgb[1]) / (double)255.0;
  double B = ((double) rgb[2]) / (double)255.0;
  double x = (double)0.412453 * R + (double)0.357580 * G + (double)0.180423 * B;
  double y = (double)0.212671 * R + (double)0.715160 * G + (double)0.072169 * B;
  double z = (double)0.019334 * R + (double)0.119193 * G + (double)0.950227 * B;

  if (y > 0.008856) {
   L = (double)116.0 * pow(y, (double)1.0 / (double)3.0) - (double)16.0;
  }
  else {
   L = (double)903.3 * y;
  }

  double sum = x + 15 * y + 3 * z;
  if (sum != 0) {
   u = 4 * x / sum, v = 9 * y / sum;
  }
  else {
   u = 4.0, v = (double)9.0 / (double)15.0;
  }

  luv[0] = L;
  luv[1] = 13 * L * (u - (double)0.19784977571475);
  luv[2] = 13 * L * (v - (double)0.46834507665248);

//0617

snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0617.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0617_138_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0617_138_gpu.dlc --optimizations cle bc --override_params --bias_bitwidth 32  --output_dlc quantize_mnv3_mini_641_481_0612_138_dsp.dlc  --input_list  ../../data/cropped/raw_list.txt

snpe-tensorflow-to-dlc --input_network quan_opt_mnv3_0526_0.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quan_opt_mnv3_0526_0.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_0.dlc  --optimizations cle bc --override_params --bias_bitwidth 32 --output_dlc quan_opt_mnv3_0526_0_dsp.dlc --input_list  ../../data/cropped/raw_list.txt

snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_0.dlc  --override_params  --output_dlc quan_opt_mnv3_0526_0_dsp_zy.dlc --input_list  ../../data/cropped/raw_list.txt

//0618
snpe-tensorflow-to-dlc --input_network quantize_mnv3_mini_641_481_0617.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quantize_mnv3_mini_641_481_0617_138_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quantize_mnv3_mini_641_481_0617_138_gpu.dlc  --override_params  --output_dlc quantize_mnv3_mini_641_481_0617_138_dsp_zy.dlc --input_list  ../../data/cropped/raw_list.txt

/lll  
snpe-tensorflow-to-dlc --input_network frozen_inference_graph_0618_342528.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_0618_342528_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_0618_342528_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc frozen_inference_graph_0618_342528_dsp.dlc

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_0618_330381.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_0618_330381_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_0618_330381_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc frozen_inference_graph_0618_330381_dsp.dlc


snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_0.dlc  --override_params --bias_bitwidth 32 --output_dlc quan_opt_mnv3_0526_0_dsp.dlc --input_list  ../../data/cropped/raw_list.txt

snpe-tensorflow-to-dlc --input_network quan_opt_mnv3_0526_0.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quan_opt_mnv3_0526_0_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_0_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quan_opt_mnv3_0526_0_have_list_dsp.dlc
snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_0_gpu.dlc --override_params --bias_bitwidth 32 --input_list  ../../data/cropped/raw_list.txt --output_dlc quan_opt_mnv3_0526_0_override_dsp.dlc

snpe-dlc-viewer -i quan_opt_mnv3_0526_0_have_list_dsp.dlc -s quan_opt_mnv3_0526_0_have_list_dsp.html
  
//0619
snpe-tensorflow-to-dlc --input_network quan_opt_mnv3_0526_0.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quan_opt_mnv3_0526_0_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_0_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc quan_opt_mnv3_0526_0_dsp.dlc 
snpe-dlc-viewer -i quan_opt_mnv3_0526_0_dsp.dlc -s quan_opt_mnv3_0526_0_dsp_input_list.html

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_0619_376234.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_0619_376234_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_0619_376234_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc frozen_inference_graph_0619_376234_dsp.dlc

zy:
snpe-tensorflow-to-dlc --input_network quan_opt_mnv3_0526_2_zy.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quan_opt_mnv3_0526_2_zy_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_2_zy_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc quan_opt_mnv3_0526_2_zy_dsp.dlc
snpe-dlc-viewer -i quan_opt_mnv3_0526_2_zy_dsp.dlc -s quan_opt_mnv3_0526_2_zy_dsp.html

//0620
Buffer（ByteBuffer）以及flip,clear及rewind区别
https://blog.csdn.net/qq_24236769/article/details/77127069
多线程--LinkedBlockingQueue的put,add跟offer的区别
https://blog.csdn.net/stalin_/article/details/80451617
ConcurrentLinkedQueue使用和方法介绍
https://www.cnblogs.com/yangzhenlong/p/8359875.html
图解ByteBuffer
https://www.cnblogs.com/ruber/p/6857159.html
阻塞队列之LinkedBlockingQueue
https://www.cnblogs.com/duodushuduokanbao/p/9556555.html


//0622
snpe-tensorflow-to-dlc --input_network frozen_inference_graph_0622_277874.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_0622_277874_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_0622_277874_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc frozen_inference_graph_0622_277874_dsp.dlc

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_0622_369854.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_0622_369854_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_0622_369854_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc frozen_inference_graph_0622_369854_dsp.dlc

//0624

python $SNPE_ROOT/models/mn_v3/scripts/setup_mnv3.py  -r dsp

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_481_361_0622_372755.pb --input_dim sub_2 "1,481,361,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_481_361_0622_372755_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_481_361_0622_372755_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc frozen_inference_graph_481_361_0622_372755_dsp.dlc

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_481_361_0622_341914.pb --input_dim sub_2 "1,481,361,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_481_361_0622_341914_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_481_361_0622_341914_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --output_dlc frozen_inference_graph_481_361_0622_341914_dsp.dlc

//0628
snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_0628.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_frozen_inference_graph_0628_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_0628_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc optimized_frozen_inference_graph_0628_dsp.dlc
snpe-dlc-viewer -i optimized_frozen_inference_graph_0628_dsp.dlc -s optimized_frozen_inference_graph_0628_dsp.html

snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_481_361_0622_372755.pb --input_dim sub_2 "1,481,361,3" --out_node "ResizeBilinear_2" --output_path optimized_frozen_inference_graph_481_361_0622_372755_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_481_361_0622_372755_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc optimized_frozen_inference_graph_481_361_0622_372755_dsp.dlc


snpe-tensorflow-to-dlc --input_network quan_opt_mnv3_0526_2.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path quan_opt_mnv3_0526_2_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc quan_opt_mnv3_0526_2_gpu.dlc --input_list  ../../data/cropped/raw_list.txt  --output_dlc quan_opt_mnv3_0526_2_dsp_nover.dlc
snpe-dlc-viewer -i quan_opt_mnv3_0526_2_dsp.dlc -s quan_opt_mnv3_0526_2_dsp.html

//0701
snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_0701_388156.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_frozen_inference_graph_0701_388156_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_0701_388156_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc optimized_frozen_inference_graph_0701_388156_dsp.dlc

snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_0701_397143.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_frozen_inference_graph_0701_397143_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_0701_397143_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc optimized_frozen_inference_graph_0701_397143_dsp.dlc

//0702
snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_0628_train.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_frozen_inference_graph_0628_train_gpu.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_0628_train_gpu.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc optimized_frozen_inference_graph_0628_train_dsp.dlc
snpe-dlc-viewer -i optimized_frozen_inference_graph_0628_train_dsp.dlc -s optimized_frozen_inference_graph_0628_train_dsp.html
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_0628_train_gpu.dlc --input_list  ../../data/cropped/raw_list.txt  --output_dlc optimized_frozen_inference_graph_0628_train_dsp_nover.dlc

//0703
adb pull /sdcard/Android/data/com.zte.videosegmentation/files/Nv21ToGaussianBlur.jpg .
 
//0704
算法题：求一个数的三次方根
https://www.codeleading.com/article/89901984918/
//0708
find . -name ".git"
rm -Rf ./.git

//0722
git pull --rebase origin dev
git commit -m "delete error offer code in  BitmapPool;
remove useless buffer allocation in SnpeSegment." 
git push origin master:refs/for/master

//0723
掩模图：
G:\我的文档\定制需求\2_AI\笔记文档\ZyModel\0311\0314\test\mask

//0724
深度学习之图像分割
https://blog.csdn.net/qq_36492210/article/details/89875708

Mask R-CNN详解
https://blog.csdn.net/WZZ18191171661/article/details/79453780

基于CP神经网络的边缘检测
https://xueshu.baidu.com/usercenter/paper/show?paperid=b42b8c3528538c1e52b830c11a21d99f&site=xueshu_se
【边缘检测】HED论文笔记
https://blog.csdn.net/qq_30159015/article/details/82497974?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
边缘检测︱基于 HED网络TensorFlow 和 OpenCV 实现图片边缘检测
https://blog.csdn.net/sinat_26917383/article/details/73087831?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param
机器学习（15）--HED网络预测实现（opencv+python实现边缘检测及源代码百度云资源）
https://blog.csdn.net/qq_36187544/article/details/89839398?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
原创】推荐一个不错的边缘检测网络：HED
https://blog.csdn.net/l7H9JA4/article/details/104666372?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
一文掌握智能抠图Deep Image Matting（pytorch实现）
https://blog.csdn.net/qianbin3200896/article/details/104688810/
Image Matting（抠图）技术介绍：序言
https://blog.csdn.net/blueswhen/article/details/22617631?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param
图像处理（二十二）贝叶斯抠图-CVPR 2001
https://blog.csdn.net/hjimce/article/details/47667947
Bayes自然图像抠图算法
https://blog.csdn.net/han6771306/article/details/25385653?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param
资深大佬：基于深度学习的图像边缘和轮廓提取方法介绍--重要！！！！
https://blog.csdn.net/weixin_38754361/article/details/100059562?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param

图像分割和轮廓提取
https://blog.csdn.net/poonjun/article/details/3701691?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param

【图像处理】数字图像处理中常用图像分割算法(理论初识--重要！！！
https://blog.csdn.net/KYJL888/article/details/78253734?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param

边缘检测：
另外，我们的人像分割，目前使用的是“语义分割”，和这个边缘检测技术有相关性。
https://paperswithcode.com/task/edge-detection
github上有个边缘检测论文跟踪的开源工程，包含了CVPR 2020的相关论文，可以参考下，链接见内。
https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers#13-semantic-edge-detection-category-aware

//0728
com.zte.camera.ui.module.zeffect.ZeffectMaskShader
com.zte.camera.ui.module.longshuttervideo.LongShutterVideoGLRender
com.zte.camera.ui.module.zeffect.EffectRenderer 
com.zte.camera.moduleview.PortraitVideoModuleView
com.zte.camera.ztevideosegmentatio
ZTEVideoSegmentationImpl
com.zte.camera.ztevideosegmentation.SnpeSegment
com.zte.camera.sensorcontroler.SurfaceManager
   private EffectRenderer mEffectRenderer;
   SurfaceTexture mPreviewSurfaceTexture

com.zte.camera.ui.module.zeffect   
EffectRenderer
//0730
OpenCL 设备上的图像对象和采样器
https://blog.csdn.net/INFINALGEORGE/article/details/105286452
使用 OpenCL 2.0读取写入图像
https://www.kutu66.com//yingyongkaifa/article_5749
OpenCL：图像处理基础note----重要！！！！！
https://www.codercto.com/a/27672.html
Opencv图像处理系列（九）—— 图像轮廓
https://www.codercto.com/a/76191.html
No.6_2 OpenCL 图像采样器——图像旋转（一）
https://blog.csdn.net/Bob_Dong/article/details/64906734?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-5.channel_param
OpenCL里面read_image小测试
https://blog.csdn.net/superyao2008/article/details/12995041?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param
浅谈Opencl之Image和Buffer 区别
https://blog.csdn.net/weixin_42730667/article/details/96724949?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
OpenCL 图像处理函数、图像放缩和插值
https://blog.csdn.net/INFINALGEORGE/article/details/105292162?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.channel_param
opencl:C++实现双线性插值图像缩放
https://blog.csdn.net/10km/article/details/50755584?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param


//0806
Edge Detection：
资深大佬：基于深度学习的图像边缘和轮廓提取方法介绍---边缘检测的几种深度网络原理简介博文---------重要！！！！！！！！！！！后面做的时候选取的时候要用
https://blog.csdn.net/AI_study/article/details/101523396

一个加权融合层自动学习如何组合来自多个尺度的输出。

轮廓提取算法
http://en.findeen.com/%E8%BD%AE%E5%BB%93%E6%8F%90%E5%8F%96%E7%AE%97%E6%B3%95.html

一种基于深度学习的人体轮廓提取方法
https://xueshu.baidu.com/usercenter/paper/show?paperid=1m100ep0hb7a0ef0pw1y04d0wj766244&site=xueshu_se

语义分割-从入门到放弃
https://zhuanlan.zhihu.com/p/48670341
扩增的Pascal VOC 语义分割数据集制作
https://blog.csdn.net/cncyww/article/details/89188506
语义分割数据集（一） — VOC系列
https://zhuanlan.zhihu.com/p/158622375


Edge Detection汇总：
CaseCadePSP Edge Detection：
[15] Jianzhong He, Shiliang Zhang, Ming Yang, Yanhu Shan, and Tiejun Huang. Bi-directional cascade network for perceptual edge detection. In CVPR, 2019.
[45] HED: Saining Xie and Zhuowen Tu. Holistically-nested edge detection.In ICCV, 2015.

Learning to Refine Object Contours with a Top-Down Fully Convolutional Encoder-Decoder Network 重要，PSP类似！！！！！！！！！！！！！！！
https://arxiv.org/abs/1705.04456
论文阅读：Learning to Refine Object Segments 重要，PSP类似！！！！！！！！！！！！！！！
https://blog.csdn.net/sgfmby1994/article/details/80478378
https://arxiv.org/abs/1603.08695

Awesome-Edge-Detection-Papers-----重要！！！！！！！！！！！！！！！
HED:https://paperswithcode.com/task/edge-detection
https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers#13-semantic-edge-detection-category-aware
git clone https://github.com/MarkMoHR/Awesome-Edge-Detection-Papers.git

1. Deep-learning based approaches
1.1 General edge detection
2020_WACV_Dense Extreme Inception Network Towards a Robust CNN Model for Edge Detection-----重要！！！！！！！，可据此来实现
code：https://github.com/xavysp/DexiNed

边缘检测用于分割：
[39] K. Zhang, L. Zhang, K.-M. Lam, and D. Zhang. A level set approach to image segmentation with intensity inhomogeneity. IEEE Transactions on Cybernetics, 46(2):546–557,
2016. 1
边缘检测综述：
[25] M. A. Oskoei and H. Hu. A survey on edge detection methods. University of Essex, UK, 33, 2010. 1

边缘数据集：MDBD—2016-----重要！！！！！！
[23] D. A. Mely, J. Kim, M. McGill, Y. Guo, and T. Serre. A systematic comparison between visual cues for boundary detection. Vision research, 120:93–107, 2016. 1, 2, 5, 6, 8

BSDS500数据集：
[3] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour detection and hierarchical image segmentation. IEEE Trans.Pattern Anal. Mach. Intell., 33(5):898–916, May 2011. 


本文BIPED数据集:Barcelona Images for Perceptual Edge Detection.
Code + dataset: https://github.com/xavysp/DexiNed

边缘检测综述：
[11] X.-Y. Gong, H. Su, D. Xu, Z.-T. Zhang, F. Shen, and H.-B.Yang. An overview of contour detection approaches. International Journal of Automation and Computing, Jun 2018.
[42] D. Ziou, S. Tabbone, et al. Edge detection techniques-an overview. Pattern Recognition and Image Analysis C/C of Raspoznavaniye Obrazov I Analiz Izobrazhenii, 8:537–559,1998.

CNN基础论文：
[17] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages1097–1105, 2012. 2

VGG16 HED基础论文---重要！！！！！！
[32] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 2

HED扩展改进：
[20] Y. Liu, M.-M. Cheng, X. Hu, K. Wang, and X. Bai. Richer convolutional features for edge detection. In Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on, pages 5872–5881. IEEE, 2017
[34] Y. Wang, X. Zhao, and K. Huang. Deep crisp boundaries.In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition, pages 3892–3900, 2017

Xception 网络出处---重要！！！！！！ 
[7] F. Chollet. Xception: Deep learning with depthwise separable convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1251–1258,2017. 3

DeepEdge出处：----重要！！！！，资深大佬1，HED REF2
[4] G. Bertasius, J. Shi, and L. Torresani. Deepedge: A multiscale bifurcated deep network for top-down contour detection. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition, pages 4380–4389, 2015

用于边缘检测的数据集：
边缘数据集：MDBD—2016-----重要！！！！！！
[23] D. A. Mely, J. Kim, M. McGill, Y. Guo, and T. Serre. A systematic comparison between visual cues for boundary detection. Vision research, 120:93–107, 2016. 1, 2, 5, 6, 8

用于目标轮廓的数据集：
CID ：
[12] C. Grigorescu, N. Petkov, and M. A. Westenberg. Contour detection based on nonclassical receptive field inhibition. IEEE Transactions on image processing, 12(7):729–739, 2003. 2, 5, 6

BSDS：
[22] D. Martin, C. Fowlkes, D. Tal, and J. Malik. A database of
human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological
statistics. In Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, volume 2, pages416–423 vol.2, July 2001
[3] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour detection and hierarchical image segmentation. IEEE Trans.Pattern Anal. Mach. Intell., 33(5):898–916, May 2011

NYUD：
[31] N. Silberman, D. Hoiem, P. Kohli, and R. Fergus. Indoor segmentation and support inference from rgbd images. In European Conference on Computer Vision, pages 746–760.Springer, 2012
[13] S. Gupta, P. Arbelaez, and J. Malik. Perceptual organization and recognition of indoor scenes from rgb-d images. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2013.

PASCAL：重要！！！！！！！！！！！！！！！！！
[24] R. Mottaghi, X. Chen, X. Liu, N.-G. Cho, S.-W. Lee, S. Fidler, R. Urtasun, and A. Yuille. The role of context for object
detection and semantic segmentation in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 891–898, 2014

边缘检测指标定义：
[42] D. Ziou, S. Tabbone, et al. Edge detection techniques-an overview. Pattern Recognition and Image Analysis C/C of Raspoznavaniye Obrazov I Analiz Izobrazhenii, 8:537–559,1998

F 指标ODS、OIS：
[3] P. Arbelaez, M. Maire, C. Fowlkes, and J. Malik. Contour detection and hierarchical image segmentation. IEEE Trans.Pattern Anal. Mach. Intell., 33(5):898–916, May 2011

Tensorflow论文出处：
[1] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean,
M. Devin, S. Ghemawat, G. Irving, M. Isard, et al. Tensorflow: A system for large-scale machine learning. In OSDI,
volume 16, pages 265–283, 2016

ResNet出处：残差网络：
[15] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual rearning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages
770–778, 2016. 4
ResNet用于超分辨率：
[40] Y. Zhang, Y. Tian, Y. Kong, B. Zhong, and Y. Fu. Residual dense network for image super-resolution. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2472–2481, 2018. 4
HED出处，加权交叉熵损失函数：
[36] S. Xie and Z. Tu. Holistically-nested edge detection. International Journal of Computer Vision, 125(1-3):3–18, 2017

RCF出处:重要！！！！！！！！！！！！！！！！！！
[19] Y. Liu, M. Cheng, X. Hu, J. Bian, L. Zhang, X. Bai, and J. Tang. Richer convolutional features for edge detection. 
    IEEE Transactions on Pattern Analysis and Machine Intelligence,pages 1–1, 2019

2019_CVPR_Bi-Directional Cascade Network for Perceptual Edge Detection--CasecadePSP REF 15
code：https://github.com/pkuCactus/BDCN

2019_CAIP_Object Contour and Edge Detection with RefineContourNet
pdf地址：https://arxiv.org/pdf/1904.13353.pdf https://arxiv.org/abs/1904.13353
通用论文下载地址：https://arxiv.org
code：https://github.com/AndreKelm/RefineContourNet

2017_NIPS_Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction
code:not found

2015_ICCV_Holistically-Nested Edge Detection--CasecadePSP REF 45----重要！！！！，资深大佬 2
code：
https://github.com/s9xie/hed
code：
https://paperswithcode.com/task/edge-detection -----包括数据集
https://paperswithcode.com/paper/holistically-nested-edge-detection#code
code：
https://github.com/tensorpack/tensorpack/tree/master/examples/HED
code王芳：
https://github.com/fengjian0106/hed-tutorial-for-document-scanning
专栏 | 手机端运行卷积神经网络实践：基于TensorFlow和OpenCV实现文档检测功能 
https://www.sohu.com/a/144624311_465975
手机端运行卷积神经网络实现文档检测功能(二) -- 从 VGG 到 MobileNetV2 知识梳理（续）
https://cloud.tencent.com/developer/article/1146535

2015_CRVR_DeepEdge A Multi-Scale Bifurcated Deep Network for Top-Down Contour Detection----重要！！！！，资深大佬1，HED REF2
code：not found

2015_CPVR_DeepContour A Deep Convolutional Feature Learned by Positive-sharing Loss for Contour Detection----重要！！！，资深大佬3
code:
https://github.com/shenwei1231/DeepContour

深度学习之前的主流算法：
[6] P. Dollar and C. L. Zitnick. Fast edge detection using struc-tured forests. PAMI, 2015.

HED基于的两篇基础文献
[23] C.-Y. Lee, S. Xie, P. Gallagher, Z. Zhang, and Z. Tu. Deeplysupervised nets. In AISTATS, 2015 ----重要，深度监督！！！！
[26] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015.---重要，FCN用于分割首创
中文翻译：VGG
https://www.cnblogs.com/ChinaField-blog/p/10665356.html


边缘测试指标F
REF[15]： X. Hou, A. Yuille, and C. Koch. Boundary detection benchmarking: Beyond f-measures. In CVPR, 2013

像素精度：
[19] J.-J. Hwang and T.-L. Liu. Pixel-wise deep learning for contour detection. In ICLR, 2015---损失函数,比较耗时

VGG Net参考：
[36] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015.

VGG:
[36] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015.

[2] G. Bertasius, J. Shi, and L. Torresani. Deepedge: A multiscale bifurcated deep network for top-down contour detection. In CVPR, 2015.

NYU Depth (NYUD) dataset：
[35] N. Silberman, D. Hoiem, P. Kohli, and R. Fergus. Indoor segmentation and support inference from rgbd images. In ECCV. 2012.
[31] X. Ren and L. Bo. Discriminatively trained sparse code gradients for contour detection. In NIPS, 2012.
[11] S. Gupta, P. Arbelaez, and J. Malik. Perceptual organization and recognition of indoor scenes from rgb-d images. In CVPR, 2013.

HHA features：
[26] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015.---重要，FCN用于分割首创
[12] S. Gupta, R. Girshick, P. Arbelaez, and J. Malik. Learning rich features from rgb-d images for object detection and segmentation. In ECCV, 2014.
RGB-D图像识别中的HHA编码
https://blog.csdn.net/qq_41581769/article/details/90581570

多路径卷积神经网络的轮廓感知----------------重要！！！！！！！！！！！！！！！！！！！,号称28 fps
数据集尺度上最优（ODS）、图片尺度上最优（OIS）、平均精度（AP）
http://www.cjig.cn/html/jig/2019/10/20191012.htm

使用了三种标准的指标进行评估：固定轮廓阈值（ODS），每幅图像的最佳阈值（OIS），和平均精度（AP）
图像边缘的无监督学习
https://www.sohu.com/a/101061140_114877


1.2 Object contour detection
2016_CVPR_Object Contour Detection with a Fully Convolutional Encoder-Decoder Network---重要
code-tf：
https://github.com/Raj-08/tensorflow-object-contour-detection

2016_CVPR_Weakly Supervised Object Boundaries
code:
not found

1.3 Semantic edge detection (Category-Aware)
Neural Compression and Filtering for Edge-assisted Real-time Object Detection in Challenged Networks--self arxiv search
https://arxiv.org/abs/2007.15818

2020_CVPR_Joint Semantic Segmentation and Boundary Detection using Iterative Pyramid Contexts
code: 
https://github.com/mingminzhen/RPCNet/blob/master/README.md,but not found

2019_IJCAI_Dynamic Feature Fusion for Semantic Edge Detection
code:pytorch
https://github.com/Lavender105/DFF

2019_CVPR_Devil is in the Edges: Learning Semantic Boundaries from Noisy Annotations---重要！！！！，修补网络！！！！！！！！！！！！！！！！！！！！！！！！！！！实际使用
code:
https://github.com/nv-tlabs/STEAL

pro:
https://nv-tlabs.github.io/STEAL/
效果演示：
https://camo.githubusercontent.com/2a6bb62a74a6a0e604b20f84007b1c4f51ea6675/68747470733a2f2f6e762d746c6162732e6769746875622e696f2f535445414c2f7265736f75726365732f636f617273655f746f5f66696e655f672e676966

SBD数据集下载及预处理:
Instructions and preprocessing scripts to download SBD and preprocess the dataset can be found here: 
https://github.com/Chrisding/sbd-preprocess

Cityscapes下载及预处理
https://github.com/Chrisding/cityscapes-preprocess



DeepLab-ResNet-Pytorch
https://github.com/Chrisding/AdaptSegNet


实现也是Pythorch--------------
语义和边缘：从噪声和符号中学习
中文解读：
https://blog.csdn.net/wujianing_110117/article/details/106389527


语义边界分割相关论文：
多类HED交叉熵：
CASENet：重要，本文基础，state-of-the-art semantic-aware-edge detection
[36] Z. Yu, C. Feng, M.-Y. Liu, and S. Ramalingam. uppercaseCASENet: Deep category-aware semantic edge detection. InCVPR, 2017.
high-quality re-annotated SBD test
[37] Z. Yu, W. Liu, Y. Zou, C. Feng, S. Ramalingam, B. Vijaya Kumar, and J. Kautz. Simultaneous edge alignment and learning. In ECCV, 2018.----重要，针对不对齐边界的相近论文


HED交叉熵
[34] S. Xie and Z. Tu. Holistically-nested edge detection. In ICCV, pages 1395–1403, 2015.

深度分水岭分割：
[3] M. Bai and R. Urtasun. Deep watershed transform for instance segmentation. In CVPR, 2017
向量点乘（内积）和叉乘（外积、向量积）概念及几何意义解读
https://blog.csdn.net/dcrmg/article/details/52416832

SBD benchmark：？？？？
Semantic Boundary Dataset (SBD)
[15] B. Hariharan, P. Arbelaez, L. Bourdev, S. Maji, and J. Malik. Semantic contours from inverse detectors. In ICCV, 2011.
pascal VOC 2012 分割数据集及其增强版SBD介绍
https://www.jianshu.com/p/da4641f50000
VOC2012中一共有10000+图，但并不都用于分割任务，有的用以物体标识或者动作识别等.
所谓其增强版就是指联合了SBD数据集（Semantic Boundaries Dataset and Benchmark），一般放在benchmark Release文件夹里

Pascal VOC官网：http://host.robots.ox.ac.uk/pascal/VOC/
SBD官网：http://home.bharathh.info/pubs/codes/SBD/download.html

Pascal VOC数据集介绍：
https://blog.csdn.net/iamoldpan/article/details/79196413
https://blog.csdn.net/weixin_38437404/article/details/78230233

图像语义分割网络实战（一）增强数据集PASCAL VOC2012 Aug的制作----重要
https://blog.csdn.net/qq_39444453/article/details/107231357?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-8.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-8.channel_param

Windows下按照pascal voc格式制作用于语义分割的数据集
https://blog.csdn.net/qq_34138126/article/details/81262001

活动轮廓：
[7] V. Caselles, R. Kimmel, and G. Sapiro. Geodesic active contours. IJCV, 22(1):61–79, 1997

水平集：
[27] S. Osher and J. A. Sethian. Fronts propagating with curvature-dependent speed: algorithms based on hamiltonjacobi formulations. Journal of computational physics,79(1):12–49, 1988.
Geodesic Active Contour
[7][27]

Cityscapes数据集：
[11] M. Cordts, M. Omran, S. Ramos, T. Rehfeld, M. Enzweiler, R. Benenson, U. Franke, S. Roth, and B. Schiele. The cityscapes dataset 

Morphological Level Set
形态学曲线演化方法----重要！！！！！！！！！！！！！！！！！！
[25] P. Marquez-Neila, L. Baumela, and L. Alvarez. A morphological approach to curvature-based evolution of curves and surfaces. T-PAMI, 36(1):2–17, 2014

标记数据集准确度评估：
[39] A. Zlateski, R. Jaroensri, P. Sharma, and F. Durand. On the importance of label quality for semantic segmentation. In CVPR, June 2018.

Deeplab V3：
[9] L.-C. Chen, Y. Zhu, G. Papandreou, F. Schroff, and H. Adam. Encoder-decoder with atrous separable convolution for semantic image segmentation. In ECCV, 2018.
Xception 65:
[10] F. Chollet. Xception: Deep learning with depthwise separable convolutions. In CVPR, pages 1800–1807. IEEE, 2017.
Resnet101:
[16] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016
[36] Z. Yu, C. Feng, M.-Y. Liu, and S. Ramalingam. uppercaseCASENet: Deep category-aware semantic edge detection. In CVPR, 2017

GrabCut:
[29] C. Rother, V. Kolmogorov, and A. Blake. Grabcut: Interactive foreground extraction using iterated graph cuts. In SIGGRAPH, 2004

2018_ECCV_Simultaneous Edge Alignment and Learning
code:https://github.com/Chrisding/seal

2017_CVPR_CASENet_Deep Category-Aware Semantic Edge Detection----重要！！！，资深大佬4
code:
https://www.merl.com/research/license#CASENet -----重要！！！！！！

2011_ICCV_Semantic Contours from Inverse Detectors
code:
https://github.com/bharath272/semantic_contours
https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/
dataset：

1.4 Occlusion boundary detection
2016_CVPR_Occlusion Boundary Detection via Deep Exploration of Context
code:not found

1.5 Edge detection from multi-frames
2018_CVPR_Boundary Flow: A Siamese Network that Predicts Boundary Motion without Training on Motion
code:not found

2018_CVPR_LEGO_Learning Edge with Geometry all at Once by Watching Videos
code:
https://github.com/zhenheny/LEGO

2016_CVPR_Unsupervised Learning of Edges
code:
https://github.com/happyharrycn/unsupervised_edges

2. Traditional approaches
2016_CVPR_SemiContour: A Semi-supervised Learning Approach for Contour Detection 
code:not found

2015_CVPR_Oriented Edge Forests for Boundary Detection
code:
https://github.com/samhallman/oef

2015_TPAMI_Fast edge detection using structured forests----重要！！！
code:
https://github.com/pdollar/edges

2014_ECCV_Edge Boxes: Locating Object Proposals from Edges
code:https://github.com/pdollar/edges

2014_ECCV_Crisp Boundary Detection Using Pointwise Mutual Information
code: 
https://github.com/phillipi/crisp-boundaries

2013_CVPR_Sketch tokens: A learned mid-level representation for contour and object detection
code:not found

2012_NIPS_Discriminatively Trained Sparse Code Gradients for Contour Detection
  
2011_TPAMI_Contour Detection and Hierarchical Image Segmentation----重要！！！HED REF 1 BSDS 500
code:
http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_source.tgz
pro:
Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500)数据集
https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html
pdf:
https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/resources.html


2011_NPAR_XDoG: advanced image stylization with eXtended Difference-of-Gaussians
code python:
https://github.com/heitorrapela/xdog
code(C++):
https://github.com/Sunwinds/xdog-demo
demo:
https://xdog.alexpeattie.com/


2007_NPAR_Coherent Line Drawing
code:
https://github.com/SSARCandy/Coherent-Line-Drawing
pdf:
https://wenku.baidu.com/view/1216513b376baf1ffc4faddb.html

1986_TPAMI_A Computational Approach to Edge Detection --Canny 原始论文
code：
https://rosettacode.org/wiki/Canny_edge_detector
code-py：
https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html

3. Useful Links
Code to plot edge PR curves: yun-liu/plot-edge-pr-curves
code:
https://github.com/yun-liu/plot-edge-pr-curves


//0807
CCNet: Criss-Cross Attention for Semantic Segmentation
https://blog.csdn.net/pangyunsheng/article/details/89069749
【文献阅读】CCNet: Criss-Cross Attention for Semantic Segmentation
论文链接：https://arxiv.org/pdf/1811.11721.pdf
国内镜像：https://xxx.itp.ac.cn/pdf/1811.11721.pdf
https://blog.csdn.net/weixin_43578873/article/details/105539364?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param  
[深度学习从入门到女装]CCNet: Criss-Cross Attention for Semantic Segmentation
https://blog.csdn.net/py184473894/article/details/100108785?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.channel_param
CCNet: Criss-Cross Attention for Semantic Segmentation论文解读---重要！！！！

DANet：Dual Attention Network for Scene Segmentation论文解读和源代码详解
https://blog.cs0dn.net/qq_34914551/article/details/90350063
相关博客：重要，深度学习系列博客！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/qq_34914551?t=1
论文地址：https://arxiv.org/abs/1809.02983
官方源码：(基于pytorch)[https://github.com/junfu1115/DANet]
DANet：Dual Attention Network for Scene Segmentation 论文翻译（学习）2019-8-30----中文版
https://blog.csdn.net/nawu2018/article/details/100161440?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param

论文阅读理解 - Panoptic Segmentation 全景分割
https://blog.csdn.net/zziahgf/article/details/79063398?utm_medium=distribute.pc_relevant.none-task-blog-title-7&spm=1001.2101.3001.4242
DL之Panoptic Segmentation：Panoptic Segmentation(全景分割)的简介(论文介绍)、全景分割挑战简介、案例应用等配图集合之详细攻略
https://blog.csdn.net/qq_41185868/article/details/100387821?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-9.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-9.channel_param

【图像分割模型】全景分割是什么？
https://blog.csdn.net/hacker_long/article/details/91641666?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-3&spm=1001.2101.3001.4242
全景分割数据集：
下面是三个数据库的链接，有需要可以自取：

Cityscapes：https://www.cityscapes-dataset.com/
ADE20k：http://groups.csail.mit.edu/vision/datasets/ADE20K/
Mapillary Vistas：
https://blog.mapillary.com/product/2017/05/03/mapillary-vistas-dataset.html

博客系列--------图像分割模型专栏：特别重要！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！！
https://blog.csdn.net/hacker_long/category_8871004.html
【AI初识境】从头理解神经网络-内行与外行的分水岭
https://blog.csdn.net/hacker_long/article/details/88068672

https://github.com/longpeng2008/yousan.ai


//0808
【总结】图像语义分割之FCN和CRF
https://zhuanlan.zhihu.com/p/22308032
ResNet原理及其在TF-Slim中的实现
https://cloud.tencent.com/developer/article/1057217


//0811
Tensorflow和Pytorch的学习资源：
Tensorflow和Pytorch有什么相同和不同之处？学习Tensorflow有什么好的学习方法？
https://www.zhihu.com/question/318778731
Pytorch实战语义分割（VOC2012）
https://blog.csdn.net/qq_43280818/article/details/105916507?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param

Edge Boxes论文浅读和EdgeBoxes Matlab代码功能函数浅析-------------重要，边缘检测Matlab实现
Edge Boxes的Matlab代码功能函数说明
Edge Boxes的Matlab代码托管在Github上：https://github.com/pdollar/edges
跑edgebox
https://blog.csdn.net/weixin_30439031/article/details/98502766?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
《Edge Boxes: Locating Object Proposals from Edges》读后感~
https://blog.csdn.net/wsj998689aa/article/details/39476551
图像处理——Edge Boxes边缘检测
https://blog.csdn.net/matt45m/article/details/104504627?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-4.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-4.nonecas
edgesBoxes-matlab代码安装调试
https://blog.csdn.net/weixin_36899784/article/details/80339539?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param

玩PyTorch？你不得不看的PyTorch资源大列表
https://blog.csdn.net/DBC_121/article/details/104578647

steal 环境搭建:
conda create --name steal_pytorch_040 python=3.6
conda remove -n steal_pytorch_040 --all


conda install Cython=0.28.5
conda install cytoolz=0.9.0.1
conda install opencv-python=3.4.0.12
pip install  opencv-python==3.4.0.12 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install opencv=3.4.1
conda install  pathos=0.2.2
conda search --full-name  pathos
pip install  pathos==0.2.2 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install Pillow=5.4.1
conda install  scikit-image=0.14.0
conda install scikit-learn=0.19.2
pip install  scikit-learn===0.19.2 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install scipy=1.0.1
pip install  scipy===1.0.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda search --full-name  scipy
conda install scipy=1.0.1

conda install sklearn=0.0
pip install  sklearn===0.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/

conda install torch=0.4.0 not install force install 
pip install  torch==0.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda search --full-name pytorch

conda install torchfile=0.1.0
pip install  torchfile==0.1.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install torchvision=0.2.1 not install ok
pip install  torchvision==0.2.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install tqdm=4.23.0
pip install  tqdm==4.23.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda search --full-name tensorflow

pip install  torch==0.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
pip install  torch==1.0.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
1.0.0
conda install pytorch=0.4.1 cuda90 -c pytorch

pytorch问题：ModuleNotFoundError: No module named 'torch'
https://blog.csdn.net/tanmx219/article/details/86214500
https://www.baidu.com/
//0814

普通代理：proxy.zte.com.cn     端口：80
普通代理认证：
http://10.88.138.100/ac_portal/zte_webauth/pc.html?template=zte_webauth&tabs=pwd&vlanid=0&url=http://ww.baidu.com%2f
http://10.88.138.100/ac_portal/zte_webauth/pc.html
香港代理：proxyhk.zte.com.cn   端口：80
香港代理认证：http://10.3.76.102/ac_portal/zte_webauth/pc.html?template=zte_webauth&tabs=pwd&vlanid=0&url=http://www.google.com
http://10.3.76.102/ac_portal/zte_webauth/pc.html
vim ~/.bashrc
source ~/.bashrc


清华Anaconda网站说明：
https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/

香港代理设置后conda无法联网问题，需修改proxy_serves：
C:\Users\10087295\.condarc
channels:
  - defaults
show_channel_urls: true
allow_other_channels: true

proxy_servers:
  http: http://proxyhk.zte.com.cn:80
  https: http://proxyhk.zte.com.cn:80

ssl_verify: true


CUDA driver version is insufficient for CUDA runtime version 解决方法
https://blog.csdn.net/qq_29591593/article/details/87937322

torch版本查询：
>>> import torch
>>> torch.__version__
'0.4.0'
>>> torch.cuda.is_available()
False

conda install pytorch torchversion cudatoolkit =10.0 -c pytorch
conda install pytorch torchvision cudatoolkit=10.1 -c pytorch
conda install pytorch=0.4.0 cuda90 -c pytorch

pytorch的cuda环境搭建（GPU版本安装）
https://blog.csdn.net/qq_36653505/article/details/83932941?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

显卡信息显示：
lspci  | grep -i vga
lspci | grep -i nvidia

查看显卡情况：
nvidia-smi
指定显卡序号：
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ['CUDA_VISIBLE_DEVICES']='0' 

pytorch 指定GPU训练
https://blog.csdn.net/alip39/article/details/87913543

# 代码1：
torch.cuda.set_device(1)

# 代码2：
device = torch.device("cuda:1")

# 代码3：（官方推荐使用）
os.environ["CUDA_VISIBLE_DEVICES"] = '1'

（如果你想同时调用两块GPU的话）
os.environ["CUDA_VISIBLE_DEVICES"] = '1,2'

Pytorch的GPU计算（cuda）
https://blog.csdn.net/qq_36653505/article/details/84728746?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

Kill掉占用GPU的进程
kill -9 63976

Pytorch GPU 设置
https://blog.csdn.net/liulinyi007/article/details/105022165


Ubuntu下查看CUDA和CUDNN版本的方法 -----重要！！！！！
https://blog.csdn.net/weixin_41677877/article/details/90003592

cuda 版本
cat /usr/local/cuda/version.txt
cudnn 版本
cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2

pytorch （GPU） 安装 全部过程（踩得坑好多）（win10）
https://blog.csdn.net/weixin_44455154/article/details/105322330?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

tgz文件解压：
tar zxvf simple-examples.tgz -C ./

0815:
创建账户：
sudo useradd -d /home/zhangdm -m -s/bin/bash -G sudo zhangdm
sudo passwd zhangdm
密码：Zdm.87295

设置密码报错解决：
sudo passwd zhangdm

sudo vim /etc/samba/smb.conf
[zhangdm]
comment = zhangdm
path = /home/zhangdm
browseable = yes
read only = no

设置smba密码：
sudo smbpasswd -a zhangdm
smba密码：Zdm.87295
\\10.74.53.13

/home/10087295

CUDA安装~/.bashrc 配置：
export CUDA_HOME=/usr/local/cuda-10.0
export PATH=$CUDA_HOME/bin${PATH:+:${PATH}}
export LD_LIBRARY_PATH=$CUDA_HOME/lib64\${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}

查看网络映射连接：
mbpasswd命令 – 修改用户SMB密码
删除指定链接：
net use p: /del

sudo mkdir zhangdongming
sudo chown -R 10087295:10087295 zhangdongming
cd /home/10087295
ln -s  /data1/zhangdongming data1

解决samba不能访问软连接的问题：
http://blog.chinaunix.net/uid-29546700-id-5155438.html
在配置文件的“[global]”节的最后，加上下面三条设置：
follow symlinks = yes
wide links = yes
unix extensions = no
然后保存退出，最后重启下samba即可：
/etc/init.d/samba restart

0816_h
Win10下Pytorch安装（Windows10+Anaconda+PyTorch）
https://blog.csdn.net/weixin_42158966/article/details/88543668

win10下pytorch-gpu安装以及CUDA详细安装过程
https://blog.csdn.net/Mind_programmonkey/article/details/99688839?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param


nvidia 相关网站：
https://developer.nvidia.com/cuda-gpus
https://developer.nvidia.com/cudnn

cudnn账号：
droidpioneer@sina.com,Nvd44*****

cudnn-10.2-windows10-x64-v7.6.5.32.7z 
https://www.iteye.com/resource/mooneve-12321374


CUDA 10.2及CUDNN下载
https://blog.csdn.net/tangxianyu/article/details/106447060?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-2.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-2.nonecas

Anaconda3、CUDA10.2版本安装包百度网盘下载链接
https://blog.csdn.net/weixin_40171930/article/details/107665388?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-3&spm=1001.2101.3001.4242

CUDA win10安装：

深度学习环境搭建（GPU）CUDA安装（完全版）---重要！！！！！安装参考
https://blog.csdn.net/cashmood/article/details/105081586

安装完命令确认：
nvcc -V
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Wed_Oct_23_19:32:27_Pacific_Daylight_Time_2019
Cuda compilation tools, release 10.2, V10.2.89


Win10上安装CUDA和CUDNN---重要！！！！！安装参考
https://blog.csdn.net/james506/article/details/105901589/?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-3&spm=1001.2101.3001.4242

笔记本配置win10+cuda 10 + pytorch ---重要！！！！！安装参考
https://www.cnblogs.com/xuanmanstein/p/13507901.html

Win10深度学习环境配置（CUDA+cuDNN+TensorFlow-gpu+Keras）
https://blog.csdn.net/enatsu/article/details/80381827


Matlab R2016b 中文破解版
http://www.xue51.com/soft/1616.html

PyTorch 中文教程
https://pytorch.apachecn.org/
https://pytorch.apachecn.org/docs/1.4/4.html


steal 环境搭建:
conda create --name steal_pytorch_040 python=3.6
conda remove -n steal_pytorch_040 --all


conda install Cython=0.28.5
conda install cytoolz=0.9.0.1
conda install opencv-python=3.4.0.12
pip install  opencv-python==3.4.0.12 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install opencv=3.4.1
conda install  pathos=0.2.2
conda search --full-name  pathos
pip install  pathos==0.2.2 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install Pillow=5.4.1
conda install  scikit-image=0.14.0
conda install scikit-learn=0.19.2
pip install  scikit-learn===0.19.2 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install scipy=1.0.1
pip install  scipy===1.0.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda search --full-name  scipy
conda install scipy=1.0.1

conda install sklearn=0.0
pip install  sklearn===0.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/

conda install torch=0.4.0 not install force install
pip install  torch==0.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda search --full-name pytorch

conda install torchfile=0.1.0
pip install  torchfile==0.1.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install torchvision=0.2.1 not install ok
pip install  torchvision==0.2.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda install tqdm=4.23.0
pip install  tqdm==4.23.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
conda search --full-name tensorflow

pip install  torch==0.4.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
pip install  torch==1.0.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
1.0.0
直接下载安装轮子：
https://download.pytorch.org/whl/cpu/torch_stable.html

conda create --name steal_pytorch_151 python=3.6

conda install pytorch=0.4.1 cuda90 -c pytorch
conda install pytorch==1.5.1 torchvision==0.6.1 cudatoolkit=10.2 -c pytorch
conda install pytorch torchvision cudatoolkit=10.2 -c pytorch

Anaconda安装详解、配置清华镜像和常用命令行集锦
https://blog.csdn.net/weixin_45949781/article/details/103326222

conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/  
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/  
conda config --set show_channel_urls yes 
conda config --show channels
conda config --remove channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/

清华Anaconda网站说明：
https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/

香港代理设置后conda无法联网问题，需修改proxy_serves：
C:\Users\10087295\.condarc
channels:
  - defaults
show_channel_urls: true
allow_other_channels: true

proxy_servers:
  http: http://proxyhk.zte.com.cn:80
  https: http://proxyhk.zte.com.cn:80

ssl_verify: true


Win 10 查看显卡情况：
C:\Program Files\NVIDIA Corporation\NVSMI\nvidia-smi

tensorflow，pytorch框架使用GPU，指定GPU问题
https://blog.csdn.net/zz2230633069/article/details/88350454

torch.cuda.is_available()  # cuda是否可用
torch.cuda.device_count()  # 返回gpu数量
torch.cuda.get_device_name(0)  # 返回gpu名字，设备索引默认从0开始
torch.cuda.current_device()  # 返回当前设备索引
torch.cuda.get_device_capability(0)

torch.cuda命令查询
https://www.jianshu.com/p/4b10a3e80321
Pytorch 提速指南

深度学习中 GPU 和显存分析----重要！！！！计算模型占用GPU的大小
https://blog.csdn.net/lien0906/article/details/78863118

深度学习的GPU：深度学习中使用GPU的经验和建议
https://blog.csdn.net/sinat_36458870/article/details/78946030?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

//0817

Pycharm出现同一目录的py文件不能相互调用的问题
https://blog.csdn.net/weixin_38044888/article/details/95457899

CityScapes数据集相关简介
https://niecongchong.github.io/2019/08/10/CityScapes%E6%95%B0%E6%8D%AE%E9%9B%86%E7%AE%80%E4%BB%8B%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E5%92%8C%E7%B2%BE%E5%BA%A6%E6%8C%87%E6%A0%87/
源码详解Pytorch的state_dict和load_state_dict
https://www.cnblogs.com/marsggbo/p/12075356.html
图像分割的水平集模型及其在医学图像分割中的应用研究--MLS相关
http://cdmd.cnki.com.cn/Article/CDMD-10730-1017702964.htm
Python中__call__的用法:
https://www.cnblogs.com/xinglejun/p/10129823.html

//0818

ResNet:（residual 、residual bottleneck）
https://blog.csdn.net/u011304078/article/details/80683985
ResNet结构分析
https://zhuanlan.zhihu.com/p/48169294

深度学习基础--Bottleneck(瓶颈) Architectures
https://blog.csdn.net/wydbyxr/article/details/83988891?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

Deeper Bottleneck(瓶颈) Architectures
https://blog.csdn.net/wydbyxr/article/details/84579576?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param



[ 1 x 1 ] Convolution-1*1卷积的作用
https://www.cnblogs.com/lemonzhang/p/9939187.html
1*1卷积----重要！！！！！！
https://blog.csdn.net/tianguiyuyu/article/details/80748015

神经网络之BN层
https://www.jianshu.com/p/fcc056c1c200
ResNet:(residual、residual bottleneck）
https://blog.csdn.net/u011304078/article/details/80683985


//0702
snpe-tensorflow-to-dlc --input_network optimized_frozen_inference_graph_364418.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path optimized_frozen_inference_graph_364418.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc optimized_frozen_inference_graph_364418.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc optimized_frozen_inference_graph_364418_dsp.dlc
snpe-dlc-viewer -i optimized_frozen_inference_graph_0628_train_dsp.dlc -s optimized_frozen_inference_graph_0628_train_dsp.html


语义分割损失总结------------重要！！！！！！！！！！！！！！！
https://blog.csdn.net/wzt_gjt/article/details/87997234?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-3&spm=1001.2101.3001.4242

语义分割总结
https://blog.csdn.net/hutanglove/article/details/80022932?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

////////////////////////////////////////
边缘损失函数专题分割

0、已阅读，边缘损失函数0，无训练代码，仅针对图像边缘：
2019_CVPR_Devil is in the Edges: Learning Semantic Boundaries from Noisy Annotations---重要！！！！，修补网络！！！！！！！！！！！！！！！！！！！！！！！！！！！实际使用
code:
https://github.com/nv-tlabs/STEAL
pro:
https://nv-tlabs.github.io/STEAL/
效果演示：
https://camo.githubusercontent.com/2a6bb62a74a6a0e604b20f84007b1c4f51ea6675/68747470733a2f2f6e762d746c6162732e6769746875622e696f2f535445414c2f7265736f75726365732f636f617273655f746f5f66696e655f672e676966

SBD数据集下载及预处理:
Instructions and preprocessing scripts to download SBD and preprocess the dataset can be found here: 
https://github.com/Chrisding/sbd-preprocess

Cityscapes下载及预处理
https://github.com/Chrisding/cityscapes-preprocess

DeepLab-ResNet-Pytorch
https://github.com/Chrisding/AdaptSegNet

实现也是Pythorch--------------
语义和边缘：从噪声和符号中学习
中文解读：
https://blog.csdn.net/wujianing_110117/article/details/106389527


1、已阅读，但没代码，边缘损失函数1：
Boundary-Aware Network for Fast and High-Accuracy Portrait Segmentation--------------重要！！！！

【Portrait分割】BANet:Boundary-Aware Network for Fast and High-Accuracy Portrait Segmentation--------------重要！！！！
中文解读：
https://blog.csdn.net/u013368992/article/details/86525436?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
https://blog.csdn.net/baidu_27643275/article/details/99683222?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
实现参考：Canny
https://github.com/ycszen/TorchSeg/blob/master/model/dfn/cityscapes.dfn.R101_v1c/dataloader.py#L16


2、PortraitNet，边缘损失函数2，有边缘Loss和pytorch代码，速度快：---重要！！！！，论文阅读，推理，代码分析--损失函数定义用法，
PortraitNet: Real-time portrait segmentation network for mobile device论文解读和代码实践---重要
https://blog.csdn.net/qq_34914551/article/details/103465299
code：
https://github.com/dong-x16/PortraitNet
注意：portraitNet其实已经被extremeC3Net（2019年七月）和SINet（2019年11月）超越了

git clone https://github.com/dong-x16/PortraitNet.git

卷积网络分割像素级分割的最初论文：
[1] Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2015. p. 3431–40

Cityscapes Dataset：
[16] Cordts M , Omran M , Ramos S , Rehfeld T , Enzweiler M , Benenson R , et al. The cityscapes dataset for semantic urban scene understanding. In: Proceedings of the IEEE conference on computer vision and pattern recognition; 2016. p. 3213–23 .

EG1800数据集出处,PortraitFCN +:
[7] Shen X , Hertzmann A , Jia J , Paris S , Price B , Shechtman E , et al. 
Automatic portrait segmentation for image stylization. In: Computer Graphics Forum, 35. Wiley Online Library; 2016. p. 93–102 . 

Supervise-Portrait人像数据集出处：
[28] Supervise.ly. https://supervise.ly/; 2017

Pytorch自动微分：
[29] Paszke A , Gross S , Chintala S , Chanan G , Yang E , DeVito Z , et al. Automatic differentiation in pytorch 2017 .
苹果上AI？？
[30] Coreml. https://developer.apple.com/documentation/coreml ; 2017.



第4篇论文，边缘损失算子：
[8] Du X , Wang X , Li D , Zhu J , Tasci S , Upright C , et al. 
Boundary-sensitive network for portrait segmentation. arXiv e-prints 2017 .

神经网络稳定性，欧几里得距离并不合适，采用KL散度：
[22] Zheng S, Song Y, Leung T, Goodfellow I. Improving the robustness of deep neural networks via stability training. In: Proceedings of the ieee conference on
computer vision and pattern recognition; 2016. p. 4480–8.
[23] Hinton G, Vinyals O, Dean J. Distilling the knowledge in a neural network.arXiv e-prints 2015

MobileNet-v2出处：
[19] Sandler M, Howard A, Zhu M, Zhmoginov A, Chen L-C. Mobilenetv2: Inverted
residuals and linear bottlenecks. In: Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition; 2018. p. 4510–20.

boundary branch：注意，边界分支！！！！！！！！！
[17] Yu C, Wang J, Peng C, Gao C, Yu G, Sang N. Learning a discriminative feature
network for semantic segmentation. In: Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition; 2018b. p. 1857–66.

focal loss:解决边界损失函数负样本少的问题：
[26] Lin T-Y, Goyal P, Girshick R, He K, Dollár P. Focal loss for dense object detection. In: Proceedings of the IEEE international conference on computer vision;
2017. p. 2980–8.

soft Lable软标签提升模型精度：
[23] Hinton G, Vinyals O, Dean J. Distilling the knowledge in a neural network.arXiv e-prints 2015.
[27] Anil R, Pereyra G, Passos A, Ormandi R, Dahl GE, Hinton GE. Large scale distributed neural network training through online distillation. arXiv e-prints2018.


3、SINet，有Pytorch实现，非边缘，但号称超越了PortraitNet：代码见官方地址！！！！！韩国人。---重要！！！！
人像分割论文SINet: Extreme Lightweight Portrait Segmentation Networks及其PyTorch实现
https://blog.csdn.net/shanglianlm/article/details/103931852?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
PDF: https://arxiv.org/pdf/1911.09099.pdf
PyTorch代码: https://github.com/shanglianlm0525/PyTorch-Networks


ExtremeC3Net - 使用高级C3模块的超轻量级肖像分割网络----有Pytorch实现，非边缘，但号称超越了PortraitNet：
https://www.ctolib.com/clovaai-ext_portrait_segmentation.html
SINet、ExtremeC3Net均有资源介绍

Git hub官方地址：
https://github.com/HYOJINPARK/ExtPortraitSeg
https://github.com/clovaai/ext_portrait_segmentation

4、Boundary-sensitive Network for Portrait Segmentation----重要，边缘损失函数3，将边缘信息融合进神经网络中！！！，但似乎无代码，注意算子定义。。。
https://xueshu.baidu.com/usercenter/paper/show?paperid=05e40c66759ed60c1b12978e6e2e7631
Boundary-sensitive Network for Portrait Segmentation论文解读
https://blog.csdn.net/qq_27637315/article/details/79147519

5、显著性检测之Contour Loss: Boundary-Aware Learning for Salient Object Segmentation---边缘损失函数4，提出了轮廓损失，非人，似乎无代码
https://blog.csdn.net/P_LarT/article/details/100025198?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
中文解读：
Contour Loss: Boundary-Aware Learning for Salient Object Segmentation
https://blog.csdn.net/P_LarT/article/details/100025198?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

6、BASNet: Boundary-Aware Salient Object Detection-----重要！！！，有边缘损失函数，也有github 代码
显著性检测论文详解（一）：BASNet: Boundary-Aware Salient Object Detection
https://blog.csdn.net/Superstar02/article/details/103100133
BASNet: Boundary-Aware Salient Object Detection论文学习
https://blog.csdn.net/calvinpaean/article/details/101036249

git hub地址：
https://github.com/NathanUA/BASNet

7、Boundary-aware Instance Segmentation 阅读笔记
https://blog.csdn.net/qq_38356387/article/details/87477173?utm_medium=distribute.pc_relevant.none-task-blog-title-4&spm=1001.2101.3001.4242

8、Boundary-Aware Fully Convolutional Network for Brain Tumor Segmentation的解读
https://blog.csdn.net/qq_29184757/article/details/79832981?utm_medium=distribute.pc_relevant.none-task-blog-title-9&spm=1001.2101.3001.4242


其它参考资料：

人像精细分割问题分析
https://blog.csdn.net/qq_39499621/article/details/85001369?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param

读图像精细分割论文 Automatic Portrait Segmentation for Image Stylization ，by Xiaoyong Shen
https://blog.csdn.net/Yangxing_ch/article/details/98033105?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param

RefineNet: Multi-Path Refinement Networks for High-Resolution Semantic Segmentation
https://arxiv.org/abs/1611.06612
https://blog.csdn.net/hacker_long/article/details/91633173
code: https://github.com/guosheng/refinenet

Automatic Portrait Segmentation for Image Stylization 数据集
https://download.csdn.net/download/zhang2012liang/10587068

Fast portrait automatic segmentation with coarse-to-fine CNNs
https://xueshu.baidu.com/usercenter/paper/show?paperid=b0c52b5b01051f79ea1f7f10eb6e3eb6

Research on Real-Time Portrait Segmentation of Mobile Terminal
https://xueshu.baidu.com/usercenter/paper/show?paperid=3352d80dcc28756813e32423814a2955


///////////////////////////////////////
语义分割综述：

重要！！！！！！！！
{阅读笔记]（语义分割最全总结，综述）《A Review on Deep Learning Techniques Applied to Semantic Segmentation》
https://blog.csdn.net/ShuqiaoS/article/details/87690424?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
语义分割总结
https://blog.csdn.net/hutanglove/article/details/80022932?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
//0810
用于语义分割的全卷积网络
https://www.cnblogs.com/ChinaField-blog/p/10665356.html
浅谈图像的语义分割
https://zhuanlan.zhihu.com/p/100140440
语义分割 | 发展综述
https://zhuanlan.zhihu.com/p/37618829
总结】图像语义分割之FCN和CRF----重要！！！！！！！！！！！！！！
PASCAL VOC Challenge performance ---语义分割检测网站：---重要！！！！！！！！！！！！！！
http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&compid=6 
https://zhuanlan.zhihu.com/p/22308032
图像语义分割综述----重要！！！！！！！！！！！！！！
https://zhuanlan.zhihu.com/p/37801090
语义分割 | 从图像分类到图像分割
https://zhuanlan.zhihu.com/p/143261645
干货 | 一文概览主要语义分割网络，FCN、UNet、SegNet、DeepLab 等等等等应有尽有------------------------重要！！！！！！！！
https://blog.csdn.net/qq_20084101/article/details/80432960?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-5&spm=1001.2101.3001.4242
FCN、Unet、deeplabv1、deeplabv2、deeplabv3、deeplabv3+的网络
https://blog.csdn.net/c_daofeng/article/details/90516691
语义分割网络总结：FCN、SegNet、U-Net、PSPNet、RefineNet到DeepLab v1～v3+
https://blog.csdn.net/qq_19329785/article/details/95050626?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
PSPNet Deeplab_v3+ pytorch复现
https://blog.csdn.net/LEILEI18A/article/details/80702481?utm_source=blogxgwz1&utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-3&spm=1001.2101.3001.4242
图像语义分割 DeepLab v3+ 训练自己的数据集
https://blog.csdn.net/qq_32799915/article/details/80070711?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
Nature：深度学习的现在和未来：DeepLearning、无监督学习、NLP
https://blog.csdn.net/q375010308/article/details/47614587?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-8.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-8.channel_param

///////////////////////////////////////////////////////////////////
数据集资源
Dataset - aisegment人像Matting数据集---重要！！！！
https://blog.csdn.net/oJiMoDeYe12345/article/details/90706792?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-3.opensearch_close_3&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-3.opensearch_close_
【知识星球】几个人像分割数据集简介和下载
https://blog.csdn.net/hacker_long/article/details/100138475
常用图像数据集大全（分类，跟踪，分割，检测等）
https://blog.csdn.net/geekmanong/article/details/50468816?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
Supervisely 人像分割数据集
https://blog.csdn.net/SimleCat/article/details/107021152?utm_medium=distribute.pc_relevant.none-task-blog-title-3&spm=1001.2101.3001.4242
将supervisely数据集中0-1的二值图像转化为0-255的二值图像
https://blog.csdn.net/wangmengmeng99/article/details/103628194?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
飞桨PaddleSeg新升级！带来187K超轻量级人像分割模型，视频级光流后处理方案
https://blog.csdn.net/weixin_45449540/article/details/106846331?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
【技术综述】最全人脸数据集收录
https://blog.csdn.net/hacker_long/article/details/83660400
边缘检测数据集bsds500及评测
https://www.jianshu.com/p/eda277063867

0820
////////////////////////////////////////////
GhostNet系列

超越谷歌MobileNet！华为提出端侧神经网络架构GhostNet｜已开源
https://baijiahao.baidu.com/s?id=1659843934591220031&wfr=spider&for=pc
论文地址：
https://arxiv.org/abs/1911.11907
项目开源地址：
https://github.com/huawei-noah/ghostnet
git clone https://github.com/huawei-noah/ghostnet.git

大白话解读2020CVPR-GhostNet论文以及相关代码: 超越MobileNetV3的轻量级网络
https://blog.csdn.net/qidailiming1994/article/details/104589749
CVPR2020】网络结构：GhostNet/频域卷积/Pi-Net
https://blog.csdn.net/qq_43257640/article/details/106361716?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param

///////////////////////////////

MobileNetV3系列
MobileNetV3
【论文学习】轻量级网络——MobileNetV3终于来了（含开源代码）----已读
https://blog.csdn.net/DL_wly/article/details/90168883
感谢github上大佬们开源，开源代码整理如下：
（1）PyTorch实现1：https://github.com/xiaolai-sqlai/mobilenetv3
（2）PyTorch实现2：https://github.com/kuan-wang/pytorch-mobilenet-v3
（3）PyTorch实现3：https://github.com/leaderj1001/MobileNetV3-Pytorch
（4）Caffe实现：https://github.com/jixing0415/caffe-mobilenet-v3
（5）TensorFLow实现：https://github.com/Bisonai/mobilenetv3-tensorflow-----重要！！！！！！！！！！！

MobileNetV3论文讲解----已读
https://blog.csdn.net/zaf0516/article/details/90374170

MobileNets V3神经网络简介与代码实战---已读
https://blog.csdn.net/u013289254/article/details/96568485
附：MobileNets V2神经网络简介与代码实战
https://blog.csdn.net/u013289254/article/details/96505943
附：MobileNets V1神经网络简介与代码实战
https://blog.csdn.net/u013289254/article/details/96189888

大白话讲解MobileNet-v3---已读
https://blog.csdn.net/qidailiming1994/article/details/103465548?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-5&spm=1001.2101.3001.4242
mobilenet V3算法理解与代码解析---已读
https://blog.csdn.net/litt1e/article/details/100574817?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
探索与实现 MobileNet V3 网络结构---已读，未细读
https://blog.csdn.net/weixin_34357267/article/details/91411999?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
pytorch code：
https://github.com/SpikeKing/mobilenet_v3/blob/master/mn3_model.py

论文学习笔记-MobileNet v3------重要，论文中文翻译!!!!!--已读
https://blog.csdn.net/sinat_37532065/article/details/90813655?utm_medium=distribute.pc_relevant.none-task-blog-title-1&spm=1001.2101.3001.4242
MobileNetV3——论文翻译-----重要，论文翻译，读完此篇就结束。
https://blog.csdn.net/thisiszdy/article/details/90167304?utm_medium=distribute.pc_relevant_download.none-task-blog-baidujs-2.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-baidujs-2.nonecase


重磅！MobileNetV3 来了！----重要！！！！！MobileNetV3解读---已读
https://blog.csdn.net/u011984148/article/details/99440118?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-7.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-7.channel_param

官方地址：
Tensorflow models官方地址：
https://github.com/tensorflow/models/tree/master/research
git clone --recurse-submodules  https://github.com/tensorflow/models.git

deeplab地址：
https://github.com/tensorflow/models/tree/master/research/deeplab

mobilenet v3地址：
mobilenet v3预训练模型:-----重要！！！！！！
https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet
https://blog.csdn.net/weixin_45154016/article/details/102922074?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.channel_param
mobilenet v3预训练模型下载：
https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md
tensorflow官方预训练模型下载链接：
https://github.com/tensorflow/models/tree/master/research/slim


mobilenetv3.pytorch
https://github.com/d-li14/mobilenetv3.pytorch/actions

mobile-deeplab-v3-plus：为何是独立的？非官方？
https://github.com/nolanliou/mobile-deeplab-v3-plus

《MobileNetV1 + MobileNetV2 + MobileNetV3 》论文阅读笔记----------重要！！！！！！！！！！！！！！！！！要点都写了
https://blog.csdn.net/LiuJiuXiaoShiTou/article/details/105918486?utm_medium=distribute.pc_relevant_right.none-task-blog-BlogCommendFromBaidu-18.channel_param_right&depth_1-utm_source=distribute.pc_relevant_right.none-task-blog-BlogCommendFromBaidu-18.channel_param_right

轻量级神经网络：MobileNetV1到MobileNetV3
https://blog.csdn.net/weixin_44474718/article/details/91045521?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

轻量级网络：MobileNet系列V1、V2、V3
https://blog.csdn.net/qq_39382877/article/details/97028560?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param
MobileNetV1/V2/V3简述 | 轻量级网络
https://blog.csdn.net/lichlee/article/details/107208403?utm_medium=distribute.pc_relevant.none-task-blog-title-3&spm=1001.2101.3001.4242

MobileNet 进化史： 从 V1 到 V3（V2篇）--重要!!!!!
https://blog.csdn.net/kuweicai/article/details/103267281?utm_medium=distribute.pc_relevant.none-task-blog-searchFromBaidu-5.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-searchFromBaidu-5.channel_param

MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications
MobileNetV1（2017）：https://arxiv.org/abs/1704.04861?context=cs
MobileNetV2: Inverted Residuals and Linear Bottlenecks
MobileNetV2（2018）：https://arxiv.org/abs/1801.04381
Searching for MobileNetV3
MobileNetV3（2019）：https://arxiv.org/abs/1905.02244?context=cs

mobilenet v1-v3
https://blog.csdn.net/TYUT_xiaoming/article/details/103176735?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-2&spm=1001.2101.3001.4242

语义分割之FCN、Deeplab V3+
https://blog.csdn.net/DaGongJiGuoMaLu09/article/details/90401407?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-10&spm=1001.2101.3001.4242
网络模型压缩和优化:MobileNet V2网络结构理解
https://blog.csdn.net/wfei101/article/details/79334659?utm_medium=distribute.pc_relevant.none-task-blog-title-5&spm=1001.2101.3001.4242

MobileNet详细总结以及代码讲解---可分离卷积
https://blog.csdn.net/qq128252/article/details/105885880?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-9.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-9.channel_param

MobileNet教程：用TensorFlow搭建在手机上运行的图像分类器
https://blog.csdn.net/jp_666/article/details/76546296?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
//////////////////////////////////
pip install pycocotools
conda search --full-name  pycocotools
conda search --full-name easydict
https://pypi.tuna.tsinghua.edu.cn/simple/
pip install  tqdm==4.23.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/

pip install easydict

解决 : ModuleNotFoundError: No module named 'pycocotools._mask'
https://blog.csdn.net/qq_38343151/article/details/105376794
COCO数据集及COCOAPI
https://zhuanlan.zhihu.com/p/84214563

COCO API安装
https://blog.csdn.net/qq_37674858/article/details/89241803
git clone https://github.com/cocodataset/cocoapi.git
# COCOAPI=/path/to/clone/cocoapi
git clone https://github.com/cocodataset/cocoapi.git $COCOAPI
cd $COCOAPI/PythonAPI
# Install into global site-packages
make install
# Alternatively, if you do not have permissions or prefer
# not to install the COCO API into global site-packages

python setup.py install --user

COCO数据集使用——COCO API配置
https://blog.csdn.net/aaon22357/article/details/82963108?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
conda install numpy=1.19.1
以上依然报错：ModuleNotFoundError: No module named 'pycocotools._mask' 
最后解决：
在/home/10087295/data1/cocoapi/cocoapi/PythonAPI目录执行make，执行后会生成_mask二进制文件,最后就能成功编过。


GPU可见查询
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ['CUDA_VISIBLE_DEVICES']='2'

根据pid查用户账户：
ps -eo pid,user | grep 10308

conda install pytorch torchversion cudatoolkit =10.0 -c pytorch
conda install pytorch torchvision cudatoolkit=10.1 -c pytorch
conda install pytorch=0.4.0 cuda90 -c pytorch

conda create --name potrait_pytorch_030post python=2.7

torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl
https://download.pytorch.org/whl/cu100/torch_stable.html

conda install pytorch==1.1.0 torchvision==0.3.0 cudatoolkit=10.0 -c pytorch
# CUDA 10.0
conda install pytorch==1.0.0 torchvision==0.2.1 cuda100 -c pytorch
>>> import torch
>>> torch.__version__
'0.4.0'
>>> torch.cuda.is_available()

//0821
tar –xvf file.tar //解压 tar包
tar -xzvf file.tar.gz //解压tar.gz

//0822
Depthwise卷积与Pointwise卷积
https://blog.csdn.net/tintinetmilou/article/details/81607721
普通卷积和可分离卷积的参数量和计算量以及FLOPS的计算
https://blog.csdn.net/justsolow/article/details/106144091?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
一文看尽9篇语义分割最新论文（GPSNet/Graph-FCN/HMANet等）
https://blog.csdn.net/fengdu78/article/details/104438002?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param
语义分割最新资料汇总------开源代码，文献集合----重要！！！！！！！！！！！
https://blog.csdn.net/qq_18315295/article/details/91401691?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
语义分割源代码----------------重要！！！！！！！！！！！
https://download.csdn.net/download/qq_29462849/10823289
语义分割+视频分割 开源代码文献集合-----重要！！！！
https://blog.csdn.net/zhangjunhit/article/details/78190283
开源|如何利用Tensorflow实现语义分割全卷积网络（附源码）
https://blog.csdn.net/scutjy2015/article/details/70230379?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
DeepLabv3+图像语义分割实战：训练自己的数据集----重要，B站有免费的视频
https://edu.csdn.net/course/detail/25328?utm_medium=distribute.pc_relevant_t0.none-task-course-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-course-BlogCommendFromMachineLearnPai2-1.channel_param

//0824
相对熵（KL散度）
https://blog.csdn.net/weixinhum/article/details/85064685
交叉熵、相对熵及KL散度通俗理解
https://blog.csdn.net/colourful_sky/article/details/78534122?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
相对熵（KL散度）----重要，说的很清楚！！！！
https://blog.csdn.net/u010032054/article/details/62056643?utm_medium=distribute.pc_relevant.none-task-blog-title-1&spm=1001.2101.3001.4242
 法详见：https://github.com/johnmyleswhite/KLDivergence.jl
class torch.nn.KLDivLoss(size_average=True, reduce=True)------重要，pytorch如何计算KL散度！！！！！！！！！！！
https://blog.csdn.net/u013548568/article/details/88932038 

//0825
显卡信息显示：
lspci  | grep -i vga
lspci | grep -i nvidia

查看显卡情况：
nvidia-smi
指定显卡序号：
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ['CUDA_VISIBLE_DEVICES']='0' 

根据pid查用户账户：
ps -eo pid,user | grep 10308

conda install tensorboard=1.14.0
conda install tensorflow-gpu=1.14.0
conda install tensorflow==1.14.0
 
模型存储位置：
/home/10087295/data1/PortraitNet/PortraitNet_only/PortraitNet/myexp/mobilenetv2_eg1800/both_224_without_group
conda安装gpu版本tensorflow
https://blog.csdn.net/bingo_liu/article/details/103620628
ensorflow 安装GPU版本，个人总结，步骤比较详细
https://blog.csdn.net/gangeqian2/article/details/79358543?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
conda/pip两种快速安装Tensorflow-gpu的方式
https://blog.csdn.net/Never__Say__No/article/details/105000916?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param

python学习——Anaconda及TensorFlow-GPU版本安装
https://blog.csdn.net/qq_35077107/article/details/94555320?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
TensorFlow 安装GPU版本-----重要！！！！！
https://blog.csdn.net/AAlonso/article/details/81504036?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.channel_param
TensorFlow-gpu安装（100%成功）
https://blog.csdn.net/SINKEDKLUV/article/details/100577436?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

执行 tensorboard --logdir logs之后遇到的浏览器中输入http://localhost:6006 网址打不开的问题
https://blog.csdn.net/sinat_28442665/article/details/81076600?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param

Visualization：
可视化训练过程：
cd path_to_save_model
tensorboard --logdir='./log'
执行后打印：
TensorBoard 1.14.0 at http://amax:6006/ (Press CTRL+C to quit)
在本机输入网址访问：
http://10.74.53.16:6006/

//0827
Deep Image Matting
https://blog.csdn.net/u011511601/article/details/79457275?utm_medium=distribute.pc_relevant_download.none-task-blog-searchfrombaidu-2.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-searchfrombaidu-2.nonecas
PyTorch 常用操作记录
http://ishero.net/PyTorch%20%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E8%AE%B0%E5%BD%95.html
Numpy：numpy.ogrid() 生成数组
https://blog.csdn.net/weixin_40522801/article/details/106580104
Pythorch入门（3）Pythorch的常见操作,PyTorch,三,常用
https://www.pythonf.cn/read/5242
PyTorch中文文档-----重要！！！！！！！！！！！！！！！！pytorch参考 API参考
https://pytorch-cn.readthedocs.io/zh/latest/
Python range() 函数用法----Python主要函数API说明：
https://www.runoob.com/python/python-func-range.html
anaconda装了pytorch，但是jupyter一直显示No module named ‘torch‘
解决办法：conda install nb_conda_kernels
https://blog.csdn.net/weixin_42707971/article/details/100694574?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param

pyotrch]nn.Conv2d中groups参数的理解
https://blog.csdn.net/monsterhoho/article/details/80173400
pytorch的函数中的group参数的作用
https://www.cnblogs.com/wanghui-garcia/p/10775851.html
对于组卷积(GROUP CONVOLUTIONAL)的理解(TORCH.NN.CONV2D中的GROUP参数)
https://www.freesion.com/article/9320430513/
深度可分离卷积
https://blog.csdn.net/makefish/article/details/88716534
对深度可分离卷积、分组卷积、空洞卷积、转置卷积的理解
https://blog.csdn.net/YQMind/article/details/82977172?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

[论文阅读]MobileNetV2: Inverted Residuals and Linear Bottlenecks
https://www.cnblogs.com/hejunlin1992/p/9395345.html
CNN基础知识——卷积（Convolution）、填充（Padding）、步长(Stride)------重要！！！！！！
https://zhuanlan.zhihu.com/p/77471866
PyTorch 学习笔记（四）：权值初始化的十种方法
https://www.cnblogs.com/jfdwd/p/11269622.html
pytorch学习(9) 提取参数及自定义初始化
https://zhuanlan.zhihu.com/p/52297770
NN模型设置--反卷积层的参数设置--将反卷积层的学习率设为0，upsample的方式就是默认的双线性插值
https://blog.csdn.net/wydbyxr/article/details/84834749
pytorch Module named_parameters 解析---注意print(f"name: {name}, param: {param}")的用法
https://www.jianshu.com/p/bb88f7c08022
训练中动态调整学习率lr，optimizer.param_groups
https://blog.csdn.net/bc521bc/article/details/85864555
pytorch中优化器optimizer.param_groups[0]是什么意思
https://blog.csdn.net/AWhiteDongDong/article/details/106143413

//0831
Pytorch model.train 与 model.eval的区别（我是搬运工）
https://blog.csdn.net/qq_32678471/article/details/102892930?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

Pytorch常用的交叉熵损失函数CrossEntropyLoss()详解---重要！！！！
Pytorch中CrossEntropyLoss()函数的主要是将softmax-log-NLLLoss合并到一块得到的结果
https://www.jianshu.com/p/6049dbc1b73f
Pytorch详解NLLLoss和CrossEntropyLoss---重要，说的很清楚，有步奏，形象！！！！
https://blog.csdn.net/qq_22210253/article/details/85229988

pytorch系列12 --pytorch自定义损失函数custom loss function
https://blog.csdn.net/dss_dssssd/article/details/84103834
PyTorch 中 backward() 详解
https://www.pytorchtutorial.com/pytorch-backward/
Pytorch的backward()相关理解----重要，比较深刻，未看懂！！！！
https://blog.csdn.net/douhaoexia/article/details/78821428
pytorch中backward()函数详解-----重要，讲得比较透彻
https://blog.csdn.net/sinat_28731575/article/details/90342082?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
pytorch的计算图----重要，计算的心得总结
https://zhuanlan.zhihu.com/p/33378444
backward()函数中的参数解析-----------------重要，雅克比矩阵矩阵含义说的很清楚
https://blog.csdn.net/xiangyong58/article/details/103787404?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param
pytorch之gather函数
https://blog.csdn.net/qq_35027690/article/details/103281280

//0901
Python numpy.transpose 详解
https://blog.csdn.net/u012762410/article/details/78912667
Python Numpy模块函数np.c_和np.r_
https://www.cnblogs.com/shaosks/p/9890787.html
cv2.warpAffine 参数详解
https://blog.csdn.net/qq878594585/article/details/81838260
Python图像处理库PIL的ImageEnhance模块介绍
https://blog.csdn.net/icamera0/article/details/50753705
Python下opencv使用笔记（五）（图像的平滑与滤波）
https://blog.csdn.net/on2way/article/details/46828567
opencv: 阈值处理(cv2.threshold) 探究(图示+源码)。
https://blog.csdn.net/JNingWei/article/details/77747959
python-opencv2利用cv2.findContours()函数来查找检测物体的轮廓
https://blog.csdn.net/hjxu2016/article/details/77833336
opencv---cv2.drawContours() 轮廓绘制
https://zhuanlan.zhihu.com/p/140514938

//0902
git commit -m "add local_test_v1_quantize.sh and modify output_stride" 
git push origin dev:refs/for/dev
data0盘映射：
ln -s  /data0  data0 

cp -rp /home/10087295/data0/liulili/zte_seg/origin_pictures/ORIGINAL_JPEGImages .
Ubuntu14.04下修改权限时出现"unable to execute /bin/chmod: Argument list too long"   ，大概意思是卧槽，你这参数也太特么长了。
解决方法：find ./ -print0 | xargs -0 chmod 644 (意思是把当前目录下的所有文件的权限改为664)
注意：-print0 中的0指的是“零”，不是“哦”    ；  xargs -0中的0也是“零”，不是“哦”
最后修改：
find ./ -print0 | xargs -0 chmod 777

/home/10087295/data0/liulili/zte_seg/origin_pictures
cp -rp /home/10087295/data0/liulili/zte_seg/origin_pictures/ORIGINAL_JPEGImages .
cp -rp /home/10087295/data0/liulili/zte_seg/origin_pictures/ORIGINAL_SegmentationClassRaw .
cp -rp /home/10087295/data0/liulili/zte_seg/origin_pictures/output_image .
cp -rp /home/10087295/data0/liulili/zte_seg/origin_pictures/output_label .
cp -rp /home/10087295/data0/liulili/zte_seg/origin_pictures/tfrecord_0808 .
find . -name data_augument_all.py

//0903

tensorboard --logdir='./log' --port=8009
 
pytorch如何使用多块gpu?
https://www.zhihu.com/question/67726969

Tmux 使用教程
https://www.ruanyifeng.com/blog/2019/10/tmux.html
tmux ls
tmux new -s zdm_pnet_t_0903
tmux new -s zdm_pnet_t_0903_view
http://10.74.53.16:8009/
tensorboard --logdir='./log' --port=8009

tmux attach -t zdm_pnet_t_0903
tmux kill-session -t zdm_pnet_t_0903
tmux switch -t zdm_pnet_t_0903
tmux detach

//0904

深度学习中的图像数据扩增(Data Augmentations)方法总结：常用传统扩增方法及应用
https://blog.csdn.net/kuweicai/article/details/106590031
简单粗暴 TensorFlow 2.0
https://www.bookstack.cn/read/TensorFlow2.0/c3c22b4a1d6d2073.md

Tensorflow 损失函数（loss function）及自定义损失函数（一）
https://blog.csdn.net/limiyudianzi/article/details/80693695
（三）tensorflow2.0 - 自定义loss function（损失函数）
https://blog.csdn.net/qq_32623363/article/details/104154418?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book

//0907
Softmax函数
https://zh.wikipedia.org/wiki/Softmax%E5%87%BD%E6%95%B0
【最强ResNet改进系列】Res2Net：一种新的多尺度网络结构，性能提升显著
https://blog.csdn.net/weixin_47196664/article/details/107873450
Res2Net：新的深度学习多尺度结构，提升物体检测立竿见影
https://blog.csdn.net/u011984148/article/details/101444177?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
官方的Res2Net仓库：https://github.com/gasvn/Res2Net
Res2NetPlus结构：https://github.com/lessw2020/res2net-plus
Res2Net论文解读
https://blog.csdn.net/zw__chen/article/details/89035192?utm_medium=distribute.pc_relevant.none-task-blog-title-1&spm=1001.2101.3001.4242
Res2net：多尺度骨干网络结构
https://blog.csdn.net/baobo8666/article/details/102308718?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

ResNet网络解析和代码实现
https://blog.csdn.net/Dominic_S/article/details/82500701?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
深度学习—激活函数详解（Sigmoid、tanh、ReLU、ReLU6及变体P-R-Leaky、ELU、SELU、Swish、Mish、Maxout、hard-sigmoid、hard-swish）
https://blog.csdn.net/jsk_learner/article/details/102822001
最全面：python绘制Sigmoid、Tanh、Swish、ELU、SELU、ReLU、ReLU6、Leaky ReLU、Mish、hard-Sigmoid、hard-Swish等激活函数（有源码）
https://blog.csdn.net/jsk_learner/article/details/102824140

//0910
Squeeze-and-Excitation
https://zhuanlan.zhihu.com/p/110952738
计算机视觉中的注意力机制研究
https://www.jianshu.com/p/55d793085e6d

//0911
使用MobileNetV3作为预训练模型遇到的问题及解决方法
https://blog.csdn.net/A_water_/article/details/107217475?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
神经网络学习小记录39——MobileNetV3（small）模型的复现详解
https://blog.csdn.net/weixin_44791964/article/details/104069624?utm_medium=distribute.pc_relevant.none-task-blog-title-5&spm=1001.2101.3001.4242
超越 MobileNetV3！谷歌大脑提出 MixNet 轻量级网络，已开源
https://toutiao.io/posts/syjppz/preview
【转载】 Tensorflow如何直接使用预训练模型(vgg16为例)
https://www.cnblogs.com/devilmaycry812839668/p/12427443.html

deeplab分割Demo地址：
http://10.63.228.28:8888/notebooks/zhuyan/research_20200311/deeplab/deeplab_demo_zte.ipynb

HZ模型：
https://github.com/openai/gpt-2
git clone https://github.com/openai/gpt-2.git
2020-09-11 16:07:03*[黄征00111069]说:
里面有个脚本下载预训练模型
2020-09-11 16:07:23*[黄征00111069]说:
python3 download_model.py 124M
python3 download_model.py 355M
python3 download_model.py 774M
python3 download_model.py 1558M
2020-09-11 16:10:27*[黄征00111069]说:
需要通过命令下载不同的预训练好的模型

Beyond Compare之PC与UNIX文件比较问题
https://blog.csdn.net/wallying/article/details/77450111

//0914
训练流程系列：
（超详细很完整）tensorflow上实现deeplabv3+
https://blog.csdn.net/malvas/article/details/88896283
（超详细很完整）tensorflow下利用deeplabv3+对自己的数据进行训练----非常重要，全程参考！！！！！！！！！！！！！！！
https://blog.csdn.net/malvas/article/details/90776327?utm_medium=distribute.pc_relevant.none-task-blog-title-3&spm=1001.2101.3001.4242
使用labelme标注语义分割数据
https://blog.csdn.net/malvas/article/details/89364284
使用 deeplabv3+ 训练自己的数据集经验总结
https://blog.csdn.net/Kelvin_XX/article/details/81946091?utm_source=blogxgwz7&utm_medium=distribute.pc_relevant.none-task-blog-title-10&spm=1001.2101.3001.4242
使用 deeplabv3+ 训练自己的数据集经验总结
https://blog.csdn.net/Kelvin_XX/article/details/81946091?utm_source=blogxgwz7&utm_medium=distribute.pc_relevant.none-task-blog-title-10&spm=1001.2101.3001.4242

源码分析系列：
TF学习之DeepLabv3+代码阅读1(train)
https://blog.csdn.net/lscelory/article/details/97787373?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase

deeplabv3+系列名博---------重要，必看！！！！！！！！！！
https://blog.csdn.net/u013249853/category_9259868.html
【代码】deeplabv3+ model train 模型 训练 代码 全网最详细解析
https://blog.csdn.net/u013249853/article/details/100698255?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
deeplabv3+ 代码解析 去除decoder 部分
https://blog.csdn.net/u013249853/article/details/100888501?utm_medium=distribute.pc_relevant.none-task-blog-title-1&spm=1001.2101.3001.4242

图像语义分割 — 利用Deeplab v3+训练自己的数据 loss震荡解决办法
https://blog.csdn.net/weixin_41713230/article/details/81937763?utm_source=blogxgwz6

Deeplabv3+安装并运行自己的数据集
https://blog.csdn.net/niuniu924/article/details/94608983?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
超详细很完整）tensorflow下利用deeplabv3+对自己的数据进行训练
https://blog.csdn.net/niuniu924/article/details/94608983?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
deeplabV3+源码分解学习
https://www.jianshu.com/p/d0cc35b3f100

deeplab系列总结（deeplab v1& v2 & v3 & v3+）
https://blog.csdn.net/Kelvin_XX/article/details/81946091?utm_source=blogxgwz7&utm_medium=distribute.pc_relevant.none-task-blog-title-10&spm=1001.2101.3001.4242

deeplabv3+csdn系列：
https://blog.csdn.net/Kelvin_XX/article/details/81946091?utm_source=blogxgwz7&utm_medium=distribute.pc_relevant.none-task-blog-title-10&spm=1001.2101.3001.4242

语义分割算法之DeepLabV3+论文理解及源码解析
https://cloud.tencent.com/developer/article/1548866

训练deeplab v3+语义分割网络，明明正负样本不均衡，但训练后效果却很好，这是为什么，很迷茫？
https://www.zhihu.com/question/302229254?sort=created
最早的deeplab的正负样本不均衡问题需要手动在loss函数上进行权重调整分配，估计后来更新的repo里面使用了focal loss一类的loss function，自动的调节了正负样本不均衡的问题。
//0917

tf.einsum
tf.one_hot()函数简介
https://blog.csdn.net/nini_coded/article/details/79250600
tf.einsum()简单使用
https://blog.csdn.net/qq_35203425/article/details/81560118
einsum满足你一切需要：深度学习中的爱因斯坦求和约定
https://zhuanlan.zhihu.com/p/44954540?utm_source=wechat_timeline
【深度学习中的神仙操作】einsum爱因斯坦求和
https://zhuanlan.zhihu.com/p/74462893

tf.nn.softmax_cross_entropy_with_logits_v2
https://zhuanlan.zhihu.com/p/95627047

tensorflow之focal loss 实现
https://blog.csdn.net/qq_38742161/article/details/89396655
tensorflow自定义的损失函数 focal_loss出现inf，在训练过程中出现inf
https://ask.csdn.net/questions/759877

focal_loss设计：
def focal_loss(lables, predictions,alpha=0.5, gamma=2., epsilon=1e-6):
        positive = tf.where(tf.equal(lables, 1), predictions, tf.ones_like(predictions))
        negative = tf.where(tf.equal(lables, 0), predictions, tf.zeros_like(predictions))
#         return  tf.log(predictions + epsilon)
        return -alpha * ((1. - positive)** gamma) * tf.log(positive + epsilon) - \
            (1-alpha) * (negative ** gamma) * tf.log(1.-negative + epsilon)

def _div_maybe_zero(total_loss, num_present):
  """Normalizes the total loss with the number of present pixels."""
  return tf.to_float(num_present > 0) * tf.math.divide(
      total_loss,
      tf.maximum(1e-5, num_present))

lables = [0,1,0,1,1,1,0,0,1,1]
predictions = [0.1,1.0,0.5,1.0,1.0,0.1,1.0,0.5,1.0,1.0]
# predictions = [0.,1.,0.,1.,1.,1.,0.,0.,1.,1.]
# predictions = [1.,0.,1.,0.,0.,0.,1.,1.,0.,0.]
keep_mask =[1.,1.,1.,1.,1.,1.,1.,1.,1.,1.]
num_present = tf.reduce_sum(keep_mask)
pixelLoss = focal_loss(lables,predictions)
totalLoss = tf.reduce_sum(pixelLoss)
loss = _div_maybe_zero(totalLoss, num_present)
sess = tf.Session()
sess.run(num_present)
sess.run(pixelLoss)
sess.run(totalLoss)
sess.run(loss)
//0920
import tensorflow as tf
def focal_loss(lables, predictions,alpha=0.5, gamma=2., epsilon=1e-6):
        positive = tf.where(tf.equal(lables, 1), predictions, tf.ones_like(predictions))
        negative = tf.where(tf.equal(lables, 0), predictions, tf.zeros_like(predictions))
        return -alpha * ((1. - positive)** gamma) * tf.log(positive + epsilon) - \
            (1-alpha) * (negative ** gamma) * tf.log(1.-negative + epsilon)

def softmax_focal_loss(lables, predictions, alpha=0.5, gamma=2., epsilon=1e-6):
    soft = tf.nn.softmax(predictions,-1)
    return focal_loss(lables, soft[:,-1], alpha, gamma, epsilon)

def avg_softmax_focal_loss(labels, predictions, alpha=0.5, gamma=2., epsilon=1e-6):
    # predictions：[n,2]，labels:[n]"""
    soft = tf.nn.softmax(predictions,-1)
    softp = soft[:,-1]
    # soft_focal：[n],softp:[n]"""
    soft_focal = focal_loss(labels, softp, alpha, gamma, epsilon)
    totalLoss = tf.reduce_sum(soft_focal)
    softpsum = tf.reduce_sum(tf.ones_like(softp))
    avgloss = _div_maybe_zero(totalLoss, softpsum)
    return avgloss

def _div_maybe_zero(total_loss, num_present):
  # Normalizes the total loss with the number of present pixels."""
  return tf.to_float(num_present > 0) * tf.math.divide(
      total_loss,
      tf.maximum(1e-5, num_present))

# the following test code:

labels = [0,1,0,1,0,1,0,1,0,1]

# test 0 loss: 
pred = [[100.,1.],[2.,100.],[300.,2.],[3.,400.],[100.,1.],[2.,100.],[300.,2.],[3.,400.],[300.,20.],[3.,400.]]
# test full loss: 
# pred = [[1.,100.],[100.,2.],[2.,300.],[400.,3.],[1.,100.],[100.,2.],[2.,300.],[400.,3.],[20.,300.],[400.,3.]]
# test normal 
# pred = [[100.,10.],[200.,100.],[30.,20.],[30.,400.],[10.,100.],[200.,100.],[30.,20.],[30.,40.],[300.,20.],[300.,400.]]

print("test debug soft ... ")
soft = tf.nn.softmax(pred,-1)
print(sess.run(soft))

print("test debug org labels ... ")
print (labels)
print("test debug pred softp ... ")
softp = soft[:,-1]
print(sess.run(softp))

print("test debug softpsum ... ")
softpsum = tf.ones_like(softp)
print(sess.run(softpsum))

soft_focal = softmax_focal_loss(labels, pred)
print("test debug soft_focal ... ")
sess = tf.Session()
print(sess.run(soft_focal))

print("test debug avg loss ... ")
num_present = tf.reduce_sum(softpsum)
totalLoss = tf.reduce_sum(soft_focal)
avg_loss = _div_maybe_zero(totalLoss, num_present)
print(sess.run(avg_loss))

print("test debug avg avg_loss_direct ... ")
labelsNoGrad =tf.stop_gradient(labels, name='labels_stop_gradient')
avg_loss_direct=  avg_softmax_focal_loss(labelsNoGrad, pred, alpha=0.5, gamma=2., epsilon=1e-6)
print(sess.run(avg_loss_direct))

Out put:
test debug soft ... 
[[1. 0.]
 [0. 1.]
 [1. 0.]
 [0. 1.]
 [1. 0.]
 [0. 1.]
 [1. 0.]
 [0. 1.]
 [1. 0.]
 [0. 1.]]
test debug org labels ... 
[0, 1, 0, 1, 0, 1, 0, 1, 0, 1]
test debug pred softp ... 
[0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]
test debug softpsum ... 
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
test debug soft_focal ... 
[-0. -0. -0. -0. -0. -0. -0. -0. -0. -0.]
test debug avg loss ... 
0.0
test debug avg avg_loss_direct ... 
0.0

//0921
[TensorFlow笔记] 获取Tensor的维度（tf.shape(x)、x.shape和x.get_shape()的区别）
https://blog.csdn.net/guolindonggld/article/details/79281938
tf.expand_dims和tf.squeeze函数
https://blog.csdn.net/qq_31780525/article/details/72280284
tensorflow gfile文件操作详解
https://zhuanlan.zhihu.com/p/31536538
TensorFlow全新的数据读取方式：Dataset API入门教程---重要，细读！！！！
https://zhuanlan.zhihu.com/p/30751039

通俗理解tf.name_scope()、tf.variable_scope()
https://zhuanlan.zhihu.com/p/52055580
1、name_scope不会作为tf.get_variable变量的前缀，但是会作为tf.Variable的前缀。（举例1）
2、在variable_scope的作用域下，tf.get_variable()和tf.Variable()都加了scope_name前缀。
因此，在tf.variable_scope的作用域下，通过get_variable()可以使用已经创建的变量，实现了变量的共享，即可以通过get_variable()在tf.variable_scope设定的作用域范围内进行变量共享。（举例2）
3、在重复使用的时候, 一定要在代码中强调 scope.reuse_variables()
tensorflow之tf.name_scope()与tf.variable_scope()的区别---重要，此文讲得很详细，例子也举得很好！！！
https://zhuanlan.zhihu.com/p/37711713

tf.concat, tf.stack和tf.unstack的用法
https://blog.csdn.net/LoseInVain/article/details/79638183?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
tensorflow的tf.pad函数详细介绍
https://blog.csdn.net/sinat_29957455/article/details/80903913
 outputs = padded + pad_value
tf.slice函数解析
https://www.cnblogs.com/cloud-ken/p/8457077.html


//0923
增强出错：9986_aug_1.png
conda create -n deeplabv3_py36_tf14  python=3.6 anaconda  
conda install tensorflow-gpu=1.14 
conda install nb_conda
conda search --full-name tensorflow
conda search --full-name tensorflow-gpu
tmux ls
tmux new -s zdm_pnet_t_0903
tmux new -s zdm_pnet_t_0903_view
http://10.74.53.16:8009/
tensorboard --logdir='./log' --port=8009

tmux attach -t zdm_pnet_t_0903
tmux kill-session -t zdm_pnet_t_0903
tmux switch -t zdm_pnet_t_0903
tmux detach

ps -eo pid,user | grep 10308
 
工作目录：
D:\pydev\torchPro\setealtest\PortraitNet\data\edge_extractor.py
Q:\10087295\data1\PortraitNet\PortraitNet_only\PortraitNet\data\edge_extractor.py

D:\pydev\torchPro\setealtest\models-master_20200820\research
Q:\10087295\data1\deeplabv3plus\models-master_20200820\research

D:\AI_git\AI\CV\Demo\SemanticSegmentation\lll\models-master_20200820\research\
D:\pydev\torchPro\setealtest\models-master_20200820\research

原始差异对比目录：
D:\AI_git\AI\CV\Demo\SemanticSegmentation\lll\models-master_20200820\research\
D:\AI_git\AI\CV\Demo\SemanticSegmentation\zy\research_20200311_v1

import tensorflow as tf
tf.__version__
'1.6.0'
tf.__path__

sh脚本\多行连接不认识报错解决方法：
用notepad把sh文件转为Unix格式
shell脚本空行造成“: not found.sh“报错的解决方法
https://www.cnblogs.com/willingtolove/p/13387424.html

//0924
tmux new -s zdm_deeplab_t_0924
tmux new -s zdm_deeplab_t_0924_view

http://10.74.53.16:8009/
tensorboard --logdir='./log' --port=8009

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_6000_0924.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_6000_0924.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_6000_0924.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc frozen_inference_graph_6000_0924_dsp.dlc

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_6000_0924_edge_18.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_6000_0924_edge_18.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_6000_0924_edge_18.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc frozen_inference_graph_6000_0924_edge_18_dsp.dlc

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_6000_0924_edge_18_full.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path frozen_inference_graph_6000_0924_edge_18_full.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_6000_0924_edge_18_full.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc frozen_inference_graph_6000_0924_edge_18_full_dsp.dlc

snpe-dlc-viewer -i frozen_inference_graph_6000_0924_edge_18_full_dsp.dlc -s frozen_inference_graph_6000_0924_edge_18_full.html

outputs_to_scales_to_logits={
	‘semantic’:{
		‘merged_logits’:[n，161，121，2 ]
	}
}

Tensorflow之调试(Debug)及打印变量
https://www.cnblogs.com/huangshiyu13/p/6721805.html

//0925
http://10.74.53.16:8009/#scalars
snpe-tensorflow-to-dlc --input_network frozen_inference_graph_edge2000.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path frozen_inference_graph_edge2000.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_edge2000.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc frozen_inference_graph_edge2000_dsp.dlc

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_edge25000.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path frozen_inference_graph_edge25000.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_edge25000.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc frozen_inference_graph_edge25000_dsp.dlc

/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/JPEGImages
/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/SegmentationClassRaw
/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/39311_aug
/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/39311/val.txt
/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/ORIGINAL_JPEGImages
/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/ORIGINAL_SegmentationClassRaw

tmux new -s zdm_deeplab_t_0924_view
tmux new -s zdm_deeplab_t_0924_view_2
tmux new -s zdm_deeplab_t_0924_make_edge
tmux new -s zdm_deeplab_t_0924_make_edge_12
tmux kill-session -t zdm_pnet_t_0903

scp -rp  10005358@10.63.228.28:/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/39311_aug ./
scp -rp  10005358@10.63.228.28:/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/39311 ./
scp -rp  10005358@10.63.228.28:/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/JPEGImages ./
scp -rp  10005358@10.63.228.28:/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/SegmentationClassRaw ./
scp -rp  10005358@10.63.228.28:/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/ORIGINAL_JPEGImages ./
scp -rp  10005358@10.63.228.28:/home/10005358/MyDoc/zhuyan/research_191108/deeplab/datasets/zte_seg/zte_images/ORIGINAL_SegmentationClassRaw ./

\\1
ln -s  10.74.158.105:/volume1/AI_Share/ AI_Share

scp -rp  "zte\10087295@10.74.158.105:\volume1\AI_Share\HDR+\人像长曝光+拍月亮样张\月亮\数据集\datasetV1_1025_1025" ./
mount.nfs 10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/datasetV1_1025_1025   ./

sudo mount -t nfs  10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/datasetV1_1025_1025 ./

进入deeplab:
/home/10087295/data1/deeplabv3plus/models-master_20200820/research/deeplab

启动边缘提取：
python /data1/zhangdongming/PortraitNet/PortraitNet_only/PortraitNet/data/edge_extractor.py

tmux new -s tfrecord_138750_val_1000_12
tmux new -s tfrecord_138750_val_1000_18 
//0926
文件个数统计：
ls -l | grep "^-" | wc -l

0926
tmux new -s tfrecord_114933_val_1000_12
tmux new -s tfrecord_114933_val_1000_18 

0927
models-master_20200820/research/deeplab/datasets/zte_seg/exp_mnv3
http://10.74.53.16:8009/
tensorboard --logdir='./log' --port=8009
tensorboard --logdir='./train' --port=8009
conda install  imageio=2.6.0
conda search --full-name imageio

snpe-tensorflow-to-dlc --input_network lll_mnv3_opt_0925_edge18_quan_400000.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path lll_mnv3_opt_0925_edge18_quan_400000.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc lll_mnv3_opt_0925_edge18_quan_400000.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc lll_mnv3_opt_0925_edge18_quan_400000_dsp.dlc


snpe-tensorflow-to-dlc --input_network ll_mnv3_opt_0925_edge12_quan_400000.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path ll_mnv3_opt_0925_edge12_quan_400000.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc ll_mnv3_opt_0925_edge12_quan_400000.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc lll_mnv3_opt_0925_edge12_quan_400000_dsp.dlc

G:\我的文档\定制需求\2_AI\笔记文档\人像虚化\tool\ffmpeg-20191113-a7245ad-win64-static\bin\video_m2_all\A11_record
//0928
snpe-tensorflow-to-dlc --input_network lll_mnv3_opt_0925_edge18_quan_400000_edge.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path lll_mnv3_opt_0925_edge18_quan_400000_edge.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc lll_mnv3_opt_0925_edge18_quan_400000_edge.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc lll_mnv3_opt_0925_edge18_quan_400000_edge_dsp.dlc

snpe-tensorflow-to-dlc --input_network lll_mnv3_opt_0925_edge12_quan_400000_edge.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path lll_mnv3_opt_0925_edge12_quan_400000_edge.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc lll_mnv3_opt_0925_edge12_quan_400000_edge.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc lll_mnv3_opt_0925_edge12_quan_400000_edge_dsp.dlc

snpe-tensorflow-to-dlc --input_network lll_mnv3_opt_0925_edge12_quan_406000_zy_addloss.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path lll_mnv3_opt_0925_edge12_quan_406000_zy_addloss.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc lll_mnv3_opt_0925_edge12_quan_406000_zy_addloss.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc lll_mnv3_opt_0925_edge12_quan_406000_zy_addloss_dsp.dlc


tmux new -s tfrecord_114933_val_1000_12
tmux new -s tfrecord_114933_val_1000_18 

//0930
snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_0926_edge12_quan_360278.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_3" --output_path zyset_mnv3_opt_0926_edge12_quan_360278.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_0926_edge12_quan_360278.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_0926_edge12_quan_360278_dsp.dlc

snpe-tensorflow-to-dlc --input_network frozen_inference_graph_e1000.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path frozen_inference_graph_e1000.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc frozen_inference_graph_e1000.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc rz2_dsp_test_e1000.dlc

//1006
snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1003_edge18_quan_371000_03.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1003_edge18_quan_371000_03.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1003_edge18_quan_371000_03.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1003_edge18_quan_371000_03_dsp.dlc


//1009
https://github.com/hkchengrex/CascadePSP.
你参考这个 https://github.com/hkchengrex/CascadePSP
PSPNet implementation: https://github.com/Lextal/pspnet-pytorch
SyncBN implementation: https://github.com/vacancy/Synchronized-BatchNorm-PyTorch

DeeplabV3+、RefineNet、PSPNet、FCN-8s实现代码及输入：
https://github.com/hkchengrex/CascadePSP/blob/master/docs/dataset.md

//
CascadePSP：解决4K超高分辨率图像的分割，简单实用 | CVPR2020
https://blog.csdn.net/sinat_17456165/article/details/106935412
CascadePSP:级联PSP：通过全局和局部精炼实现对类无关和非常高分辨率的分割
https://blog.csdn.net/qq_41997237/article/details/106633876
一种高效的处理超高分辨图像分割的方法：CascadePSP CVPR2020
https://zhuanlan.zhihu.com/p/148466095?from_voters_page=true
CascadePSP-2020-CVPR- 分割论文阅读笔记
https://zhuanlan.zhihu.com/p/159118817
CascadePSP: 用于语义分割的全局修正模块和局部修正模块CVPR2020
https://zhuanlan.zhihu.com/p/149767428
高像素精度语义分割，CascadePSP
https://blog.csdn.net/dl643053/article/details/107663507?utm_medium=distribute.pc_relevant.none-task-blog-baidujs-2&spm=1001.2101.3001.4242

skip connections
https://www.cnblogs.com/yeshengCqupt/articles/9942718.html
语义分割之PSPNet个人总结
https://blog.csdn.net/LeeWanzhi/article/details/83388347?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
语义分割网络总结：FCN、SegNet、U-Net、PSPNet、RefineNet到DeepLab v1～v3+
https://blog.csdn.net/qq_19329785/article/details/95050626?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
CVPR 2020 论文大盘点-语义分割篇----重要！！！！最新进展
https://blog.csdn.net/moxibingdao/article/details/106880529?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
PSP-Net的理解（多尺度特征融合分割）
https://blog.csdn.net/chenlufei_i/article/details/94570372?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
目标分割(七)PSPNet讲解
https://blog.csdn.net/qq_40520596/article/details/104512818?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param
语义分割网络之PSPnet
https://blog.csdn.net/linolzhang/article/details/78536191?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param
语义分割之FCN、SegNet和PSPNet小结
https://blog.csdn.net/u013289254/article/details/106816815?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param

conda create -n cascade_psp
pip install segmentation-refinement

python 转位深 24位转8位
https://blog.csdn.net/hzm786287928/article/details/105918411
labelme 标注生成24位深度图像转换为8位
https://blog.csdn.net/MrYaoLing/article/details/94406931?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.channel_param

//1012
\\10.74.158.105\AI_Share\个人\zhangdongming\
python-opencv腐蚀膨胀处理
https://blog.csdn.net/JohinieLi/article/details/81041276
python opencv 图像处理 图像二值化、腐蚀、膨胀、填小洞
https://blog.csdn.net/nijiayan123/article/details/80093653

tmux new -s zy_set_adjust

//1015
tensorflow中设置保存checkpoint的最大数量
https://blog.csdn.net/lfs666666/article/details/85377406

slim.learning.train()参数：
https://blog.csdn.net/MOU_IT/article/details/82810953#6%E3%80%81slim.learning.train%28%29%3A%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83
saver = tf.train.Saver(max_to_keep=10)

 
1、边缘提取：
PC：
D:\pydev\torchPro\setealtest\PortraitNet\data\edge_extractor.py
Linux：
Q:\10087295\data1\PortraitNet\PortraitNet_only\PortraitNet\data\edge_extractor.py
Q:\10087295\data1\deeplabv3plus_zy_18\models-master_20200820\research\deeplab\datasets\edge_extractor.py

2、TFRecord生成：
PC:
D:\pydev\torchPro\setealtest\models-master_20200820\research\deeplab\datasets\download_and_convert_voc2012.sh
Linux：
Q:\10087295\data1\deeplabv3plus_zy_18\models-master_20200820\research\deeplab\datasets\download_and_convert_voc2012.sh

3、Cascade系列脚本
批量mask Cascade修复：
PC:
D:\pydev\torchPro\setealtest\CascadePSP_simple_test\test_all.py
Linux：
Q:\10087295\data1\CascadePSP\CascadePSP\segmentation-refinement\test_all.py
批量32位灰度转8位灰度：
PC:
D:\pydev\torchPro\setealtest\CascadePSP_simple_test\rgb_gray.py
Linux：
Q:\10087295\data1\CascadePSP\CascadePSP\segmentation-refinement\rgb_gray.py
批量黑屏label 2转黑白label 255：
PC:
D:\pydev\torchPro\setealtest\CascadePSP_simple_test\gray2_gray255.py
Linux：
Q:\10087295\data1\CascadePSP\CascadePSP\segmentation-refinement\gray2_gray255.py
批量黑白label 255转黑屏label 2：
PC:
D:\pydev\torchPro\setealtest\CascadePSP_simple_test\gray255_gray2.py
Linux：
Q:\10087295\data1\CascadePSP\CascadePSP\segmentation-refinement\gray255_gray2.py
批量连续label 255--0转黑白label 255：
PC:
D:\pydev\torchPro\setealtest\CascadePSP_simple_test\gray_continous_gray255.py
Linux：
Q:\10087295\data1\CascadePSP\CascadePSP\segmentation-refinement\gray_continous_gray255.py
批量连续label 255--0转黑屏label 2：
PC:
D:\pydev\torchPro\setealtest\CascadePSP_simple_test\gray_continous_gray2.py
Linux：
Q:\10087295\data1\CascadePSP\CascadePSP\segmentation-refinement\gray_continous_gray2.py

///////////////
TF 梯度提取
【Tensorflow】Tensorflow训练过程中使用边缘提取
https://blog.csdn.net/huang_nansen/article/details/103686347
tensorflow卷积实现图片轮廓提取
https://blog.csdn.net/yeler082/article/details/90445074
tensorflow进行图片边缘检测
https://blog.csdn.net/qq_37749442/article/details/102726942
Python-OpenCV 处理图像（五）：图像中边界和轮廓检测
https://blog.csdn.net/qq_26898461/article/details/50454547?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
tensorflow 读取图片进行边缘检测 并reshape后显示--重要！！！！！
https://blog.csdn.net/weixin_39739789/article/details/81386116?utm_medium=distribute.wap_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.wap_blog_relevant_no_pic&depth_1-utm_source=distribute.wap_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.wap_blog_relevant_no_pic
【TensorFlow】tf.nn.conv2d是怎样实现卷积的？
https://blog.csdn.net/mao_xiao_feng/article/details/53444333
【TensorFlow】tf.nn.conv2d底层卷积实现+filter计算原理
https://blog.csdn.net/xinyuski/article/details/85072630?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
使用卷积提取图片轮廓---重要！！！！
https://blog.csdn.net/chengqiuming/article/details/80289147?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param

//1017
解决linux终端路径过长的问题
https://blog.csdn.net/c20130911/article/details/78811299?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
总结了 150 余个神奇网站，你不来瞅瞅吗？
https://aoweibrave.blog.csdn.net/article/details/104750730?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-7.channel_param

tmux new -s tfrecord_114933_val_1000_18_org_fix 

//1019
snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1016_edge18_quan_351078_fix.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1016_edge18_quan_351078_fix.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1016_edge18_quan_351078_fix.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1016_edge18_quan_351078_fix_dsp.dlc/

//1026
snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1016_edge18_quan_363708_fix_org.pb --input_dim sub_2 "1,641,481,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1016_edge18_quan_363708_fix_org.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1016_edge18_quan_363708_fix_org.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1016_edge18_quan_363708_fix_org_dsp.dlc

查主板型号：
，首先打开命令运行窗，点击“开始”菜单，输入“DxDiag”即可，然后点击运行。 2，接下来就会出现“DirectX诊断工具”，可以在里面查看到基本的信息了，包括主板型号

zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_dsp

tmux attach -t zdm_pnet_t_0903
tmux kill-session -t zdm_pnet_t_0903

//1029
https://pixabay.com/zh/
ffmpeg命令：
http://linux.51yip.com/search/ffmpeg

//1030
snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1280_720.pb --input_dim sub_2 "1,1025,1025,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1025.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1280_720.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1025_dsp.dlc

//1031

snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721.pb --input_dim sub_2 "1,1281,721,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721_dsp.dlc

snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1028_edge18_quan_365832_fix_1025_1025.pb --input_dim sub_2 "1,1025,1025,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1028_edge18_quan_365832_fix_1025_1025.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1028_edge18_quan_365832_fix_1025_1025.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1028_edge18_quan_365832_fix_1025_1025_dsp.dlc

snpe-dlc-info -i zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1280_720_dsp.dlc -s zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1280_720_dsp.csv
snpe-dlc-viewer -i zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1280_720_dsp.dlc -s zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_1280_720_dsp.html

snpe-dlc-info -i zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721_dsp.dlc -s zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721_dsp.csv
snpe-dlc-viewer -i zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721_dsp.dlc -s zyset_mnv3_opt_1028_edge18_quan_365832_fix_1281_721_dsp.html

//1102
tmux attach -t deeplabv3plus_zy_18_fix_1281
tmux new -s deeplabv3plus_zy_18_fix_1281
tmux kill-session -t deeplabv3plus_zy_18_fix_1281
tmux kill-session -t tfrecord_114933_val_1000_18_org_fix

//1103
snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_161_121.pb --input_dim sub_2 "1,161,121,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_161_121.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_161_121.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_161_121_dsp.dlc

snpe-tensorflow-to-dlc --input_network zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_129_97.pb --input_dim sub_2 "1,129,97,3" --out_node "ResizeBilinear_2" --output_path zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_129_97.dlc --allow_unconsumed_nodes
snpe-dlc-quantize --input_dlc zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_129_97.dlc --input_list  ../../data/cropped/raw_list.txt --override_params --bias_bitwidth 32 --output_dlc zyset_mnv3_opt_1016_edge18_quan_370528_fix_org_129_97_dsp.dlc

//1106
语义分割预处理与后处理方法
https://blog.csdn.net/weixin_43162240/article/details/105137693
//1109
用算法合成的背景虚化效果与用大光圈镜头拍出的效果相比差距有多大，主要区别在哪里？
https://www.zhihu.com/question/40186365
图像算法研究---背景虚化算法
https://blog.csdn.net/Trent1985/article/details/76037400
深度学习与图像处理之：人像背景虚化
https://blog.csdn.net/wujuxKkoolerter/article/details/86153502?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
深度学习与图像处理实例：人像背景虚化与背景替换
https://blog.csdn.net/wujuxkkoolerter/article/details/103127634/?utm_medium=distribute.pc_relevant.none-task-blog-title-6&spm=1001.2101.3001.4242
opencv高斯滤波GaussianBlur()详解(sigma取值)
https://blog.csdn.net/wuqindeyunque/article/details/103694900?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
opencv背景虚化（后篇）----重要
https://blog.csdn.net/qq_37059483/article/details/79444506?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
OpenCV背景虚化-（中篇）
https://blog.csdn.net/qq_37059483/article/details/79444496?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~first_rank_v2~rank_v28-14-79444496.nonecase&utm_term=%E8%83%8C%E6%99%AF%E8%99%9A%E5%8C%96&spm=1000.2123.3001.4430
Crimm Imageshop 2.3--小型绿色处理软件
https://www.cnblogs.com/Imageshop/p/3308782.html

//1110
opencv图像处理之在手机上实现背景虚化
https://blog.csdn.net/cnbloger/article/details/75004162?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~all~first_rank_v2~rank_v28-8-75004162.nonecase&utm_term=%E8%83%8C%E6%99%AF%E8%99%9A%E5%8C%96&spm=1000.2123.3001.4430
引导滤波/导向滤波（Guided Filter）
https://www.jianshu.com/p/4fce5af4dd3d
Guided Image Filtering
https://www.researchgate.net/publication/236228168_Guided_Image_Filtering
双边滤波与引导滤波
https://blog.csdn.net/aichipmunk/article/details/20704681
双边滤波与引导滤波
https://blog.csdn.net/pi9nc/article/details/26592377?utm_medium=distribute.pc_relevant.none-task-blog-title-2&spm=1001.2101.3001.4242
导向滤波(Guided Filter)公式详解----重要
https://blog.csdn.net/weixin_43194305/article/details/88959183
基于导向滤波的图像融合(GFF)---重要，图像融合
https://blog.csdn.net/weixin_43194305/article/details/90678312
导向滤波之图像融合（C++版） Image Fusion with Guided Filtering---重要，图像融合
https://blog.csdn.net/qq_41510657/article/details/107007341?utm_medium=distribute.pc_relevant.none-task-blog-title-6&spm=1001.2101.3001.4242

//1113
git commit -m "upload opengl shader code for y halo remove" 
git push origin master:refs/for/master
http://10.95.243.146:8080/c/AI/CV/VideoSegmentation/+/158793


//1116
10.74.158.105\AI_Share\HDR+\人像长曝光+拍月亮样张\月亮\数据集\已解析

PB GPU优化：
sudo bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=need_convert/model.ckpt-500000.pb \
--out_graph=need_convert/optimize_model.ckpt-500000.pb \
--inputs='ImageTensor' \
--outputs='SemanticPredictions' \
--transforms='
strip_unused_nodes(type=float, shape="1,641,481,3")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
flatten_atrous_conv
fold_batch_norms
fold_old_batch_norms'


sudo bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=moon/moon_train_181_val_20_20000_513.pb \
--out_graph=moon/opt_moon_train_181_val_20_20000_513.pb \
--inputs='ImageTensor' \
--outputs='SemanticPredictions' \
--transforms='
strip_unused_nodes(type=float, shape="1,513,513,3")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
flatten_atrous_conv
fold_batch_norms
fold_old_batch_norms'


sudo bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=moon/moon_train_181_val_20_20000_1025.pb \
--out_graph=moon/opt_moon_train_181_val_20_20000_1025.pb \
--inputs='ImageTensor' \
--outputs='SemanticPredictions' \
--transforms='
strip_unused_nodes(type=float, shape="1,1025,1025,3")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
flatten_atrous_conv
fold_batch_norms
fold_old_batch_norms'


参考资料：
如何使用transform_graph优化Tensorflow模型
https://www.thinbug.com/q/52309506
bazel build tensorflow/tools/graph_transforms:transform_graph
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=tensorflow_inception_graph.pb \
--out_graph=optimized_inception_graph.pb \
--inputs='Mul' \
--outputs='softmax' \
--transforms='
  strip_unused_nodes(type=float, shape="1,299,299,3")
  fold_constants(ignore_errors=true)
  fold_batch_norms
  fold_old_batch_norms
  round_weights(num_steps=256)'

/home/zhangdm/tensorflow_20200106_master/tensorflow_master/tensorflow

TF Lite浮点转换：
tflite_convert \
  --output_file=quantize_mnv3_mini_641_481_0423_resizebilinear_2_gpu.tflite \
  --graph_def_file=quantize_mnv3_mini_641_481_0423.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_2" \
  --input_shape=1,641,481,3 \
  --output_arrays="ResizeBilinear_2"
 
 
tflite_convert \
  --output_file=opt_moon_train_181_val_20_20000_513.tflite \
  --graph_def_file=opt_moon_train_181_val_20_20000_513.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_2" \
  --input_shape=1,513,513,3 \
  --output_arrays="ResizeBilinear_2"

tflite_convert \
  --output_file=opt_moon_train_181_val_20_20000_1025.tflite \
  --graph_def_file=opt_moon_train_181_val_20_20000_1025.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_2" \
  --input_shape=1,1025,1025,3 \
  --output_arrays="ResizeBilinear_2"
  
  
  
TF Lite量化转换：
tflite_convert \
  --output_file=optimized_quan_mnv3_dsp_test_3_512.tflite \
  --graph_def_file=optimized_quan_mnv3_aip_test_3_512.pb\
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --inference_input_type=QUANTIZED_UINT8 \
  --input_arrays="sub_2" \
  --input_shape=1,512,512,3 \
  --output_arrays="ResizeBilinear_2" \
  --std_dev_values=128 \
  --mean_values=128 \
  --default_ranges_min=0 \
  --default_ranges_max=6  

//1118
基于部件的人脸编辑与美化算法
https://blog.csdn.net/nzzfsw/article/details/87700990
opencv人脸检测+美颜
https://blog.csdn.net/qq_34914551/article/details/80302027?utm_medium=distribute.pc_relevant_download.none-task-blog-baidujs-1.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-baidujs-1.nonecase
opencv人像（人脸）美颜、磨皮
https://blog.csdn.net/xiakejiang/article/details/106019736?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param
[Opencv基础]人脸磨皮
https://blog.csdn.net/hongchengling2/article/details/107574175?utm_medium=distribute.pc_relevant.none-task-blog-title-3&spm=1001.2101.3001.4242
OpenCV实时美颜摄像并生成H264视频流
https://blog.csdn.net/zhangqipu000/article/details/52210391?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
基于OpenCV 的美颜相机推送直播流
https://blog.csdn.net/weixin_30383279/article/details/98440521?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.channel_param
人脸美颜技术----重要，框架
https://blog.csdn.net/confusingbird/article/details/102572303?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.channel_param
深度学习AI美颜系列---天天P图疯狂变脸算法，重要，系列
https://blog.csdn.net/trent1985/article/details/80295532?utm_medium=distribute.pc_relevant.none-task-blog-title-6&spm=1001.2101.3001.4242
OpenCV-C++-CUDA-05-高斯双边加速，实时美颜
https://blog.csdn.net/Daker_Huang/article/details/106869316?utm_medium=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-10.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-blogcommendfrombaidu-10.nonecas
深度学习AI美颜系列----基于抠图的人像特效算法
https://blog.csdn.net/qq_36178899/article/details/81556821?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-7&spm=1001.2101.3001.4242
人脸美白磨皮算法
https://www.cnblogs.com/celerychen/archive/2013/03/09/2951581.html
利用Python+opencv进行图像的缩放(附代码)
https://blog.csdn.net/weixin_43730228/article/details/84979285

利用Python读取图片exif敏感信息
https://www.cnblogs.com/sevck/p/10942219.html
Python获取照片Exif信息----重要
https://www.biaodianfu.com/exif-python.html
在Android中将EXIF标签(属性)写入并保存到JPEG图像
http://ddrv.cn/a/368830
如何在Android中将exif数据写入图像？
http://www.voidcn.com/article/p-ektkcgel-btg.html

一种具有细节保留功能的磨皮算法。
https://www.cnblogs.com/Imageshop/p/3576818.html

//1119
基于深度学习优化光照的暗光下的图像增强：
https://i.zte.com.cn/#/space/416eb09b7cb74421bf3c64e31dbbddcd/wiki/page/d32bd055fa5f4590a0d2628021a19d9e/view
python numpy矩阵的数据类型转换
https://blog.csdn.net/yitanjiong4414/article/details/88964725?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control

//1121
OpenCV—python 形态学处理（腐蚀、膨胀、开闭运算、边缘检测）
https://blog.csdn.net/wsp_1138886114/article/details/82917661

//1124
dos下文件夹拷贝命令：
xcopy /s /e C:\PROGRA~1 D:\
xcopy /s /e datasetV1_1025_1025 Q:\10087295\data1\Data\moon
cp -rp ./input_rgb_img/ "/q/10087295/data1/Data/moon_1025"
Python中打乱列表顺序 random.shuffle()的使用方法
https://blog.csdn.net/chichu261/article/details/83302736?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase

//1125
文件个数统计：
ls -l | grep "^-" | wc -l
查看当前目录文件夹大小：
du -h --max-depth=1 *

OpenCV探索之路（十八）：使用imwrite调整保存的图片质量
https://blog.csdn.net/u012308586/article/details/100933090?utm_medium=distribute.pc_relevant.none-task-blog-title-2&spm=1001.2101.3001.4242
YUV(NV21)图像数据到RGB颜色空间的转换
https://cggos.github.io/computervision/image-yuv-rgb.html
opencv图片旋转90度，180度，270度
https://blog.csdn.net/Anliya/article/details/90899061?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-2&spm=1001.2101.3001.4242


  
//1126
opencv
https://www.csdn.net/gather_22/MtTaEg0sMTk0NDgtYmxvZwO0O0OO0O0O.html
移动端视频进阶（三）：OpenCV的集成及视频帧转cv::Mat的相关操作
https://blog.csdn.net/aiynmimi/article/details/89386130?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-5.control

//图像增强论文：
深度光照估计的暗光图像增强（UPE）
https://i.zte.com.cn/#/space/416eb09b7cb74421bf3c64e31dbbddcd/wiki/page/d32bd055fa5f4590a0d2628021a19d9e/view
实时 AI 图像增强技术：3篇论文
https://i.zte.com.cn/#/space/416eb09b7cb74421bf3c64e31dbbddcd/wiki/page/77b97d45c95447e4a126070e1e9262e5/view
  
//1347
谷歌HDRplus研读（一）
https://blog.csdn.net/wgx571859177/article/details/79510805
快门背后的机器学习：实时 HDR+ 和双重曝光控制----重要
https://google.blog.csdn.net/article/details/108332177?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-4.control

HDRNet:
Deep Bilateral Learning for Real-Time Image (hdrnet) SIGGRAPH 2017 论文阅读
HDRNET碰到的坑
https://blog.csdn.net/u013049912/article/details/91419506?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-2.control

深度学习HDR算法总结:
https://blog.csdn.net/weixin_45250844/article/details/103207184?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-6.control
谷歌又放大招：视觉效果完胜其他SOTA的风格迁移网络，手机端可达实时4K---重要
https://blog.csdn.net/Extremevision/article/details/105765660?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-7.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-7.control
Google又发大招：高效实时实现视频目标检测
https://blog.csdn.net/Extremevision/article/details/88980970?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-6.control
移动端70+fps！谷歌新出高效实时视频目标检测
https://blog.csdn.net/moxibingdao/article/details/106666769?utm_medium=distribute.pc_relevant.none-task-blog-title-3&spm=1001.2101.3001.4242

Deep Snake : 基于轮廓调整的SOTA实例分割方法，速度32.3fps | CVPR 2020
https://blog.csdn.net/lichlee/article/details/105122144?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-8.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-8.control
git clone https://github.com/zju3dv/snake.git

//1201
python+opencv均值滤波，高斯滤波，中值滤波，双边滤波
https://blog.csdn.net/qq_27261889/article/details/80822270

//1202
推荐 ：完备的 AI 学习路线，最详细的资源整理！
https://i.zte.com.cn/#/space/08c501c448b047ecbc3bd57014251081/wiki/page/d9deecbf66a4407783cd0ae1487976b2/view

序列图像降噪论文：
Spatio-temporal Wiener filtering of image sequences using a parametric motion model---未下载到
https://ieeexplore.ieee.org/abstract/document/900931
一种基于运动估计的视频降噪算法--已下载
https://www.ixueshu.com/document/996cd84d6c0ba091318947a18e7f9386.html
基于时空联合滤波的高清视频降噪算法---浙大学报，已下载
https://www.ixueshu.com/document/fad7c01c8a744916318947a18e7f9386.html

基于Non_local means的时空联合视频降噪算法--已下载，参考价值较大
https://www.ixueshu.com/document/3750cf6b88dc8b126df4dd4e9b40aaf1318947a18e7f9386.html
https://xueshu.baidu.com/usercenter/paper/show?paperid=0fc5cb369ba5f133be5a3a2d8db9fa09&site=xueshu_se&hitarticle=1
基于时域和空域混合的低信噪比视频降噪算法及其分析--已下载，参考价值较大
https://www.ixueshu.com/document/19734847653e5590318947a18e7f9386.html
一种基于运动补偿的时域自适应视频降噪算法---未下载
https://www.ixueshu.com/document/4da86022a3a979424e7a1680eb7beffc318947a18e7f9386.html
一种基于时空联合的实时视频降噪算法--未下载
https://www.ixueshu.com/document/abb5ebcd021d8bc7318947a18e7f9386.html
一种基于运动检测的智能视频序列降噪算法--未下载
https://www.ixueshu.com/document/81d892931dd751d3.html
[0][10]_一种基于运动估计的3D视频降噪算法--未下载
https://wenku.baidu.com/view/2626ab1d10a6f524ccbf85d7.html

时序图像降噪处理--未下载，重要！！！！！
https://wenku.baidu.com/view/c86c72cc8bd63186bcebbcb6.html
图像去噪方法简介
https://www.cnblogs.com/ccbb/archive/2011/01/06/1929033.html


//1204
tmux new -s deeplabv3plus_moon_1025
tmux attach -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025

tmux new -s cascade_moon_png_jpeg
tmux attach -t cascade_moon_png_jpeg


mount挂载：
sudo mount -t nfs  "10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/datasetV1_1025_1025" .
sudo mount -t nfs  "10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/datasetV2_1025_1025" .


取消mount：
sudo umount datasetV1_1025_1025_mount/
ln -s  10.74.158.105:/volume1/AI_Share/ AI_Share
解决nfs挂载错误wrong fs type, bad option, bad superblock
https://blog.51cto.com/smoke520/1949833
apt-get install nfs-common

tmux attach -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025

tmux new -s cascade_moon_png_jpeg
tmux attach -t cascade_moon_png_jpeg

文件个数统计：
ls -l | grep "^-" | wc -l
查看当前目录文件夹大小：
du -h --max-depth=1 *

pb优化：
sudo bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=moon_1212/moon_mnv3_1204_train_354496_val_1000_800000_1025.pb \
--out_graph=moon_1212/opt_moon_mnv3_1204_train_354496_val_1000_800000_1025.pb \
--inputs='ImageTensor' \
--outputs='SemanticPredictions' \
--transforms='
strip_unused_nodes(type=float, shape="1,1025,1025,3")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
flatten_atrous_conv
fold_batch_norms
fold_old_batch_norms'

pb转tfLite：
tflite_convert \
  --output_file=opt_moon_mnv3_1204_train_354496_val_1000_800000_1025.tflite \
  --graph_def_file=opt_moon_mnv3_1204_train_354496_val_1000_800000_1025.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_2" \
  --input_shape=1,1025,1025,3 \
  --output_arrays="ResizeBilinear_2"

//1208
一种去除运动目标重影的图像镶嵌方法研究
https://www.ixueshu.com/document/64024802b1ed6f5f318947a18e7f9386.html
图说卡尔曼滤波，一份通俗易懂的教程---没时间细读，重要
https://zhuanlan.zhihu.com/p/39912633
卡尔曼滤波：从入门到精通
https://zhuanlan.zhihu.com/p/36745755

//1212
shearlet 剪切波的构造
https://wenku.baidu.com/view/a7aecfd1dd3383c4ba4cd24e.html

https://www.hindawi.com/journals/jam/2014/652128/
Image Sequence Fusion and Denoising Based on 3D Shearlet Transform

python+opencv均值滤波，高斯滤波，中值滤波，双边滤波
https://blog.csdn.net/qq_27261889/article/details/80822270

//1217
Numpy 基本除法运算和模运算
https://www.cnblogs.com/xieshengsen/p/6822772.html

//1221
高通开源了 AIMET
高通开源了一个 AI Model Efficiency Toolkit (AIMET)
https://github.com/quic/aimet

AIMET, which was open sourced by Qualcomm Innovation Center (QuIC), is a library that provides advanced quantization and compression techniques for trained neural network models. It is based on state-of-art work published in several Qualcomm AI Researchpapers. AIMET makes neural networks much smaller while maintaining accuracy, resulting in higher-performance models that consume less power, less memory bandwidth, and less storage. 

It includes: 
Cross-Layer Equalization: Equalize weight tensors to reduce amplitude variation across channels
Bias Correction: Corrects shift in layer outputs introduced due to quantization
Quantization Simulation: Simulate on-target quantized inference accuracy
Fine-tuning: Use quantization sim to train the model further to improve accuracy
Spatial SVD Compression: Tensor-decomposition technique to split a large layer into two smaller ones
Channel Pruning: Removes redundant input channels from a layer and reconstructs layer weights
Automatic selection of per-layer compression ratios: Automatically selects how much to compress each layer in the model
And much more
AIMET is designed to work with PyTorch and TensorFlow models.


另外，如下工具有更新（已经放到 AI Share上了）
Qualcomm Neural Processing SDK 
Update: v1.45.2 
This month’s update includes several new improvements to our popular SDK for developing artificial intelligence solutions. For a complete list of release notes, please visit the link above. 

Qualcomm Snapdragon Profiler 
Update: v2020.4 
This update of our Snapdragon Profiler includes several additions designed to help facilitate your use of our Trace view, and some improved support for various new devices 

//1224
图像的峰值信噪比（PSNR）的计算方法
https://blog.csdn.net/xrinosvip/article/details/88569111
OpenCV 实现SSIM结构相似性算法
https://blog.csdn.net/chaipp0607/article/details/70160307
SSIM（structural similarity）算法原理
https://blog.csdn.net/xrinosvip/article/details/88573555?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-6.control
两种常用的全参考图像质量评价指标——峰值信噪比（PSNR）和结构相似性（SSIM）---重要，参考价值极大
https://blog.csdn.net/loveliuzz/article/details/83862412?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control

//1230
android studio编译jar包或者aar包的方法教程详解
https://cloud.tencent.com/developer/article/1720382
Halide 
https://blog.csdn.net/tbzj_2000/article/details/84671390
https://blog.csdn.net/tbzj_2000/category_8018674.html
原创 Halide学习笔记----Halide tutorial源码阅读1
https://blog.csdn.net/luzhanbo207/category_7314346.html
【图像处理】多帧降噪算法
https://blog.csdn.net/jaych/article/details/68262911?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control
夜间降噪与多帧降噪的原理
https://blog.csdn.net/z827997640/article/details/81175692?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control
国防科大提出基于可变形三维卷积的视频超分辨，代码已开源
https://blog.csdn.net/extremevision/article/details/107727298?utm_medium=distribute.pc_relevant_download.none-task-blog-baidujs-2.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-baidujs-2.nonecase
论文链接： https://arxiv.org/pdf/2004.02803.pdf
代码链接： https://github.com/XinyiYing/D3Dnet
Halide简介
https://blog.csdn.net/weixin_42261213/article/details/100030830?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control
Halide学习主要用到以下两个网址：
Halide学习可参考官方教程：https://halide-lang.org/
Halide tutorial源码阅读（部分中文翻译）：https://blog.csdn.net/luzhanbo207/article/category/7314346
Github:https://github.com/halide/Halide

0106:
opencv之Canny()函数
https://blog.csdn.net/duwangthefirst/article/details/79971212
python opencv入门 Canny边缘检测（15）
https://blog.csdn.net/tengfei461807914/article/details/76376941?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control
OpenCv学习笔记(二)--Mat矩阵(图像容器)的创建及CV_8UC1,CV_8UC2等参数详解
https://blog.csdn.net/maweifei/article/details/51221259
OPENCV ROTATEDRECT的各参数详解
https://www.cnblogs.com/hsy1941/p/7923323.html
OpenCV—椭圆拟合fitEllipse---重要，代码来源
https://blog.csdn.net/i_chaoren/article/details/78358991
OpenCV3之——漫水填充：floodFill函数
https://blog.csdn.net/qq_35294564/article/details/81197049
OpenCV中的轮廓提取新函数connectedComponentsWithStats的使用
https://blog.csdn.net/sy95122/article/details/85992617
OpenCV中的新函数connectedComponentsWithStats使用
https://yq.aliyun.com/articles/649467/
opencv getStructuringElement函数
https://blog.csdn.net/kksc1099054857/article/details/76569718

0107:
OpenCV中的split函数
https://www.cnblogs.com/tcysky/p/6491835.html
0108:
android – 控制相机的自动曝光
http://www.voidcn.com/article/p-mqlhvhmd-bum.html

Camera 图像处理原理分析
https://blog.csdn.net/hktkfly6/article/details/53965807?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-14&spm=1001.2101.3001.4242
Camera 图像处理原理分析- 色彩篇 一
https://blog.csdn.net/colorant/article/details/1913200?utm_medium=distribute.pc_relevant.none-task-blog-searchFromBaidu-4.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-searchFromBaidu-4.control
opencv学习(四十三)之图像的矩moments()
https://blog.csdn.net/keith_bb/article/details/70197104
OpenCV中Mat类rowRange和colRange的用法
https://blog.csdn.net/jpc20144055069/article/details/102800181

Android基于CMake进行OpenCV开发配置----重要！！！！
https://www.jianshu.com/p/9f5758c36b34

//0109

git commit -m "upload moon fusion opencv code without complie error.

@type RQ" 
git push origin master:refs/for/master

//0111
git commit -m "move libopencv_java4.so to opecv related directory for complie error.

@type BUG" 
git push origin master:refs/for/master

git commit -m "upload test image read and write funciton code.

@type RQ" 
git push origin master:refs/for/master

//1112
git commit -m "upload reconstruction code,finish the main funtion reconstruction. 

@type RQ" 

//0113

tmux new -s deeplabv3plus_moon_1025
tmux attach -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025

tmux new -s cascade_moon_png_jpeg
tmux attach -t cascade_moon_png_jpeg

mount挂载：
sudo mount -t nfs  "10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/datasetV1_1025_1025" .
sudo mount -t nfs  "10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/datasetV2_1025_1025" .

取消mount：
sudo umount datasetV1_1025_1025_mount/
ln -s  10.74.158.105:/volume1/AI_Share/ AI_Share
解决nfs挂载错误wrong fs type, bad option, bad superblock
https://blog.51cto.com/smoke520/1949833
apt-get install nfs-common

tmux attach -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025
tmux kill-session -t deeplabv3plus_moon_1025

tmux new -s deeplabv3plus_moon_back_1025
//0114
pb优化：
sudo bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=moon_back_0114/moon_back_mnv3_0113_train_3680_val_300_30000_1025.pb \
--out_graph=moon_back_0114/opt_moon_back_mnv3_0113_train_3680_val_300_30000_1025.pb \
--inputs='ImageTensor' \
--outputs='SemanticPredictions' \
--transforms='
strip_unused_nodes(type=float, shape="1,1025,1025,3")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
flatten_atrous_conv
fold_batch_norms
fold_old_batch_norms'

pb转tfLite：
tflite_convert \
  --output_file=opt_moon_back_mnv3_0113_train_3680_val_300_30000_1025.tflite \
  --graph_def_file=opt_moon_back_mnv3_0113_train_3680_val_300_30000_1025.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_2" \
  --input_shape=1,1025,1025,3 \
  --output_arrays="ResizeBilinear_2"

Android Camera原理之createCaptureSession模块
https://www.pianshen.com/article/85591273215/
Zoom Camera(变焦相机)V7.2安卓版
https://www.cr173.com/soft/183077.html
深入理解Camera 基础知识点
https://www.cnblogs.com/programandriod/p/13868576.html

git commit -m "finish and upload reconstruction code. 

@type RQ"
 
//1118
mount挂载：
sudo mount -t nfs  "10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/datasetV1_1025_1025" .
sudo mount -t nfs  "10.74.158.105:/volume1/AI_Share/HDR+/人像长曝光+拍月亮样张/月亮/数据集/backMoonDatasetV2" .

取消mount：
sudo umount datasetV1_1025_1025_mount/

文件个数统计：
ls -l | grep "^-" | wc -l
查看当前目录文件夹大小：
du -h --max-depth=1 *
 
git commit -m "upload long-focus large moon split so and include file.

@type RQ" 
git push origin master:refs/for/master
 
//1119
是否有任何GPU支持细粒度系统SVM？
https://stackoom.com/question/39mzL/%E6%98%AF%E5%90%A6%E6%9C%89%E4%BB%BB%E4%BD%95GPU%E6%94%AF%E6%8C%81%E7%BB%86%E7%B2%92%E5%BA%A6%E7%B3%BB%E7%BB%9FSVM
OpenCL 2.0 规范 – SVM共享虚拟内存
https://www.cnblogs.com/lifan3a/articles/4613858.html

git commit -m "upload splite init and close code.

@type RQ" 
git push origin master:refs/for/master

git commit -m "upload test moon split code directly by image from camera.

@type RQ" 
git push origin master:refs/for/master

opencv resize （C/C++/Python）
https://blog.csdn.net/u012005313/article/details/51943442


git commit -m "add moon split related libmoon_segment.so and libmoon_split.so related files

@type RQ" 
git push origin master:refs/for/master
git push origin dev:refs/for/dev
LLL:
http://10.95.243.146:8080/c/AI/CV/Demo/+/168951

git commit -m "replace libimage_segment.so libimage_split.so to libmoon_segment.so and libmoon_split.so

@type RQ" 
git push origin master:refs/for/master
WYN:
http://10.95.243.146:8080/c/AI/ML/Moon/+/168952

//0121
pb优化：
sudo bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
--in_graph=moon_back_0119/moon_back_mnv3_0119_train_101512_val_1000_30000_1025.pb \
--out_graph=moon_back_0119/opt_moon_back_mnv3_0119_train_101512_val_1000_30000_1025.pb \
--inputs='ImageTensor' \
--outputs='SemanticPredictions' \
--transforms='
strip_unused_nodes(type=float, shape="1,1025,1025,3")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
flatten_atrous_conv
fold_batch_norms
fold_old_batch_norms'

pb转tfLite：
tflite_convert \
  --output_file=opt_moon_back_mnv3_0119_train_101512_val_1000_30000_1025.tflite \
  --graph_def_file=opt_moon_back_mnv3_0119_train_101512_val_1000_30000_1025.pb\
  --input_format=TENSORFLOW_GRAPHDEF \
  --output_format=TFLITE \
  --inference_type=FLOAT \
  --inference_input_type=FLOAT \
  --input_arrays="sub_2" \
  --input_shape=1,1025,1025,3 \
  --output_arrays="ResizeBilinear_2"
  
//0122

git commit -m "add API and test code to get moon split mask to certain output width and height  

@type RQ" 
git push origin master:refs/for/master
git push origin dev:refs/for/dev

//0125
git commit -m "modify test code to finish adaptiveMergeMoon without moon mask image  

@type RQ" 
git push origin master:refs/for/master


Android 使用Settings 数据库demo（源码）以及adb 读写settings数据库
https://blog.csdn.net/qq_37858386/article/details/106683276?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-10&spm=1001.2101.3001.4242

COLOR_YUV2BGR_NV21

//0126
git commit -m "upload ImageManager to collect main and tele camera images prepared for jni merge.  

@type RQ" 
git push origin master:refs/for/master

http://10.95.243.146:8080/c/AI/ML/Moon/+/170032
 

OpenCV C从android NV21图像数据缓冲区创建Mat对象
https://www.366service.com/cn/qa/1f94df15db50d08adf0253469d3e6bc6
android - opencv C++从Android NV21图像数据缓冲区创建Mat对象
https://www.coder.work/article/577723
http://10.95.243.146:8080/c/AI/ML/Moon/+/171136/1/moon/src/main/cpp/moonUtils.cpp

git commit -m "upload full flow of moon merge process, ImageManager.ENABLE is not true for stability.  

@type RQ" 
git push origin master:refs/for/master

git commit -m "modify test image dir for esay to find.  

@type RQ" 
git push origin master:refs/for/master

//0128

@type RQ" 

git commit -m "upload MVC code refactoring for image disaptch use:
1: add  ImageController to dispatch all images captured by both Main and tele camears;
2: add EffectModel interface to support various effects, and EffectModelMoon is only one instance;
3: add ImageInfoCache to  support multiple pictures both for Main and tele camears.

@type RQ"
git push origin master:refs/for/master 
http://10.95.243.146:8080/c/AI/ML/Moon/+/170592 

//0129
git commit -m " fix bugs related to different size between main and tele cameras of A2022P 

@type RQ"
git push origin master:refs/for/master 

git commit -m " trans cener posiont to jni for merge 

@type RQ"
git push origin master:refs/for/master 

git commit -m "mask useless test code  

@type RQ"
git push origin master:refs/for/master 

git commit -m "fix different rotation bugs  between main and tele cameras of A2022P 

@type BGU"
git push origin master:refs/for/master 
http://10.95.243.146:8080/c/AI/ML/Moon/+/170862
小米：3,4
A30：0，4
 
//0201
git commit -m "convert resultImg BGR Mat to outNv21 buffer, so fusion result can be directly saved in Camera DCIM dir. 

@type RQ"
git push origin master:refs/for/master 

git commit -m "add NativeApi.release() to finish native release fuction. 

@type BUG"
git push origin master:refs/for/master 

git commit -m "fix free buffer size bug

@type BUG"

git commit -m "fix dirty screen bug caused by finishFusion Mat float format 

@type BUG"


git commit -m "fix dead cycle bug on device which TeleCamera not supported

@type BUG"

App/src/main/java/com/zte/demo/algo/AlgoModuleController.java

//21:0207
耗时分析：
2021-02-07 15:37:38.276 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step0 time=74ms
2021-02-07 15:37:38.392 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step1 time=113ms
2021-02-07 15:37:38.392 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step2 time=0ms
2021-02-07 15:37:38.620 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step3 time=230ms
2021-02-07 15:37:38.652 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step4 time=33ms
2021-02-07 15:37:38.656 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step5 time=5ms
2021-02-07 15:37:38.660 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step6 time=1ms
2021-02-07 15:37:39.908 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step7 time=1249ms,totoal=1705ms
2021-02-07 15:37:40.104 15786-18569/org.codeaurora.snapcam D/ZteMoon: test debug time mergeFromMainAndTel,all time=2751ms

2021-02-07 15:39:49.176 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step0 time=91ms
2021-02-07 15:39:49.292 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step1 time=115ms
2021-02-07 15:39:49.292 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step2 time=0ms
2021-02-07 15:39:49.512 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step3 time=222ms
2021-02-07 15:39:49.548 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step4 time=36ms
2021-02-07 15:39:49.556 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step5 time=7ms
2021-02-07 15:39:49.556 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step6 time=1ms
2021-02-07 15:39:51.336 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step7 time=1779ms,totoal=2251ms
2021-02-07 15:39:51.524 15786-21991/org.codeaurora.snapcam D/ZteMoon: test debug time mergeFromMainAndTel,all time=3273ms

不画中间结果：
2021-02-07 16:10:21.848 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step0 time=117ms
2021-02-07 16:10:21.968 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step1 time=121ms
2021-02-07 16:10:21.968 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step2 time=0ms
2021-02-07 16:10:22.000 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step3 time=30ms
2021-02-07 16:10:22.036 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step4 time=39ms
2021-02-07 16:10:22.044 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step5 time=6ms
2021-02-07 16:10:22.044 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step6 time=1ms
2021-02-07 16:10:24.988 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step7 time=2945ms,totoal=3259ms
2021-02-07 16:10:25.188 5761-6331/org.codeaurora.snapcam D/ZteMoon: test debug time mergeFromMainAndTel,all time=4375ms

2021-02-07 16:11:42.924 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step0 time=80ms
2021-02-07 16:11:43.052 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step1 time=126ms
2021-02-07 16:11:43.052 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step2 time=0ms
2021-02-07 16:11:43.088 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step3 time=35ms
2021-02-07 16:11:43.128 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step4 time=43ms
2021-02-07 16:11:43.132 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step5 time=4ms
2021-02-07 16:11:43.136 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step6 time=1ms
2021-02-07 16:11:45.008 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step7 time=1875ms,totoal=2164ms
2021-02-07 16:11:45.232 5761-9167/org.codeaurora.snapcam D/ZteMoon: test debug time mergeFromMainAndTel,all time=3255ms


2021-02-07 16:41:47.656 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step0 time=87ms
2021-02-07 16:41:47.768 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step1 time=113ms
2021-02-07 16:41:47.768 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step2 time=0ms
2021-02-07 16:41:47.800 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step3 time=30ms
2021-02-07 16:41:47.832 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step4 time=32ms
2021-02-07 16:41:47.836 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step5 time=5ms
2021-02-07 16:41:47.836 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step6 time=1ms
2021-02-07 16:41:47.904 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step7 time=67ms,totoal=335ms
2021-02-07 16:41:48.084 22604-22675/org.codeaurora.snapcam D/ZteMoon: test debug time mergeFromMainAndTel,all time=1386ms


多灯图片：
region：
2021-02-07 17:58:43.958 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step0 time=87ms
2021-02-07 17:58:44.062 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step1 time=107ms
2021-02-07 17:58:44.062 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step2 time=0ms
2021-02-07 17:58:44.078 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step3 time=16ms
2021-02-07 17:58:44.114 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step4 time=33ms
2021-02-07 17:58:44.118 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step5 time=6ms
2021-02-07 17:58:44.118 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step6 time=1ms
2021-02-07 17:58:44.190 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step7 time=72ms,totoal=322ms
2021-02-07 17:58:44.370 16666-16791/org.codeaurora.snapcam D/ZteMoon: test debug time mergeFromMainAndTel,all time=1355ms


全融合：
2021-02-07 18:00:03.018 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step0 time=79ms
2021-02-07 18:00:03.130 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step1 time=111ms
2021-02-07 18:00:03.130 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step2 time=0ms
2021-02-07 18:00:03.146 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step3 time=16ms
2021-02-07 18:00:03.182 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step4 time=36ms
2021-02-07 18:00:03.186 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step5 time=5ms
2021-02-07 18:00:03.186 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step6 time=1ms
2021-02-07 18:00:05.350 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time adaptiveMergeMoon step7 time=2163ms,totoal=2411ms
2021-02-07 18:00:05.530 17143-17252/org.codeaurora.snapcam D/ZteMoon: test debug time mergeFromMainAndTel,all time=3414m

https://developer.android.com/ndk/guides/cpu-arm-neon

https://github.com/android/ndk-samples

//0218
git clone "ssh://10087295@10.95.243.146:29418/AI/ML/Moon" && scp -p -P 29418 10087295@10.95.243.146:hooks/commit-msg "Moon/.git/hooks/"
删除指定链接：
net use p: /del
net use命令详解（转）
https://www.cnblogs.com/mamiyiya777/p/11017875.html

//0219
Android Camera 曝光：
https://blog.csdn.net/haiping1224746757/article/details/107636207
Camera系列文章：
https://blog.csdn.net/haiping1224746757/category_9879070.html
Android Camera HDR 拍照模式的原理
https://blog.csdn.net/haiping1224746757/article/details/109719744

Android 新老两代 Camera API 大起底
https://blog.csdn.net/Byeweiyang/article/details/80515192?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.control

关于Android Camera的曝光补偿（Exposure Compensation）
https://blog.csdn.net/daihuimaozideren/article/details/92758190?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.control

WB(白平衡) ISO(感光度) 曝光补偿 详解
https://blog.csdn.net/jinchengblue/article/details/39183779?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control

快门光圈感光度口诀_光圈快门感光度，正确曝光三要素
https://blog.csdn.net/weixin_29122445/article/details/112186815?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control

camera2 曝光百度翻译记录
https://blog.csdn.net/m0_37039192/article/details/95081439?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-3&spm=1001.2101.3001.4242

android camera2 详解说明（一）
https://www.cnblogs.com/kingwild/articles/5422329.html

Camera2 APP Flash 打闪流程及原理分析
https://blog.csdn.net/haiping1224746757/article/details/106046986#comments_14218413

为什么色温越高。偏蓝的趋势越大。温度月低，偏橙黄色的趋势越大。
https://zhidao.baidu.com/question/97308348.html
色温和色调到底有什么区别？
https://zhidao.baidu.com/question/196091033.html
高色温光源照射下，如亮度不高则给人们有一种阴冷的气氛；低色温光源照射下，亮度过高会给人们有一种闷热感觉。
暖色调的亮度越高，其整体感觉越偏暖，冷色调的亮度越高，其整体感觉越偏冷。

傻傻分不清色温和色调关系？？？重要！！！！
http://www.360doc.com/content/19/0719/10/36925391_849715712.shtml


Android Camera相机开发详解2017-08-21
https://awenzeng.me/2017/08/21/tech_android_camera/
Camera官方文档：
https://developer.android.com/training/camera?hl=zh-cn 

Android Camera 相机开发详解：
https://www.lagou.com/lgeduarticle/80217.html
Android Camera详解（译）
https://www.jianshu.com/p/e5312fd916dd
Android Camera简单整理(一)-Camera Android架构(基于Q)---框架
https://www.jianshu.com/p/760dec1a9078

Camera系列：---重要！！！！
Android:调用系统相机实现拍照+裁切（兼容7.0以上系统）
https://www.jianshu.com/p/eca7335602c1
Android: Camera相机开发详解(上) —— 知识储备
https://www.jianshu.com/p/f8d0d1467584
Android: Camera相机开发详解(中) ——实现预览、拍照、保存照片等功能
https://www.jianshu.com/p/e20a2ad6ad9a
Android: Camera相机开发详解(下) —— 实现人脸检测功能
https://www.jianshu.com/p/3bb301c302e8
Android:Camera2开发详解(上)：实现预览、拍照、保存照片等功能
https://www.jianshu.com/p/0ea5e201260f
Android:Camera2开发详解(下)：实现人脸检测功能并实时显示人脸框
https://www.jianshu.com/p/331af6dc2772
完整代码
https://github.com/smashinggit/Study

Android Camera教程系列：
Android Camera1 教程 · 第一章 · 开启相机
https://www.jianshu.com/p/3440d82545f6
Android Camera1 教程 · 第二章 · 预览
https://www.jianshu.com/p/705d4792e836
Android Camera2 教程 · 第一章 · 概览
https://www.jianshu.com/p/9a2e66916fcb
Android Camera2 教程 · 第二章 · 开关相机
https://www.jianshu.com/p/df3c8683bb90
Android Camera2 教程 · 第三章 · 预览
https://www.jianshu.com/p/067889611ae7
Android Camera2 教程 · 第四章 · 拍照
https://www.jianshu.com/p/2ae0a737c686

//0220
git commit -m "modify exposure time and iso in TeleCamer for data collection

@type RQ"
git push origin master:refs/for/master 

git log --graph origin master      zdm@Develop
git reset  973cfc6a2b53259777b7041bb8c000bf6f86479f --hard

git reset  d0ee86c1517a58d9e8877857ae940489cef7e744 --hard


commit b44f33f791e5e2b2fbe465c3d21ca526a9f1672e
Author: 10087295 <zhang.dongming@zte.com.cn>
Date:   Sat Feb 20 10:56:10 2021 +0800

    modify exposure time and iso in TeleCamer for data collection

    @type RQ

    Change-Id: Iba0f548cb25a5121dd61fda5c5ce8d3d3e49f912

commit a41ebec7bcc45c66719f970c4c197d0b66c09cb7
Author: 10087295 <zhang.dongming@zte.com.cn>
Date:   Mon Feb 8 14:41:46 2021 +0800

    upload finishFusionOnlyRegion function to decrease process time.

    @type RQ

    Change-Id: I475627b1e1d669e1ff130af8b8920e817f23f39e

git reset  a41ebec7bcc45c66719f970c4c197d0b66c09cb7 --hard
git reset  b44f33f791e5e2b2fbe465c3d21ca526a9f1672e --hard


git commit -m "remove test code  for data collection

@type RQ"
git push origin master:refs/for/master 

git commit -m "upload simulated scenario switch support

@type RQ"

git commit -m "add iso 400 ... 1600 captrue images

@type RQ"

git push origin master:refs/for/master 

//0223
在c/java code中打印log--(把多个字符串起来打印一行)
https://www.cnblogs.com/snowdrop/articles/3975363.html


报错：
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG: backtrace:
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #00 pc 00000000000830f0  /apex/com.android.runtime/lib64/bionic/libc.so (abort+160) (BuildId: 596462ba33c607448e0776eb2ca6d48e)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #01 pc 0000000000d46240  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #02 pc 0000000000d463a0  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #03 pc 0000000000d43184  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #04 pc 0000000000d4288c  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #05 pc 0000000000d4280c  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (__cxa_throw+120) (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #06 pc 00000000003b1a24  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (cv::error(cv::Exception const&)+388) (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #07 pc 00000000003b1494  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (cv::error(int, std::__ndk1::basic_string<char, std::__ndk1::char_traits<char>, std::__ndk1::allocator<char>> const&, char const*, char const*, int)+324) (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #08 pc 0000000000300168  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (cv::Mat::Mat(cv::Mat const&, cv::Rect_<int> const&)+784) (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #09 pc 00000000006a8c14  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libopencv_java4.so (cv::seamlessClone(cv::_InputArray const&, cv::_InputArray const&, cv::_InputArray const&, cv::Point_<int>, cv::_OutputArray const&, int)+720) (BuildId: a9553e303663974c24c60cfc16756e7beaeb3b58)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #10 pc 000000000003ae38  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libztemoon.so (Fusion::PoissonFusion(cv::Mat, cv::Mat, cv::Mat, int)+352) (BuildId: fb41d2ffcc58d11c2ac0ae73a507edb53f5c5e43)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #11 pc 000000000003bfc4  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libztemoon.so (Fusion::edgePoissonCenterLap(int, int)+860) (BuildId: fb41d2ffcc58d11c2ac0ae73a507edb53f5c5e43)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #12 pc 0000000000033508  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libztemoon.so (finishFusion(cv::Mat&, cv::Mat&, cv::Mat&, int, int, std::__ndk1::basic_string<char, std::__ndk1::char_traits<char>, std::__ndk1::allocator<char>>&, int)+672) (BuildId: fb41d2ffcc58d11c2ac0ae73a507edb53f5c5e43)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #13 pc 0000000000034cf0  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libztemoon.so (finishFusionOnlyRegion(cv::Rect_<int>, cv::Mat&, cv::Mat&, cv::Mat&, int, int, std::__ndk1::basic_string<char, std::__ndk1::char_traits<char>, std::__ndk1::allocator<char>>&, int)+212) (BuildId: fb41d2ffcc58d11c2ac0ae73a507edb53f5c5e43)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #14 pc 000000000002c960  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libztemoon.so (adaptiveMergeMoon(cv::Mat, cv::Mat, cv::Mat, std::__ndk1::basic_string<char, std::__ndk1::char_traits<char>, std::__ndk1::allocator<char>>&, int)+3744) (BuildId: fb41d2ffcc58d11c2ac0ae73a507edb53f5c5e43)
2021-02-23 17:57:53.611 9340-9340/? A/DEBUG:       #15 pc 000000000002aca8  /data/app/org.codeaurora.snapcam-ZMCgI0Yh2t4Y6KQrQEcPpQ==/lib/arm64/libztemoon.so (testMergeMoon()+1656) (BuildId: fb41d2ffcc58d11c2ac0ae73a507edb53f5c5e43)

git commit -m "upload adaptive threshold for background moon segmentation

@type RQ"

//0303
git commit -m "fix location err bug in backgound 

@type BUG"

git commit -m "upload all test imges test function

@type RQ"

git commit -m "adjust MOON_CDF_MIN to fix backgound location error

@type RQ"

git commit -m "modify adaptive theshold  mechanism to fix backgound location error

@type BUG"

git commit -m "modify adaptive theshold  mechanism to fix backgound location error

@type BUG"
git push origin master:refs/for/master 

git commit -m "modify adaptive theshold  mechanism to fix backgound location error

@type BUG"

git commit -m "adjust theshold to fix miss location bug on images captured by xiaomi devices

@type BUG"

git commit -m "add test macro code fot all image test

@type BUG"

git commit -m "add contrast and brightness adjust function for moon content optimization 

@type RQ"

git commit -m "modify fusion threshold to adjust edge effects
@type BUG"

git push origin master:refs/for/master 

rm /sdcard/data_merged_out/*
adb shell rm /sdcard/data_merged_out/*
adb pull /sdcard/data_merged_out .
adb pull /sdcard/moon_temp_test .

//0304
色温(Kelvin)到RGB的转换：算法和样例
https://blog.csdn.net/lz0499/article/details/104088393
自动白平衡(AWB)算法---2,色温计算
https://blog.csdn.net/wzwxiaozheng/article/details/40586293
白平衡（灰度世界、全反射、色温估计）
https://blog.csdn.net/a6333230/article/details/82889842?utm_medium=distribute.pc_relevant.none-task-blog-searchFromBaidu-7.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-searchFromBaidu-7.control
基于白点检测的数码相机自动白平衡算法实现（Opencv+vs）
https://blog.csdn.net/u010373145/article/details/44223375
色温计算方法怎么应用？
https://www.zybang.com/question/884e2dd79bd8e1195d3690a7f2e47bfb.html

色温所对及应的RGB颜色表
https://blog.csdn.net/u014549283/article/details/81149061?utm_medium=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-2.nonecase&depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task-blog-baidujs-2.nonecase
如何从RGB值转换为色温？(How to convert from RGB values to color temperature?)
https://www.it1352.com/2006071.html
简单的一种图像冷暖色温转换（MATLAB）----重要！！！
https://blog.csdn.net/weixin_44690935/article/details/104347324
【OpenCV（C++）】分离颜色通道、多通道图像混合----重要！！！
https://blog.csdn.net/weixin_43645790/article/details/104083817

图像光照校正处理（白平衡）及其速度优化 -OPENCV+PYTHON
https://www.freesion.com/article/2972442101/
opencv-ios开发笔记11 亮度和色温调节
https://blog.csdn.net/baixiaozhe/article/details/52634006
OpenCV——色调映射
https://blog.csdn.net/matrix_space/article/details/40584537

色温计算公式.docx
https://blog.csdn.net/weixin_30466953/article/details/95391732?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.control
色温所对及应的RGB颜色表
https://download.csdn.net/download/u014549283/10556207?spm=1001.2101.3001.5697

ISP（图像信号处理）算法概述、工作原理、架构、处理流程
https://blog.csdn.net/mao_hui_fei/article/details/99544395?utm_medium=distribute.pc_relevant_bbs_down.none-task--2~all~first_rank_v2~rank_v29-7.nonecase&depth_1-utm_source=distribute.pc_relevant_bbs_down.none-task--2~all~first_rank_v2~rank_v29-7.nonecase
图像颜色校正的几种方法
https://blog.csdn.net/wenglican3523/article/details/79668981?utm_medium=distribute.pc_relevant_download.none-task-blog-baidujs-1.nonecase&depth_1-utm_source=distribute.pc_relevant_download.none-task-blog-baidujs-1.nonecase

结合灰度世界和完美反射的颜色校正方法
https://blog.csdn.net/lydujing/article/details/50790003?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control

基于灰度世界、完美反射、动态阈值等图像自动白平衡算法的原理、实现及效果...----重要！！！！
https://blog.csdn.net/chuifuhuo6864/article/details/100875554?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-4&spm=1001.2101.3001.4242

基于灰度世界、完美反射、动态阈值等图像自动白平衡算法的原理
https://blog.csdn.net/qq_38676868/article/details/80946840?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-1.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1.control

python-opencv五种自动白平衡算法，附源码直接可用（均值、完美反射、灰度世界、动态阈值、基于图像分析的偏色检测及颜色校正）---重要！！！！
https://blog.csdn.net/qq_36187544/article/details/97657927?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-3.control

Python-OpenCV中的Gamma变换（校正）
https://blog.csdn.net/u013063099/article/details/79967027?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control&dist_request_id=1328593.26213.16148551849847163&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.control

自动白平衡算法原理及结合Opencv的C++实现---重要！！！
https://blog.csdn.net/thecentry/article/details/105710982?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-8&spm=1001.2101.3001.4242


git commit -m "modify fusion threshold to adjust edge effects
@type BUG"

git push origin master:refs/for/master 

rm /sdcard/data_merged_out/*
adb shell rm /sdcard/data_merged_out/*
adb pull /sdcard/data_merged_out .
adb pull /sdcard/moon_temp_test .

adb shell rm /sdcard/moon_data/data_merged_out/*
adb shell rm /sdcard/moon_data/moon_temp_test/*
adb pull /sdcard/moon_data/data_merged_out .
adb pull /sdcard/moon_data/moon_temp_test .

adb shell rm /storage/emulated/0/DCIM/moon_data/data_merged_out/*
adb shell rm  /storage/emulated/0/DCIM/moon_data/moon_temp_test/*

adb pull /storage/emulated/0/DCIM/moon_data/moon_temp_test/ .
adb pull /storage/emulated/0/DCIM/moon_data/data_merged_out/ .

Mat finishFusion
Fusion fs(largeMoon, background, kSeg, resultFileName, occlusionExist, number);

left:834,top:1002,right:1722,bottom:1873

git commit -m "fix moon not filled bug
@type BUG"

git commit -m "add macro control to save temp image
@type BUG"
git push origin master:refs/for/master 

git commit -m "modify save folders fot all image test
@type BUG"
git push origin master:refs/for/master 


Mat Nv21Main(mH + mH / 2, mW, CV_8UC1, inMainNv21);
Mat Nv21Tel(tH + tH / 2, tW, CV_8UC1, inTeleNv21);
resize(Nv21Main, Nv21Main, Size(w, h), 0, 0, INTER_CUBIC);

ImageUtils.getYUVData2NV21FromImageReade

NV21裁剪 缩放
https://blog.csdn.net/jacke121/article/details/103281350
NV21格式图像旋转（原理--代码实现），平移、缩放实现代码
https://blog.csdn.net/cgwang_1580/article/details/79645645?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.control&dist_request_id=1328666.8533.16159619144748105&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.control

git commit -m "upload crop and scale fuction similar to camera 
@type RQ"
git push origin master:refs/for/master 

git commit -m "remove crop and scale fuction similar to camera 
@type RQ"
git push origin master:refs/for/master 


git commit -m "upload SR process and modify view rect by 3 times 
@type RQ"
git push origin master:refs/for/master 


git commit -m "upload SR process and modify view rect by 6 times 
@type RQ"
git push origin master:refs/for/master 

git commit -m "modify AIP to surpport adaptive TEL_SCALE_RATIO
@type RQ"
git push origin master:refs/for/master 


git commit -m "fix location error bug
@type BUG"

git commit -m "fix too bright bug
@type BUG"

git commit -m "support 6x fusion scale to 4x
@type BUG"

git commit -m "add version and moon scale setter and getter API
@type RQ"

git commit -m "update libarcsoft_ai_moon.so to remove watermark
@type RQ"
git push origin master:refs/for/master 


http://todo.zte.com.cn/IOA/SpAudit/CounterSignDetail.aspx?spId=7511828&amp;Op=1&amp;OrNo=0



float getVersion();

2021-03-22 15:35:12.310 8659-8904/org.codeaurora.snapcam E/AndroidRuntime: FATAL EXCEPTION: Thread-6
    Process: org.codeaurora.snapcam, PID: 8659
    java.lang.UnsatisfiedLinkError: JNI_ERR returned from JNI_OnLoad in "/data/app/~~x87YVAhzr9EpTiIIhVWQNQ==/org.codeaurora.snapcam-cxsjs4zaRroIxgFB4T969A==/lib/arm64/libarcsoft_moon_jni.so"
        at java.lang.Runtime.loadLibrary0(Runtime.java:1087)
        at java.lang.Runtime.loadLibrary0(Runtime.java:1008)
        at java.lang.System.loadLibrary(System.java:1664)
        at com.zte.moon.arcsoftmoon.ArcsoftMoon.<clinit>(ArcsoftMoon.java:6)
        at com.zte.demo.algo.AlgoModuleController$ProcessThread.run(AlgoModuleController.java:294)
		
mActiveRect.width()=4624,mActiveRect.height()=3472,
mPreviewSize.getWidth()=1440,mPreviewSize.getHeight()=1080

updateCenterPosRatio locRect=Rect(403, 518 - 748, 992)
updateCenterPosRatio centerWRatio=0.53287035, centerHRatio=0.5243056, widthRatio=0.31944445, heightRatio=0.32916668
 renderDebug left=403, top=518, right=748, bottom=992
 updateCenterPosRatio centerWRatio=0.53287035, centerHRatio=0.5243056, widthRatio=0.31944445, heightRatio=0.32916668
		
modified:   api/src/main/java/com/zte/camera/api/ztemoon/IZTEMoon.java
modified:   camera/src/com/zte/camera/imageprocess/ZTEMoonProcess.java
modified:   camera/src/com/zte/camera/moduleview/MoonModuleView.java
modified:   camera/src/com/zte/camera/util/Util.java
modified:   ztemoon/libs/moon.aar
modified:   ztemoon/src/main/java/com/zte/moonscene/ZTEMoonImp.java


demo改长焦放大倍数的地方：CameraParamUtils.java,public static float TEL_SCALE_RATIO = 4f;//6f;
Camera改长焦放大倍数的地方：MoonModuleView.java,public static float TEL_SCALE_RATIO = 6f/*4f*/;


2021-03-25 12:19:23.079 3726-4093/org.codeaurora.snapcam D/ZteMoon: test debug merge getAdaptiveThreshold ---moonCenter.x:501.000000,moonCenter.y:974.000000
2021-03-25 12:19:23.173 3726-4093/org.codeaurora.snapcam D/ZteMoon: test debug merge getAdaptiveThreshold moonCenter.x:501.000000,moonCenter.y:974.000000

:614.000000,moonCenter.y:867.000000

onnectedComponentsWithStats （）详细用法
https://blog.csdn.net/qq_40119386/article/details/89085075


2021-03-26 17:18:27.370 6292-15881/org.codeaurora.snapcam D/ZteMoon: test debug merge getAdaptiveThreshold 
moonCenter.x 000:658.000000,moonCenter.y:733.000000,nonZeroNum:1352,moonWidth:58.666668,moonHeight:35.333332

2021-03-26 17:19:41.212 6292-16552/org.codeaurora.snapcam D/ZteMoon: test debug merge getAdaptiveThresholdFromBg 333 
 centerLabel:48,centerX:1105,centerY:1518,rightness:183.330215,area:58.666668,moonWidth:35.333332,moonHeight:0.000000

27 51 55 60 69 74 85


#define RES_STAT_OK            0

#define RES_STAT_MOON_NONE     1
#define RES_STAT_MOON_CONFUSE  2
#define RES_STAT_MOON_BORDER   3

#define RES_STAT_BG_MOON_DARK     4
#define RES_STAT_BG_MOON_DISTURB  5
#define RES_STAT_BG_MOON_OCCLUSION  6

#define RES_STAT_FUSION_MOON_CLOUD  7


//0408
go:
NanoDet Git地址：
https://github.com/RangiLyu/nanodet
Android优化：
https://github.com/nihui/ncnn-android-nanodet

NenoDet环境搭建：
nanodet 
conda create -n nanodet_py38 python=3.8 -y
conda activate nanodet_py38
conda install pytorch torchvision cudatoolkit=11.0 -c pytorch
pip install Cython termcolor numpy tensorboard pycocotools matplotlib pyaml opencv-python tqdm
pip 安装失败解决：
conda install Cython
最终解决办法：
pip安装难题:There was a problem confirming ssl certifi...
https://www.seogurublog.com/20200718529.html
pip install --trusted-host mirrors.aliyun.com Cython -i http://mirrors.aliyun.com/pypi/simple/
pip install --trusted-host mirrors.aliyun.com termcolor numpy tensorboard pycocotools matplotlib pyaml opencv-python tqdm -i http://mirrors.aliyun.com/pypi/simple/


相关资料：
Gdy：
1.8M超轻量目标检测模型NanoDet，比YOLO跑得快，上线两天Star量超500
https://www.jiqizhixin.com/articles/2020-11-24-5
android 端可以使用 nihui 那个版本的优化

知乎中文官网说明：
YOLO之外的另一选择，手机端97FPS的Anchor-Free目标检测模型NanoDet现已开源~
https://zhuanlan.zhihu.com/p/306530300

大白话 Generalized Focal Loss
https://zhuanlan.zhihu.com/p/147691786

Backbone：
ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices
https://arxiv.org/abs/1707.01083
轻量化网络：ShuffleNet v2解析
https://www.pianshen.com/article/33731319646/
https://github.com/TropComplique/shufflenet-v2-tensorflow

ShuffleNet-Series github官网： MIT License
https://github.com/megvii-model/ShuffleNet-Series

重磅！13 篇基于 Anchor free 的目标检测方法
https://bbs.cvmart.net/articles/442/zhong-bang-13-pian-ji-yu-anchor-free-de-mu-biao-jian-ce-fang-fa

Pytorch转NCNN的流程记录
https://zhuanlan.zhihu.com/p/124294444
pytorch模型的部署（系列一）--ncnn的编译和使用
https://zhuanlan.zhihu.com/p/137458205
深度学习框架大PK：TNN决战MNN，ncnn依旧经典
https://www.huaweicloud.com/articles/212284f0faf9c3c01b8c856c906bc1a8.html

//0409
离线环境迁移：
迁移anaconda虚拟环境到新服务器+解决迁移后pip无法使用
https://blog.csdn.net/weixin_44633882/article/details/105308120
Anaconda复制/克隆虚拟环境到其他机器
https://blog.csdn.net/ben1010101010/article/details/104301377?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-2.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-2.control
conda create --name new_env --clone ~/env

查看当前目录文件夹大小：
du -sh
du -h --max-depth=1 *
	